{"_default": {"1": {"action_state": "story_bot.1_shape.gather_context", "status": "started", "timestamp": "2025-12-09T19:10:23.136804"}, "2": {"action_state": "story_bot.1_shape.gather_context", "status": "completed", "timestamp": "2025-12-09T19:10:23.147524", "outputs": {"instructions": {"action": "gather_context", "behavior": "1_shape", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["Who are the distinct types of users (e.g., operational users, power users, compliance consumers, content creators, producers)?", "What are the key goals, behaviors, or decisions each group is trying to accomplish using this capability?", "Who are the primary users or stakeholder groups impacted?", "What is the first thing users will try to do with this new capability or system?", "What problems, inefficiencies, or workarounds is this request trying to eliminate?", "Where are users currently struggling, getting stuck, or experiencing delays in the process we're aiming to improve?", "What other systems, data sources, or tools does this capability need to interact with in order to deliver value?", "What are the key behaviors or integration points that define how these systems support or depend on one another?", "What is the business domain we are modeling?", "What are the core business concepts and their relationships?", "What are the distinct sub-domains or business capabilities?", "What are the boundaries between different parts of the domain?", "What domain events occur in this business domain?", "What are the key business rules and constraints?", "What domain language do business experts use to describe this domain?"], "evidence": ["Business model canvas", "Journey maps or other design thinking artifacts", "Technical specifications", "Product charters", "Business cases", "Business models", "Impact maps", "R&D maps", "User research", "User journey maps", "Similar systems", "User interviews", "Business process documentation", "Domain expert interviews", "Existing system documentation", "Business glossaries or dictionaries", "Financial statements", "Industry literature", "Event storming outputs", "Domain models from similar systems"]}}}}, "3": {"action_state": "story_bot.1_shape.gather_context", "status": "started", "timestamp": "2025-12-09T19:10:55.537876"}, "4": {"action_state": "story_bot.1_shape.gather_context", "status": "completed", "timestamp": "2025-12-09T19:10:55.560878", "outputs": {"instructions": {"action": "gather_context", "behavior": "1_shape", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["Who are the distinct types of users (e.g., operational users, power users, compliance consumers, content creators, producers)?", "What are the key goals, behaviors, or decisions each group is trying to accomplish using this capability?", "Who are the primary users or stakeholder groups impacted?", "What is the first thing users will try to do with this new capability or system?", "What problems, inefficiencies, or workarounds is this request trying to eliminate?", "Where are users currently struggling, getting stuck, or experiencing delays in the process we're aiming to improve?", "What other systems, data sources, or tools does this capability need to interact with in order to deliver value?", "What are the key behaviors or integration points that define how these systems support or depend on one another?", "What is the business domain we are modeling?", "What are the core business concepts and their relationships?", "What are the distinct sub-domains or business capabilities?", "What are the boundaries between different parts of the domain?", "What domain events occur in this business domain?", "What are the key business rules and constraints?", "What domain language do business experts use to describe this domain?"], "evidence": ["Business model canvas", "Journey maps or other design thinking artifacts", "Technical specifications", "Product charters", "Business cases", "Business models", "Impact maps", "R&D maps", "User research", "User journey maps", "Similar systems", "User interviews", "Business process documentation", "Domain expert interviews", "Existing system documentation", "Business glossaries or dictionaries", "Financial statements", "Industry literature", "Event storming outputs", "Domain models from similar systems"]}}}}, "5": {"action_state": "story_bot.1_shape.gather_context", "status": "started", "timestamp": "2025-12-09T19:10:57.586864"}, "6": {"action_state": "story_bot.1_shape.gather_context", "status": "completed", "timestamp": "2025-12-09T19:10:57.600489", "outputs": {"instructions": {"action": "gather_context", "behavior": "1_shape", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["Who are the distinct types of users (e.g., operational users, power users, compliance consumers, content creators, producers)?", "What are the key goals, behaviors, or decisions each group is trying to accomplish using this capability?", "Who are the primary users or stakeholder groups impacted?", "What is the first thing users will try to do with this new capability or system?", "What problems, inefficiencies, or workarounds is this request trying to eliminate?", "Where are users currently struggling, getting stuck, or experiencing delays in the process we're aiming to improve?", "What other systems, data sources, or tools does this capability need to interact with in order to deliver value?", "What are the key behaviors or integration points that define how these systems support or depend on one another?", "What is the business domain we are modeling?", "What are the core business concepts and their relationships?", "What are the distinct sub-domains or business capabilities?", "What are the boundaries between different parts of the domain?", "What domain events occur in this business domain?", "What are the key business rules and constraints?", "What domain language do business experts use to describe this domain?"], "evidence": ["Business model canvas", "Journey maps or other design thinking artifacts", "Technical specifications", "Product charters", "Business cases", "Business models", "Impact maps", "R&D maps", "User research", "User journey maps", "Similar systems", "User interviews", "Business process documentation", "Domain expert interviews", "Existing system documentation", "Business glossaries or dictionaries", "Financial statements", "Industry literature", "Event storming outputs", "Domain models from similar systems"]}}}}, "7": {"action_state": "story_bot.1_shape.gather_context", "status": "started", "timestamp": "2025-12-09T19:11:16.545838"}, "8": {"action_state": "story_bot.1_shape.gather_context", "status": "completed", "timestamp": "2025-12-09T19:11:16.559964", "outputs": {"instructions": {"action": "gather_context", "behavior": "1_shape", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["Who are the distinct types of users (e.g., operational users, power users, compliance consumers, content creators, producers)?", "What are the key goals, behaviors, or decisions each group is trying to accomplish using this capability?", "Who are the primary users or stakeholder groups impacted?", "What is the first thing users will try to do with this new capability or system?", "What problems, inefficiencies, or workarounds is this request trying to eliminate?", "Where are users currently struggling, getting stuck, or experiencing delays in the process we're aiming to improve?", "What other systems, data sources, or tools does this capability need to interact with in order to deliver value?", "What are the key behaviors or integration points that define how these systems support or depend on one another?", "What is the business domain we are modeling?", "What are the core business concepts and their relationships?", "What are the distinct sub-domains or business capabilities?", "What are the boundaries between different parts of the domain?", "What domain events occur in this business domain?", "What are the key business rules and constraints?", "What domain language do business experts use to describe this domain?"], "evidence": ["Business model canvas", "Journey maps or other design thinking artifacts", "Technical specifications", "Product charters", "Business cases", "Business models", "Impact maps", "R&D maps", "User research", "User journey maps", "Similar systems", "User interviews", "Business process documentation", "Domain expert interviews", "Existing system documentation", "Business glossaries or dictionaries", "Financial statements", "Industry literature", "Event storming outputs", "Domain models from similar systems"]}}}}, "9": {"action_state": "story_bot.1_shape.build_knowledge", "status": "started", "timestamp": "2025-12-09T19:11:20.683419"}, "10": {"action_state": "story_bot.1_shape.build_knowledge", "status": "completed", "timestamp": "2025-12-09T19:11:20.699969", "outputs": {"instructions": {"knowledge_graph_template": {"_explanation": {"hierarchical": "sub_epics can contain: nested sub_epics or story_groups. sequential_order is always an integer (1, 2, 3, 4) - unique within parent, no decimals.", "connector": "Story groups: 'and' or 'or' (null for first group). Stories within groups: 'and' or 'or' (null for first story). Epics and sub_epics don't have connectors.", "domain_placement": "domain_concepts: 'local' if relevant to single sub_epic, 'global' if relevant to multiple sub_epics. Place at most specific level (local preferred), but elevate to parent if used by multiple children."}, "epics": [{"name": "", "sequential_order": 1, "estimated_stories": null, "domain_concepts": [{"name": "", "responsibilities": [{"name": "", "collaborators": []}]}], "sub_epics": [{"name": "", "sequential_order": 1, "estimated_stories": null, "domain_concepts": [{"name": "", "responsibilities": [{"name": "", "collaborators": []}]}], "sub_epics": [], "story_groups": [{"type": "and", "connector": null, "sequential_order": 1, "stories": [{"name": "", "sequential_order": 1, "connector": null, "users": [], "story_type": "user"}, {"name": "", "sequential_order": 2, "connector": "and", "users": [], "story_type": "user"}]}, {"type": "and", "connector": "or", "sequential_order": 2, "stories": [{"name": "", "sequential_order": 1, "connector": null, "users": [], "story_type": "user"}, {"name": "", "sequential_order": 2, "connector": "and", "users": [], "story_type": "user"}, {"name": "", "sequential_order": 3, "connector": "and", "users": [], "story_type": "user"}]}, {"type": "or", "connector": "or", "sequential_order": 3, "stories": [{"name": "", "sequential_order": 1, "connector": null, "users": [], "story_type": "user"}]}]}], "stories": []}]}, "knowledge_graph_config": {"name": "build_story_graph_outline", "path": "docs/stories/", "template": "story-graph-outline.json", "output": "story-graph.json"}, "template_path": "C:\\dev\\augmented-teams\\agile_bot\\bots\\story_bot\\behaviors\\1_shape\\2_content\\1_knowledge_graph\\story-graph-outline.json", "config_path": "C:\\dev\\augmented-teams\\agile_bot\\bots\\story_bot\\behaviors\\1_shape\\2_content\\1_knowledge_graph\\build_story_graph_outline.json", "validation_rules": [{"rule_file": "apply_7_plus_minus_2_hierarchy.json", "rule_content": {"description": "Apply 7\u00b12 rule for hierarchy: epics contain 4-9 sub-epics, sub-epics contain 4-9 stories. Split when exceeding, merge when below minimum.", "examples": [{"do": {"description": "Maintain hierarchy within the 7\u00b12 cognitive limit range", "content": ["(E) Epic: Contains 4-9 sub-epics", "  - Split into additional Sub-Epics when > 9 sub-epics", "  - Merge with another epic when < 4 sub-epics", "(E) Sub-Epic: Contains 4-9 stories", "  - Split into 2 sub-epics when > 9 stories", "  - Merge with another sub-epic when < 4 stories", "(S) Story: Contains 2-9 acceptance criteria", "  - Split into 2 stories when > 9 AC", "  - Merge with another story when < 2 AC (single AC stories are too small)", "Apply 7\u00b12 cognitive limit principle (optimal range: 5-9, acceptable: 4-9)", "", "Example:", "(E) Manage Orders (10 sub-epics \u2192 SPLIT)", "  and (E) Manage Customer Orders (6 stories) \u2713", "  and (E) Manage Order Fulfillment (4 stories) \u2713", "", "(E) Place Order (12 stories \u2192 SPLIT)", "  and (S) Initiate Order (6 AC) \u2713", "  and (S) Complete Order (6 AC) \u2713", "", "(S) Validate Payment (11 AC \u2192 SPLIT)", "  and (AC) Check Payment Method (5 steps) \u2713", "  and (AC) Process Payment Transaction (6 steps) \u2713"]}, "dont": {"description": "Don't exceed thresholds or create items below minimum", "content": ["Create epics with > 9 sub-epics (use additional Sub-Epics instead)", "Create sub-epics with > 9 stories (split the sub-epic)", "Create stories with > 9 acceptance criteria (split the story)", "Create very small stories with < 2 AC (merge with related story)", "Ignore sizing thresholds during shaping, discovery, or exploration", "", "Wrong Examples:", "- (E) Epic with 15 sub-epics (too many, use additional Sub-Epics)", "- (E) Sub-Epic with 15 stories (too many, split sub-epic)", "- (S) Story with 15 AC (too many, split story)", "- (S) Story with 1 AC (too small, merge with related story)"]}}]}}, {"rule_file": "avoid_noun_redundancy.json", "rule_content": {"description": "When shaping stories, avoid noun redundancy in domain and concept names", "context": "when shaping stories", "examples": [{"do": {"description": "INTEGRATE first: nest related capabilities under one domain", "content": ["INTEGRATE first: nest related capabilities under one domain (90% of cases)", "Only then rename: use distinct nouns ONLY when integration doesn't make sense", "Test for uniqueness: Can you remove the qualifier and still know what it is?", "Use subject-area nouns when domains are genuinely separate", "Only when integration truly doesn't make sense"]}, "dont": {"description": "Don't rename without considering integration", "content": ["Don't rename without considering integration (this hides the real issue)", "Wrong: Repeat same noun with different prefixes: X Animation, Y Animation, Z Animation", "Don't use vague qualifiers to avoid integration", "Wrong: Animation 1, Animation System", "Don't create parallel domains that should be nested", "Wrong: Integrate related concepts rather than creating redundant structures"]}}]}}, {"rule_file": "avoid_technical_implementation_language.json", "rule_content": {"description": "When shaping stories, avoid technical implementation language in user-facing story elements", "context": "when shaping stories", "do": {"examples": [{"description": "Use business language in user-facing elements", "content": ["Customer places order, User views profile, Admin approves request"]}, {"description": "Focus on what user experiences, not how it's implemented", "content": ["Story describes user experience, not technical implementation"]}]}, "dont": {"examples": [{"description": "Don't use development task language", "content": ["implement, create, refactor, optimize, fix, build, set up"]}, {"description": "Don't use technical implementation details", "content": ["query database, call API, update table"]}, {"description": "Don't focus on delivery or development tasks", "content": ["Implement order system, Create database schema, Set up API endpoints"]}, {"description": "Don't focus on system internals", "content": ["Optimize query performance, Refactor authentication code, Update configuration"]}]}}}, {"rule_file": "avoid_technical_stories.json", "rule_content": {"description": "Technical stories represent implementation tasks that do not describe system behavior. They are normally avoided in favor of user stories and system stories. When technical stories are necessary, they should be marked with story_type: 'technical' and kept minimal.", "do": {"examples": [{"description": "Prefer user stories and system stories over technical stories", "content": ["Instead of 'Set up database schema', use 'Store user data' (user story)", "Instead of 'Create API endpoint', use 'Expose user data via API' (system story)", "Instead of 'Write unit tests', use 'Verify story behavior' (user story)"]}, {"description": "When technical stories are necessary, mark with story_type: 'technical'", "content": ["Story: 'Migrate legacy data format' with story_type: 'technical'", "Story: 'Refactor authentication module' with story_type: 'technical'", "Story: 'Update dependency versions' with story_type: 'technical'"]}, {"description": "Keep technical stories minimal and focused", "content": ["Technical stories should be rare exceptions", "Technical stories should still follow Verb-Noun format", "Technical stories should be clearly justified"]}]}, "dont": {"examples": [{"description": "Don't create technical stories for normal development work", "content": ["Avoid: 'Write code', 'Create class', 'Add method'", "Avoid: 'Set up CI/CD', 'Configure database', 'Install package'", "These are implementation details, not stories"]}, {"description": "Don't use technical stories to describe system behavior", "content": ["Use system stories for system-to-system behavior", "Use user stories for user-facing behavior", "Technical stories are for unavoidable implementation tasks only"]}]}}}, {"rule_file": "balance_fine_grained_testable_stories.json", "rule_content": {"description": "Balance fine-grained stories with testable and valuable independent units. Stories must deliver value and be independently testable.", "examples": [{"do": {"description": "Create stories that are complete interactions with value", "content": ["Create stories that are complete interactions with value", "Example: Customer places order (complete interaction, testable, valuable)", "Balance fine-grained stories with testable/valuable stories", "Ensure stories are fine-grained enough to enable frequent feedback", "Ensure stories are grouped into meaningful chunks for high quality feedback", "Stories that deliver measurable value independently"]}, "dont": {"description": "Avoid stories that are too small or too large", "content": ["Avoid stories that are too small and have no value alone", "Don't create stories that are too fine-grained without being testable or valuable", "Don't create stories that are too large to be testable or deliverable quickly", "", "Wrong Examples:", "- Add order button (too fine-grained, no value alone)", "- Change button color (too fine-grained, no value)", "- Customer places order and views history and updates profile (too large, multiple flows)"]}}]}}, {"rule_file": "create_lightweight_precise_docs.json", "rule_content": {"description": "Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.", "examples": [{"do": {"description": "Create lightweight but precise documentation during shaping", "content": ["Balance fine-grained stories with testable/valuable stories", "Ensure stories are fine-grained enough to enable frequent feedback", "Ensure stories are grouped into meaningful chunks for high quality feedback", "Validate that a business expert can understand the language of most of the stories", "Focus the language on the business domain", "Create lightweight but precise documentation", "Focus on structure and scope, not detailed specifications", "Make the map easy to walk through (it tells a story)", "", "Example:", "(E) Manage Orders", "  and (E) Place Order", "    and (S) Customer --> places order", "(Shows hierarchy and structure, not detailed specs)"]}, "dont": {"description": "Don't over-elaborate or add detailed specifications during shaping", "content": ["Create stories that are too fine-grained without being testable or valuable", "Create stories that are too large to be testable or deliverable quickly", "Add detailed technical specifications during shaping phase", "Over-elaborate story mapping during shaping", "", "Wrong Example:", "(E) Manage Orders", "  and (E) Place Order", "    and (S) Customer --> places order", "  \u2192 Detailed API specs, database schema, UI mockups", "(Too much detail for shaping phase)"]}}]}}, {"rule_file": "discover_relationships_from_story_map.json", "rule_content": {"description": "Domain Discovery determines relationships and responsibilities between core domain objects by walking through the story map, then suggests story refinements to rebuild the story map to complement the domain model.", "examples": [{"do": {"description": "Extract keywords from story map and determine relationships and responsibilities", "content": "Go through all stories in increment scope, extract keywords from story titles/descriptions/acceptance criteria, ask clarifying questions for each keyword, map relationships with multiplicities, document responsibilities"}, "dont": {"description": "Don't skip keyword identification or build domain model without story map analysis", "content": "Skip going through stories, ignore keywords in acceptance criteria, build domain model without asking what keywords mean, use technical terms instead of domain terms"}}]}}, {"rule_file": "enforce_behavioral_journey_flow.json", "rule_content": {"description": "When shaping stories, CRITICAL: Stories must show user/system journey flow, not just list operations. Stories must include context (when/why actions happen) and connect logically. Order by user journey, not technical sequential_order.", "context": "when shaping stories", "examples": [{"do": {"description": "Show user/system journey with context and flow", "content": ["Stories must show WHEN and WHY actions happen, not just WHAT", "Story maps must show logical flow: Initialize \u2192 Validate \u2192 Process \u2192 Confirm \u2192 Complete", "Each story must connect to previous/next stories in the journey", "Order stories by user journey flow, not by technical sequential_order", "", "Correct Examples (with journey context - Payment Domain):", "(E) Process Payment", "  and (E) Process Card Payment", "    and (S) User --> invokes process payment command", "    and (S) System --> validates payment details", "    and (S) System --> authorizes payment", "    and (S) System --> processes payment transaction", "    and (S) System --> confirms payment and sends notification", "", "(E) Refund Payment", "  and (E) Process Refund", "    and (S) User --> invokes refund payment command", "    and (S) System --> validates refund eligibility", "    and (S) System --> processes refund transaction", "    and (S) System --> confirms refund and sends notification", "", "(E) Process Payment", "  and (E) Validate Payment", "    and (S) User --> submits payment request", "    and (S) System --> validates card number", "    and (S) System --> validates amount", "    and (S) System --> validates currency", "    and (S) System --> returns validation result", "", "Note: Individual stories like 'Authorize Payment with Processor' are correct story format (verb-noun, specific), but they need to be part of a journey. Stories should NOT include actors in the name (actors are documented separately).", "", "Correct Individual Stories (but need journey context):", "- 'Authorize Payment with Processor' (correct story format, but needs: when? why? what happens next?)", "- 'Validate Payment Details' (correct story format, but needs: when? why? what triggers this?)", "- 'Process Payment Transaction' (correct story format, but needs: when? why? what happens before/after?)", "", "Journey Flow Requirements:", "- Start with initialization/entry point", "- Show logical progression through operations", "- Include error handling and alternative paths", "- End with completion/save operations", "- Connect stories logically (this leads to that)"]}, "dont": {"description": "Don't create isolated sets of functions that don't make sense linearly", "content": ["Don't group unrelated operations together that don't form a logical journey", "Don't create story maps with random functions that have no linear relationship", "Don't mix unrelated operations from different domains or contexts", "", "Wrong Examples (isolated sets of functions, no linear sense - Payment Domain):", "(E) Payment Operations", "  and (E) Process Payment", "  and (E) Generate Invoice", "  and (E) Send Email", "  and (E) Update Inventory", "  and (E) Calculate Tax", "(unrelated operations, no linear flow - why does email come after payment? why inventory? no journey)", "", "(E) Payment System", "  and (E) Authorize Payment", "  and (E) Create User Account", "  and (E) Process Refund", "  and (E) Generate Report", "  and (E) Delete Transaction", "(random operations, no logical sequence - account creation doesn't follow authorization, deletion doesn't follow processing)", "", "(E) Payment Flow", "  and (S) System --> validates payment", "  and (S) System --> sends notification", "  and (S) System --> authorizes payment", "  and (S) System --> updates database", "  and (S) System --> processes payment", "(wrong order, no linear sense - notification before authorization? database update before processing?)", "", "What Makes It NOT a Linear Journey:", "- Unrelated operations grouped together (payment + inventory + email + tax - why together?)", "- Operations from different contexts mixed (payment + user account + reporting - different domains)", "- No logical sequence (why does X come before Y? no reason)", "- Operations can be in any order (no dependencies, no flow)", "- Random collection of functions (like a function library, not a journey)", "- No user/system goal that connects them (what are we trying to accomplish?)"]}}]}}, {"rule_file": "enforce_functional_accomplishment.json", "rule_content": {"description": "CRITICAL: Stories must represent complete functional accomplishments, not data access operations or implementation steps. Stories must deliver value independently.", "examples": [{"do": {"description": "Create stories that accomplish complete functions", "content": ["Stories must represent complete functional accomplishments", "Stories must deliver value independently (INVEST principle)", "Stories must show end-to-end flow, not just data access", "", "Correct Examples (complete functional accomplishments):", "- 'User loads story graph and system displays epics in diagram' (complete: load + display = accomplishment)", "- 'Developer edits epic name and system updates diagram' (complete: edit + update = accomplishment)", "- 'User requests render and system generates DrawIO file' (complete: request + generate = accomplishment)", "- 'CLI invokes render command and system saves outline diagram' (complete: invoke + save = accomplishment)", "", "Functional Accomplishment Requirements:", "- Story must accomplish something meaningful for user/system", "- Story must be independently valuable (can be tested/delivered alone)", "- Story must show complete flow (start \u2192 process \u2192 outcome)", "- Story must have clear acceptance criteria (how do we know it's done?)"]}, "dont": {"description": "Don't create stories that are just data access or implementation steps", "content": ["Don't create stories that are just data access operations", "Don't create stories that are implementation steps without outcomes", "Don't create stories that aren't independently valuable", "", "Wrong Examples (not complete accomplishments):", "- 'Read All Epics from Diagram' (data access - not accomplishment, what happens with the data?)", "- 'Load All Features In Graph Epic' (data access - not accomplishment)", "- 'Serialize Components to JSON' (implementation step - not accomplishment, part of what story?)", "- 'Convert Diagram to StoryGraph Format' (implementation step - not accomplishment)", "- 'Calculate Component Positions' (implementation step - not accomplishment)", "", "Data Access/Implementation Indicators (REJECT as stories):", "- Just reads/loads data without using it", "- Just converts/formats data without purpose", "- Just calculates/computes without outcome", "- Just serializes/saves without context", "", "These should be STEPS within stories, not stories themselves:", "- Step: 'System reads epics from diagram' (within story: 'User views story map and system displays epics')", "- Step: 'System serializes components' (within story: 'User saves story graph and system writes JSON file')", "- Step: 'System calculates positions' (within story: 'User requests render and system generates positioned diagram')", "", "Instead, ask:", "- What does the user/system accomplish with this?", "- Is this independently valuable?", "- Can this be tested/delivered alone?", "- What's the complete flow from start to finish?"]}}]}}, {"rule_file": "enforce_specificity_in_stories.json", "rule_content": {"description": "CRITICAL: Stories must be specific about what, when, why, and who. Generic operations like 'Add Sub-Epic' or 'Read Epics' are insufficient - stories must include context and specificity.", "examples": [{"do": {"description": "Create specific stories with full context", "content": ["Stories must be specific about what, when, why, and who", "Stories must include context: when does it happen? why? what triggers it?", "Stories must specify actors, objects, and outcomes clearly", "", "Correct Examples (specific with context - Payment Domain):", "- 'User processes payment for order #12345 with amount $50.00 when customer completes checkout' (specific: user, order ID, amount, context)", "- 'Merchant invokes refund command from API and system reverses payment transaction' (specific: merchant, API, command, outcome)", "- 'System validates payment card number 4111-1111-1111-1111 when user submits payment form' (specific: system, card number, trigger)", "- 'User clicks Process Payment button and system prompts for payment method selection' (specific: user, action, UI element, system response)", "", "Specificity Requirements:", "- WHO: Specific actor (User, Merchant, Customer, System, PaymentProcessor, API)", "- WHAT: Specific action and object (processes payment for order #12345 with amount $50.00)", "- WHEN: Specific trigger/context (when customer completes checkout, when user submits payment form)", "- WHY: Purpose in journey (to complete purchase transaction, to reverse payment error)", "- OUTCOME: Specific result (payment processed, transaction ID returned, notification sent)"]}, "dont": {"description": "Don't create generic stories without context", "content": ["Don't create generic operations without specificity", "Don't omit context about when/why actions happen", "Don't use vague descriptions without details", "", "Wrong Examples (generic without context - Payment Domain):", "- 'Process Payment' (which payment? for which order? when? why?)", "- 'Authorize Payment' (which payment? with which card? when? why? what happens next?)", "- 'Exposes Payment API' (which endpoints? to whom? when? why?)", "- 'Refund Payment' (which payment? for which reason? when? why?)", "", "Generic Indicators (REJECT or require more specificity):", "- Single verb + noun without context: 'Process Payment', 'Authorize Payment', 'Refund Payment'", "- No specific objects: 'Process Payment' (which payment? which order?)", "- No context: 'Authorize Payment' (when? why? what triggers this?)", "- No outcome: 'Authorize Payment' (what happens with the authorization result?)", "", "Instead, ask:", "- Which specific object? (payment ID, order number, transaction ID, card number)", "- When does this happen? (trigger, context, user action - when customer completes checkout, when merchant requests refund)", "- Why does this happen? (purpose, user need, journey step - to complete purchase, to reverse error)", "- What's the outcome? (result, system response, user experience - payment processed, transaction ID returned, notification sent)"]}}]}}, {"rule_file": "establish_spine_vs_optional_enhanced_behavior.json", "rule_content": {"description": "Establish mandatory spine stories vs optional/enhanced behavior stories. When mapping stories, carefully distinguish between sequential spine (essential path) and optional paths, alternate routes, or additional functionality that is not strictly essential. Mandatory stories form the sequential spine (story AND story AND story). Optional stories are alternatives or enhancements (story OR story) that branch from the spine and can return to it. Sequential stories form the mandatory flow; optional stories are alternatives, enhancements, or non-essential sub-epics.", "examples": [{"do": {"description": "Identify the essential spine first", "content": ["Start by identifying the minimal essential path that delivers core value", "The spine represents the mandatory sequence: Story1 AND Story2 AND Story3", "Spine stories get sequential_order numbers (1, 2, 3, etc.)", "Spine stories are required for the sub-epic to deliver its core purpose", "Ask: 'What is the minimum path to deliver value?'", "Establish the mandatory spine before identifying optional/enhanced behaviors", "Explicitly distinguish between spine (mandatory) and optional/enhanced behaviors"]}, "dont": {"description": "Don't mark everything as sequential", "content": ["Don't assign sequential_order to all stories when some are optional", "Don't treat alternate routes as part of the spine", "Don't include enhancements in the mandatory sequential flow", "Don't confuse 'nice to have' with 'must have'", "Don't mark all stories as mandatory when some are alternatives or enhancements", "Don't fail to establish the spine before adding optional/enhanced behaviors"]}}, {"do": {"description": "Mark optional paths clearly", "content": ["Optional stories branch from or enhance the spine but are not required", "Mark optional stories with 'optional: true' in the story structure", "Optional stories may have sequential_order if they're part of an alternative flow (e.g., 2.1, 3.1, etc.)", "Optional stories represent: alternate routes, enhancements, nice-to-have sub-epics", "Ask: 'Can the sub-epic deliver value without this story?'", "Optional/enhanced stories can return to the spine after completion", "Sort optional/enhanced stories by priority of delivery within the same sub-epic"]}, "dont": {"description": "Don't omit optional markers", "content": ["Don't leave optional stories unmarked - be explicit", "Don't assume all stories in a sub-epic are mandatory", "Don't mix optional and mandatory without clear distinction", "Don't fail to identify the spine before adding optional paths", "Don't omit the optional marker - be explicit about spine vs optional/enhanced behaviors", "Don't create sub-epics where every story is mandatory when alternatives or enhancements exist"]}}, {"do": {"description": "Distinguish types of optional paths with concrete examples", "content": ["Spine (all stories with and), then OR optional branch (all stories with and), then OR enhanced (all stories with and):", "", "Correct Example:", "Spine (all stories with and):", "  (S) User --> creates account", "  and (S) User --> logs in", "  and (S) User --> views dashboard", "OR optional branch (all stories with and):", "  (S) User --> signs in with social media (optional)", "  and (S) User --> signs in with email (optional)", "OR enhanced (all stories with and):", "  (S) User --> customizes dashboard (enhanced)", "  and (S) User --> shares dashboard (enhanced)"]}, "dont": {"description": "Wrong mapping examples", "content": ["Wrong: All stories marked mandatory when some are clearly alternatives or enhancements", "  and (S) User --> creates account (1)", "  and (S) User --> logs in with email (2)", "  and (S) User --> logs in with social media (3) - social media should be optional", "", "Wrong: No distinction between essential path and optional sub-epics", "  and (S) User --> views dashboard (1)", "  and (S) User --> customizes dashboard (2)", "  and (S) User --> shares dashboard (3) - customization and sharing should be optional", "", "Wrong: Missing optional markers on alternative flows or enhanced behaviors", "Wrong: Optional/enhanced stories not sorted by priority", "Wrong: No clear spine established before adding optional behaviors"]}}]}}, {"rule_file": "extract_story_map_checklist.json", "rule_content": {"description": "Quick checklist for extracting story maps from code. Follow this process step-by-step.", "steps": [{"step": 1, "title": "Find Outermost Layer and Entry Points", "checklist": ["Locate CLI commands (main(), argparse, command handlers)", "Locate UI entry points (routes, event handlers, button clicks)", "Locate MCP server tool definitions (tool names, parameters)", "Locate API contracts (REST endpoints, GraphQL, WSDL)", "Locate WebSocket handlers, message queues, event listeners", "Locate acceptance tests (end-to-end, integration, BDD/Gherkin)", "Document all entry points with their parameters and return values"]}, {"step": 2, "title": "Analyze Operations and Domain Concepts", "checklist": ["List all operations from entry points (what can be invoked?)", "Identify MAJOR domain concepts (high-level entities)", "Identify MINOR domain concepts (supporting entities)", "Identify relationships between concepts", "Document operation names, parameters, return values", "Document concept names, properties, relationships"]}, {"step": 3, "title": "Create Epics Based on Higher-Order Goals", "checklist": ["Group operations by higher-order goals (what is user/system trying to accomplish?)", "Create epics from goals, not from implementation structure", "Each epic represents a major capability or lifecycle stage", "Validate: Epic name describes a goal, not a technical operation"]}, {"step": 4, "title": "Create Sub-Epics Based on Distinct Behaviors", "checklist": ["For each epic, identify distinct behaviors (different ways to accomplish goal)", "Group behaviors into sub-epics (different types, modes, contexts)", "Each sub-epic represents a distinct path or scenario", "Validate: Sub-epic name describes a behavior, not a technical mechanism"]}, {"step": 5, "title": "Identify Distinct Behaviors from Tests and Code Flow", "checklist": ["Trace through acceptance tests: what happens step by step?", "Trace through CLI commands: what's the execution flow?", "Trace through MCP tool calls: what's the sequence?", "Identify distinct behaviors at each step", "Document typical execution order", "Document error handling and alternative paths"]}, {"step": 6, "title": "Lay Out Story Journey from End-to-End Flow", "checklist": ["Start with entry point (how does user/system initiate?)", "Follow code flow through operations (what happens step by step?)", "Include error handling (what happens when things go wrong?)", "End with completion (how does it finish?)", "For each story, include:", "  - WHEN: trigger, condition, user action", "  - WHY: purpose, user need, system requirement", "  - OUTCOME: result, state change, user experience", "  - ACTOR: who performs the action", "Validate: Stories show complete journey, not isolated operations"]}, {"step": 7, "title": "Validate Story Map Quality", "checklist": ["Stories show user/system journey (not just list operations)", "Stories have context (when/why/outcome)", "Stories are specific (not generic like 'Add Sub-Epic')", "Stories represent complete accomplishments (not data access)", "Implementation details are steps, not stories", "Order follows user journey, not technical sequential_order", "Epics/sub-epics based on goals, not implementation structure"]}], "common_mistakes": ["Starting with internal classes instead of entry points", "Creating epics from class structure instead of goals", "Creating stories from every method call", "Missing context (when/why) in stories", "Making implementation details into stories", "Ordering by technical sequential_order instead of user journey", "Generic stories without specificity"]}}, {"rule_file": "extract_story_map_from_code.json", "rule_content": {"description": "CRITICAL: When creating story maps from code, analyze the outermost layer showing end-to-end journey. Locate acceptance tests, human code engagement points (CLI/UI), MCP server definitions, WSDL, API contracts. Analyze operations and domain for major/minor concepts. Create epics/sub-epics based on higher-order goals. Look at distinct behaviors and typical execution order to lay out story journey.", "examples": [{"do": {"description": "Find outermost layer and entry points", "content": ["Start with the OUTERMOST LAYER showing end-to-end journey", "Locate all HUMAN CODE ENGAGEMENT points:", "  - CLI commands and entry points (main(), command handlers)", "  - UI entry points (web routes, event handlers, button clicks)", "  - MCP server tool definitions (tool names, parameters, descriptions)", "  - API contracts (REST endpoints, GraphQL queries, WSDL operations)", "  - WebSocket handlers, message queues, event listeners", "", "Locate ACCEPTANCE TESTS:", "  - End-to-end tests that show complete user journeys", "  - Integration tests that show system-to-system flows", "  - Test scenarios that describe 'when X, then Y' behaviors", "  - BDD/Gherkin tests with Given-When-Then structure", "", "Example Entry Points to Find:", "- CLI: 'python -m story_io.story_io_cli render-outline --story-graph file.json'", "- MCP: Tool 'render_outline' with parameters 'story_graph_path', 'output_path'", "- API: POST /api/story-graph/render with body {storyGraph, outputFormat}", "- UI: Button 'Render Outline' that triggers render operation", "- Test: 'test_render_outline_from_json' that shows complete flow"]}, "dont": {"description": "Don't start with internal implementation details", "content": ["Don't start with internal classes or helper functions", "Don't start with data structures or domain models", "Don't start with utility functions or low-level operations", "", "Wrong Starting Points:", "- Internal class: 'StoryIODiagram.load_from_json()' (implementation detail)", "- Helper function: 'parse_story_graph()' (internal mechanism)", "- Data structure: 'Epic' class definition (domain model, not entry point)", "", "These are important but come AFTER identifying the journey"]}}, {"do": {"description": "Analyze operations and domain for major/minor concepts", "content": ["Analyze OPERATIONS from entry points:", "  - What operations are exposed? (render, sync, search, edit, save)", "  - What are the operation names? (render-outline, sync-increments, search-stories)", "  - What parameters do they take? (story_graph_path, output_path, query)", "  - What do they return? (DrawIO file, JSON report, search results)", "", "Analyze DOMAIN CONCEPTS:", "  - MAJOR CONCEPTS: High-level domain entities (StoryGraph, Diagram, Epic, Sub-Epic, Story)", "  - MINOR CONCEPTS: Supporting entities (Position, Boundary, User, Increment)", "  - OPERATIONS: Actions on concepts (Load, Read, Edit, Render, Synchronize, Search, Save)", "  - RELATIONSHIPS: How concepts relate (Epic contains Sub-Epics, Sub-Epic contains Stories)", "", "Example Analysis (Story-IO Domain):", "- Operations: render-outline, render-increments, sync-outline, sync-increments, search, add-user, merge", "- Major Concepts: StoryGraph (main entity), Diagram (visual representation), Epic/Sub-Epic/Story (hierarchy)", "- Minor Concepts: Position (2D coordinate), Boundary (rectangular area), User (story actor), Increment (priority grouping)", "- Relationships: StoryGraph contains Epics, Epic contains Sub-Epics, Sub-Epic contains Stories", "", "Example Analysis (Payment Domain):", "- Operations: process-payment, refund-payment", "- Major Concepts: Payment (main entity), Transaction (financial transaction), Card (payment method), Refund (reversal)", "- Minor Concepts: Amount (monetary value), Currency (USD, EUR), Status (pending, approved, declined), PaymentMethod (card, bank transfer)", "- Relationships: Payment contains Transaction, Payment uses Card, Payment can have Refund, Transaction has Status"]}, "dont": {"description": "Don't confuse implementation details with domain concepts", "content": ["Don't treat implementation classes as domain concepts", "Don't treat utility functions as operations", "Don't treat data structures as domain entities", "", "Wrong Analysis:", "- Implementation class: 'StoryIORenderer' (implementation detail, not domain concept)", "- Utility function: 'calculate_position()' (implementation detail, not operation)", "- Data structure: 'dict' or 'list' (implementation detail, not domain concept)", "", "Focus on WHAT the system does (domain), not HOW it does it (implementation)"]}}, {"do": {"description": "Create epics/sub-epics based on higher-order goals", "content": ["Group operations into EPICS based on HIGHER-ORDER GOALS:", "  - What is the user/system trying to accomplish?", "  - What are the major capabilities?", "  - What are the lifecycle stages?", "", "Example Epic Creation from Operations (Story-IO Domain):", "- Operations: render-outline, render-increments, render-exploration", "- Higher-Order Goal: 'Render StoryGraph' (user wants to visualize story map)", "- Epic: 'Render StoryGraph'", "", "- Operations: sync-outline, sync-increments, generate-sync-report, merge", "- Higher-Order Goal: 'Synchronize StoryGraph' (user wants to sync between formats)", "- Epic: 'Synchronize StoryGraph'", "", "Example Epic Creation from Operations (Payment Domain):", "- Operations: process-payment, process_payment, POST /api/payments/process", "- Higher-Order Goal: 'Process Payment' (user wants to process a payment transaction)", "- Epic: 'Process Payment'", "", "- Operations: refund-payment, refund_payment, POST /api/payments/refund", "- Higher-Order Goal: 'Refund Payment' (user wants to reverse a payment)", "- Epic: 'Refund Payment'", "", "Group operations into SUB-EPICS based on DISTINCT BEHAVIORS:", "  - What are the different ways to accomplish the epic goal?", "  - What are the different types or modes?", "  - What are the different contexts or scenarios?", "", "Example Sub-Epic Creation (Story-IO Domain):", "- Epic: 'Render StoryGraph'", "- Distinct Behaviors: Render outline (basic), Render increments (with priorities), Render exploration (with acceptance criteria)", "- Sub-Epics: 'Render Outline', 'Render Increments', 'Render Exploration'", "", "- Epic: 'Synchronize StoryGraph'", "- Distinct Behaviors: Sync outline structure, Sync increments, Generate comparison report, Merge graphs", "- Sub-Epics: 'Synchronize Outline', 'Synchronize Increments', 'Generate Sync Report', 'Merge StoryGraphs'", "", "Example Sub-Epic Creation (Payment Domain):", "- Epic: 'Process Payment'", "- Distinct Behaviors: Validate payment (required), Authorize payment (required), Process with card (common), Process with bank transfer (alternative), Process with wallet (alternative), Confirm payment (required)", "- Sub-Epics: 'Validate Payment', 'Authorize Payment', 'Process Card Payment', 'Process Bank Transfer', 'Process Wallet Payment', 'Confirm Payment'", "", "- Epic: 'Refund Payment'", "- Distinct Behaviors: Validate refund eligibility, Process refund, Confirm refund", "- Sub-Epics: 'Validate Refund', 'Process Refund', 'Confirm Refund'"]}, "dont": {"description": "Don't create epics/sub-epics from implementation structure", "content": ["Don't create epics based on class structure (StoryIODiagram, DrawIORenderer, PaymentProcessor, etc.)", "Don't create sub-epics based on method names (load_json, parse_xml, charge_card, etc.)", "Don't create epics/sub-epics from technical layers (data layer, service layer, etc.)", "", "Wrong Epic Creation:", "- Based on class: 'StoryIODiagram Operations' (implementation structure)", "- Based on method: 'JSON Loading' (technical mechanism)", "- Based on layer: 'Data Access Layer' (technical architecture)", "", "Focus on USER/SYSTEM GOALS, not technical structure"]}}, {"do": {"description": "Look at distinct behaviors and typical execution order", "content": ["Analyze DISTINCT BEHAVIORS from acceptance tests and code flow:", "  - What are the different scenarios?", "  - What are the different paths through the code?", "  - What are the different user actions?", "", "Example Behavior Analysis (Story-IO Domain):", "- Test: 'test_render_outline_from_json' shows: Load JSON \u2192 Parse \u2192 Generate XML \u2192 Calculate Positions \u2192 Apply Styles \u2192 Save", "- Distinct Behaviors: Load, Parse, Generate, Calculate, Apply, Save", "- These become STORIES in the journey", "", "Example Behavior Analysis (Payment Domain):", "- Test: 'test_process_payment_success' shows: Invoke \u2192 Validate \u2192 Authorize \u2192 Process \u2192 Confirm", "- Distinct Behaviors: Invoke (entry point), Validate (check input), Authorize (check funds/fraud), Process (execute transaction), Confirm (complete and notify)", "- These become STORIES in the journey", "", "Determine TYPICAL EXECUTION ORDER from code flow:", "  - Trace through acceptance tests: what happens first, second, third?", "  - Trace through CLI commands: what's the flow?", "  - Trace through MCP tool calls: what's the sequence?", "  - Look at error handling: what are alternative paths?", "", "Example Execution Order Analysis (Story-IO Domain):", "- CLI: 'render-outline --story-graph file.json --output file.drawio'", "- Code Flow: Parse args \u2192 Load story graph \u2192 Create diagram \u2192 Render outline \u2192 Save file", "- Typical Order: 1. Parse arguments, 2. Load story graph, 3. Render outline, 4. Save file", "- Stories: 'Parses Command Arguments' \u2192 'Loads StoryGraph from JSON' \u2192 'Renders Outline to DrawIO' \u2192 'Saves DrawIO File'", "", "Example Execution Order Analysis (Payment Domain):", "- CLI: 'process-payment --payment-id 123 --amount 50.00'", "- Code Flow: Parse args \u2192 Validate payment \u2192 Authorize payment \u2192 Process payment \u2192 Confirm payment", "- Typical Order: 1. User invokes process payment, 2. System validates payment details, 3. System authorizes payment, 4. System processes payment, 5. System confirms payment", "- Stories: 'User invokes process payment command' \u2192 'System validates payment details' \u2192 'System authorizes payment with payment processor' \u2192 'System processes payment transaction' \u2192 'System confirms payment and sends notification'", "", "Create STORY JOURNEY from execution order:", "  - Start with entry point (CLI invocation, UI click, MCP tool call)", "  - Follow the code flow through operations", "  - Include error handling and alternative paths", "  - End with completion (save, return result, display)", "", "Example Story Journey (Story-IO Domain):", "- Entry: 'User invokes render-outline command from CLI'", "- Flow: 'CLI parses arguments' \u2192 'CLI loads story graph' \u2192 'CLI invokes render' \u2192 'System renders outline' \u2192 'System saves file'", "- Error: 'If file not found, CLI displays error message'", "- Completion: 'CLI returns success message'", "", "Example Story Journey (Payment Domain):", "- Entry: 'User invokes process payment command' (WHEN: user wants to charge customer, WHY: to complete purchase, OUTCOME: CLI/MCP/API receives request)", "- Flow: 'System validates payment details' (WHEN: after request received, WHY: to ensure payment can be processed, OUTCOME: details validated) \u2192 'System authorizes payment' (WHEN: after validation, WHY: to check funds/fraud, OUTCOME: payment authorized) \u2192 'System processes payment' (WHEN: after authorization, WHY: to execute transaction, OUTCOME: payment processed) \u2192 'System confirms payment' (WHEN: after processing, WHY: to notify user, OUTCOME: payment confirmed)", "- Error: 'If validation fails, System displays validation error' (WHEN: validation fails, WHY: to inform user, OUTCOME: error shown, process stops)", "- Completion: 'System returns transaction ID' (WHEN: after confirmation, WHY: to provide reference, OUTCOME: transaction ID returned)"]}, "dont": {"description": "Don't create stories from code structure or method calls", "content": ["Don't create stories from every method call in code", "Don't create stories from internal function calls", "Don't create stories from data structure operations", "", "Wrong Story Creation:", "- From method: 'StoryIODiagram.__init__()' (internal initialization)", "- From function: 'parse_json()' (internal parsing)", "- From operation: 'dict.get()' (data access, not behavior)", "- From method: 'PaymentProcessor.charge_card()' (internal implementation)", "", "Focus on USER/SYSTEM VISIBLE BEHAVIORS, not internal implementation"]}}, {"do": {"description": "Lay out story journey from end-to-end flow", "content": ["Create STORY JOURNEY that shows complete end-to-end flow:", "  - Start: How does user/system initiate? (CLI command, UI click, API call)", "  - Middle: What happens step by step? (parse, load, process, transform)", "  - End: How does it complete? (save, return, display, notify)", "", "Include CONTEXT for each story:", "  - WHEN does it happen? (trigger, condition, user action)", "  - WHY does it happen? (purpose, user need, system requirement)", "  - WHAT is the outcome? (result, state change, user experience)", "  - ACTOR: Who performs the action? (User, System, CLI, MCP, API, etc.)", "", "Example Complete Story Journey (Story-IO Domain):", "(E) Render StoryGraph", "  and (E) Render Outline", "    and (S) User --> invokes render-outline command from CLI", "    and (S) CLI --> parses command arguments", "    and (S) CLI --> loads story graph from JSON file", "    and (S) System --> renders outline to DrawIO format", "    and (S) System --> saves DrawIO file", "", "Example Complete Story Journey (Payment Domain):", "(E) Process Payment", "  and (E) Process Card Payment", "    and (S) User --> invokes process payment command", "    and (S) System --> validates payment details", "    and (S) System --> authorizes payment with payment processor", "    and (S) System --> processes payment transaction", "    and (S) System --> confirms payment and sends notification", "", "Include ERROR HANDLING and ALTERNATIVE PATHS:", "  - What happens when file not found?", "  - What happens when parsing fails?", "  - What happens when validation fails?", "  - What happens when authorization fails?", "", "Example Error Handling (Story-IO Domain):", "  and (S) CLI --> displays error message if story graph file not found", "", "Example Error Handling (Payment Domain):", "  and (S) System --> displays validation error if validation fails", "  and (S) System --> displays authorization declined message if authorization fails"]}, "dont": {"description": "Don't create isolated stories without journey context", "content": ["Don't create stories that are just operations without context", "Don't create stories that don't connect to a journey", "Don't create stories without when/why/outcome/actor", "", "Wrong Story Creation:", "- (S) System --> loads StoryGraph (no context: when? why? what happens next?)", "- (S) System --> parses JSON (no context: when? why? what's the outcome?)", "- (S) System --> saves file (no context: when? why? what triggers this?)", "- (S) System --> processes payment (no context: when? why? what's the outcome?)", "", "Every story must be part of a JOURNEY with CONTEXT (when/why/outcome/actor)"]}}]}}, {"rule_file": "focus_real_actions_on_domain_concepts.json", "rule_content": {"description": "When shaping stories, stories must describe REAL ACTIONS that users or other actors (even system or technical actors) can perform, not capabilities or structural descriptions. Organize by lifecycle flow (Load, Read, Edit, Render, Synchronize, Search, Save). CRITICAL: Actor names must NOT appear in Epic/Sub-Epic/Story names - names are Verb-Noun only.", "context": "when shaping stories", "examples": [{"do": {"description": "Use real actions - actor separate from name", "content": ["Stories describe actions: Load, Read, Add, Remove, Render, Search, Save", "Organize by lifecycle: Load \u2192 Read \u2192 Edit \u2192 Render \u2192 Synchronize \u2192 Search \u2192 Save", "Use Verb-Noun format for names: '[Verb] [Noun]' - NO ACTOR in name", "Focus on what users/code CAN DO, not what things ARE", "", "NAMING RULE - Actor NOT in Name:", "- Epic name: 'Places Order' (NOT 'Customer Places Order')", "- Sub-Epic name: 'Validates Payment' (NOT 'PaymentValidator Validates Payment')", "- Story name: 'Processes Order Items' (NOT 'OrderProcessor Processes Order Items')", "- Actor is documented separately, not in the name itself", "", "ACTORS for User/System Stories (normal stories):", "- Use human/system actors: User, Developer, System, Customer, Admin", "- Actor is implicit or documented separately from name", "- Examples: Epic 'Places Order' has actor: Customer", "- Examples: Sub-Epic 'Validates Payment' has actor: System", "", "ACTORS for Technical Stories (deep internal class-level interactions):", "- Domain concepts CAN be actors: OrderProcessor, PaymentValidator, InventoryManager, Cart, Product", "- Actor is documented separately, NOT in name", "- Examples: Epic 'Loads Order Data' has actor: OrderProcessor (technical)", "- Examples: Sub-Epic 'Updates Inventory' has actor: InventoryManager (technical)", "- Examples: Story 'Calculates Total' has actor: Cart (technical)", "- This is acceptable when documenting class-to-class interactions internally"]}, "dont": {"description": "Avoid capabilities, structural descriptions, passive states, and actors in names", "content": ["Don't use capability nouns or structural descriptions", "Don't describe what things ARE or CONTAIN", "Don't use passive states or properties as stories", "CRITICAL: Don't put actor in Epic/Sub-Epic/Story names", "", "Wrong Examples (capabilities/structure):", "- 'PaymentValidator Contains Validation Logic' (capability, not action)", "- 'OrderProcessor Tracks Order Count' (passive state, not action)", "- 'Cart Hierarchy Foundation' (structural description)", "- 'Domain Components Implementation' (capability)", "- 'Product Represents Item' (structural description)", "", "Wrong Examples (actor in name):", "- Epic: 'Customer Places Order' (actor in name - WRONG)", "- Sub-Epic: 'OrderProcessor Validates Payment' (actor in name - WRONG)", "- Sub-Epic: 'Cart Adds Product' (actor in name - WRONG)", "- Story: 'InventoryManager Updates Stock' (actor in name - WRONG)", "", "Correct Examples (actor NOT in name):", "- Epic: 'Places Order' (actor: Customer, documented separately)", "- Sub-Epic: 'Validates Payment' (actor: PaymentValidator, documented separately)", "- Sub-Epic: 'Adds Product' (actor: Cart, documented separately)", "- Story: 'Updates Stock' (actor: InventoryManager, documented separately)", "", "These are not actions users/code can perform - they describe structure or capabilities", "Instead ask: What can users/code DO with this domain concept?", "- Instead of 'Contains Logic' \u2192 'Generates XML' or 'Renders Diagram'", "- Instead of 'Tracks Count' \u2192 'Reads Count' or 'Updates Count'", "- Instead of 'Represents X' \u2192 'Creates X' or 'Loads X'"]}}]}}, {"rule_file": "focus_user_and_system_activities.json", "rule_content": {"description": "Focus story maps on both user AND system activities, not tasks. Stories should outline user and system behavior patterns.", "examples": [{"do": {"description": "Include both user and system activities in story descriptions", "content": ["User submits order, System validates payment", "Customer views products, System displays inventory", "Use user activity patterns: User submits, Customer places", "Use system activity patterns: System validates, System sends", "Focus stories on user interactions and how the system behaves as observed by users", "Example: Customer places order with payment details", "", "ACTOR SELECTION (documented separately, NOT in name):", "- For user/system stories: Actors are User, System, Developer, Customer, Admin (human/system actors)", "- For technical stories (deep internal class-level): Domain concepts can be actors (StoryIODiagram, DrawIORenderer, DrawIOSynchronizer, User, Increment, Component)", "- Technical stories document class-to-class interactions where domain concepts act as actors", "", "CRITICAL NAMING RULE:", "- Actor must NOT appear in Epic/Sub-Epic/Story name", "- Name format: '[Verb] [Noun]' only", "- Examples: 'Loads StoryGraph' (actor: StoryIODiagram, documented separately)", "- Examples: 'Adds Sub-Epic' (actor: Epic, documented separately)", "- Examples: 'Changes Parent' (actor: Component, documented separately)"]}, "dont": {"description": "Avoid task-oriented language that describes implementation", "content": ["Avoid task-oriented language that describes implementation", "Don't use task language for building or setting up", "Don't focus only on user activities (ignore system activities)", "Don't focus only on tasks (instead of activities)", "Don't use development task language: implement, create, refactor, optimize, fix, build, set up", "Don't use technical implementation details: query database, call API, update table", "", "Wrong Examples:", "- Only user activities: User submits order, User views products (missing system activities)", "- Only tasks: Implement order submission, Create payment validation (not activities)", "- Implement order submission, Create payment validation", "- Build product listing page, Set up inventory display"]}}]}}, {"rule_file": "identify_system_stories.json", "rule_content": {"description": "System stories capture system-to-system interactions that are not user-facing. They represent internal system behavior that crosses system boundaries (e.g., microservice to microservice, component to component). System stories should be identified and marked with story_type: 'system'.", "do": {"examples": [{"description": "Identify system-to-system interactions", "content": ["Storage Microservice validates payload from Local Mgmt System", "API Gateway routes request to Authentication Service", "Message Queue delivers event to Notification Service"]}, {"description": "Mark system stories with story_type: 'system'", "content": ["Story: 'Validate Payload' with story_type: 'system'", "Story: 'Route Request' with story_type: 'system'", "Story: 'Deliver Event' with story_type: 'system'"]}, {"description": "Use system stories for internal system behavior", "content": ["System stories represent behavior that happens between systems/components", "System stories are not directly visible to end users", "System stories enable user-facing stories to function"]}]}, "dont": {"examples": [{"description": "Don't mark user-facing stories as system stories", "content": ["User clicks button \u2192 NOT a system story", "User views dashboard \u2192 NOT a system story", "User submits form \u2192 NOT a system story"]}, {"description": "Don't confuse system stories with technical stories", "content": ["System stories = system-to-system behavior (dark blue in DrawIO)", "Technical stories = implementation tasks (black/white in DrawIO, normally avoided)"]}]}}}, {"rule_file": "maximize_integration_of_related_concepts.json", "rule_content": {"description": "When shaping stories, maximize integration of related concepts", "context": "when shaping stories", "examples": [{"do": {"description": "Group concepts that the user sees as one capability", "content": ["Group concepts that the user sees as one capability", "Nest implementation details under the sub-epic they serve", "Keep related data and operations together", "Eliminate artificial boundaries based on code organization"]}, "dont": {"description": "Don't separate related concepts", "content": ["Don't separate related concepts into different major sections", "Wrong: Split based on code layers (data, business, presentation)", "Don't duplicate related concepts across multiple sections", "Wrong: Create gaps that break the user's mental model"]}}]}}, {"rule_file": "place_domain_concepts_by_relevance.json", "rule_content": {"description": "When shaping stories, place domain concepts locally or globally based on relevance to one or multiple sub_epics", "context": "when shaping stories", "examples": [{"do": {"description": "Place domain concepts at the most specific level, favoring local placement", "content": ["Favor local placement: Place domain_concepts at the sub_epic level when they are relevant to only that sub_epic", "Think about the core: Consider core domain concepts that span multiple sub_epics - these should be placed at the parent epic/sub_epic level", "Elevate when shared: If a domain concept is used by multiple child sub_epics, elevate it to the parent level", "Start local, elevate if needed: Begin with local placement, but elevate if the concept is referenced by multiple sub_epics", "", "Correct Examples (Local Placement):", "- Sub-Epic 'Validates Payment' has domain_concept: 'Payment' (only used in this sub-epic)", "- Sub-Epic 'Processes Order' has domain_concept: 'Order' (only used in this sub-epic)", "- Sub-Epic 'Updates Inventory' has domain_concept: 'InventoryItem' (only used in this sub-epic)", "", "Correct Examples (Global Placement):", "- Epic 'Process Payment' has domain_concept: 'Payment' (used by multiple sub-epics: Validate Payment, Authorize Payment, Process Transaction)", "- Epic 'Manage Orders' has domain_concept: 'Order' (used by multiple sub-epics: Create Order, Update Order, Cancel Order)", "- Sub-Epic 'Order Management' has domain_concept: 'Customer' (used by multiple child sub-epics: Create Customer Order, Update Customer Order)"]}, "dont": {"description": "Don't place domain concepts at wrong levels or duplicate them unnecessarily", "content": ["Don't place domain concepts at epic level when they're only used in one sub-epic", "Wrong: Epic 'Payment System' has domain_concept: 'PaymentValidator' (only used in 'Validates Payment' sub-epic - should be local)", "Don't duplicate domain concepts at multiple levels", "Wrong: Both Epic and Sub-Epic have 'Payment' concept when it's only used in one sub-epic", "Don't place core domain concepts too locally if they're used across multiple epics", "Wrong: Core concept 'User' placed only in one sub-epic when it's used across multiple epics", "Don't ignore shared usage - if multiple sub-epics reference a concept, elevate it", "Wrong: 'Order' concept placed in each sub-epic separately when all sub-epics use it (should be at parent level)"]}}]}}, {"rule_file": "prevent_generic_capabilities.json", "rule_content": {"description": "CRITICAL: Stories must describe specific actions with actors, not generic capabilities. Reject stories that describe what system IS (capabilities) vs what system DOES (behaviors).", "examples": [{"do": {"description": "Use specific actions with actors and outcomes", "content": ["Stories must have specific actors performing specific actions", "Stories must describe what system DOES (behaviors), not what system IS (capabilities)", "Stories must have specific outcomes, not generic descriptions", "", "Correct Examples (specific behaviors with actors):", "- 'User invokes MCP tool and system routes to StoryIO handler' (specific: user, MCP tool, routing action)", "- 'Developer adds sub-epic Render Exploration to epic Render StoryGraph' (specific: developer, sub-epic name, epic name)", "- 'System loads story graph from JSON file when user requests render' (specific: system, load action, trigger)", "- 'CLI determines workspace root from current directory' (specific: CLI, determine action, source)", "", "Actor Requirements:", "- Every story must have an actor (User, System, Developer, CLI, StoryIODiagram, etc.)", "- Actor must be documented separately (not in name)", "- Actor must be specific (not generic 'Component' or 'System')", "- Actor must perform the action (not just be present)"]}, "dont": {"description": "Don't use generic capabilities or passive descriptions", "content": ["Don't describe what system IS (capabilities)", "Don't use generic action descriptions without actors", "Don't use passive states or properties as stories", "", "Wrong Examples (generic capabilities):", "- 'Exposes Tools' (capability - what tools? when? to whom? what happens?)", "- 'Provides Server Interface' (capability - what interface? when? why?)", "- 'Contains Validation Logic' (capability - not an action)", "- 'Tracks Order Count' (passive state - not an action)", "", "Capability Indicators (REJECT):", "- Describes what system IS: 'Exposes', 'Provides', 'Contains', 'Represents'", "- No specific actor or action", "- No specific outcome or trigger", "- Generic description without context", "", "Instead, ask:", "- Who performs this action? (actor)", "- When does this happen? (trigger/context)", "- What specific outcome occurs? (result)", "- Why does this happen? (purpose in journey)"]}}]}}, {"rule_file": "prevent_implementation_details_as_stories.json", "rule_content": {"description": "CRITICAL: Implementation operations (serialize, convert, calculate, generate XML, apply formatting) must be steps within stories, not stories themselves. Stories must focus on user/system outcomes, not technical mechanisms.", "examples": [{"do": {"description": "Keep implementation details as steps within stories", "content": ["Implementation operations must be steps within stories", "Stories must focus on user/system outcomes, not technical mechanisms", "Stories must describe what user/system experiences, not how it's implemented", "", "Correct Examples (outcomes, not mechanisms):", "- Story: 'User saves story graph and system writes JSON file' \u2192 Steps: 'System converts diagram to story graph format', 'System serializes components to JSON', 'System writes file'", "- Story: 'User requests render and system generates DrawIO diagram' \u2192 Steps: 'System generates DrawIO XML', 'System calculates component positions', 'System applies styles', 'System saves file'", "- Story: 'User edits epic and system updates diagram' \u2192 Steps: 'System updates epic data', 'System recalculates layout', 'System refreshes diagram'", "", "Story vs Step Distinction:", "- Story = User/system outcome (what they experience)", "- Step = Implementation detail (how it's done)", "- Story = Independently valuable (can be tested/delivered)", "- Step = Part of story (not independently valuable)"]}, "dont": {"description": "Don't make implementation operations into stories", "content": ["Don't create stories for implementation operations", "Don't expose technical mechanisms as user stories", "Don't break implementation steps into separate stories", "", "Wrong Examples (implementation details as stories):", "- 'Convert Diagram to StoryGraph Format' (implementation - should be step in 'Save StoryGraph' story)", "- 'Serialize Components to JSON' (implementation - should be step in 'Save StoryGraph' story)", "- 'Generate DrawIO XML from StoryGraph' (implementation - should be step in 'Render Outline' story)", "- 'Calculate Component Positions' (implementation - should be step in 'Render Outline' story)", "- 'Apply Component Styles' (implementation - should be step in 'Render Outline' story)", "- 'Save DrawIO XML to File' (implementation - should be step in 'Render Outline' story)", "", "Implementation Operation Indicators (REJECT as stories):", "- Serialize, deserialize, convert, transform, format", "- Calculate, compute, generate, create (technical artifacts)", "- Apply, set, configure (technical settings)", "- Save, write, store (without user context)", "", "These are implementation mechanisms, not user/system behaviors", "They should be steps within stories that describe outcomes", "", "Instead, ask:", "- What does the user/system experience? (story)", "- How is it implemented? (step within story)", "- What's the outcome? (story)", "- What's the mechanism? (step)"]}}]}}, {"rule_file": "refine_scope_to_functional_accomplishment.json", "rule_content": {"description": "Refine Scope to Functional Accomplishment", "examples": [{"do": {"description": "Focus on functional outcomes, not mechanisms", "content": ["Focus on functional outcomes, not mechanisms", "Frame domains by what they accomplish for users", "Ask about user enablement: What does this enable the user to do or understand?", "State the transformation or capability provided", "Be specific about the functional benefit"]}, "dont": {"description": "Don't frame domains by their technical implementation", "content": ["Don't frame domains by their technical implementation", "Wrong: Focus on 'how' before 'what'", "Don't use generic system capabilities as domain names", "Wrong: Describe mechanisms instead of outcomes"]}}]}}, {"rule_file": "size_stories_3_to_12_days.json", "rule_content": {"description": "Size stories to fall within 3-12 day effort range for effective planning and frequent delivery.", "examples": [{"do": {"description": "Create stories that represent complete flows within the effort range", "content": ["Create stories that represent complete flows within the effort range", "Example: Customer places order (complete flow, 3-5 days)", "Break/group stories so that most fall into a 3-12 day effort range", "Enable frequent feedback by decomposing the work into smaller items"]}, "dont": {"description": "Avoid stories that are too large or too small", "content": ["Avoid stories that are too large and span multiple weeks", "Don't arbitrarily decompose stories to a functional level, regardless of size", "", "Wrong Examples:", "- Order management system (too large, 20+ days)", "- Create stories that are too small without considering value"]}}]}}, {"rule_file": "story_map_code_approach.json", "rule_content": {"description": "Quick checklist for extracting story maps from code. Follow this process step-by-step.", "steps": [{"step": 1, "title": "Find Outermost Layer and Entry Points", "checklist": ["Locate CLI commands (main(), argparse, command handlers)", "Locate UI entry points (routes, event handlers, button clicks)", "Locate MCP server tool definitions (tool names, parameters)", "Locate API contracts (REST endpoints, GraphQL, WSDL)", "Locate WebSocket handlers, message queues, event listeners", "Locate acceptance tests (end-to-end, integration, BDD/Gherkin)", "Document all entry points with their parameters and return values"]}, {"step": 2, "title": "Analyze Operations and Domain Concepts", "checklist": ["List all operations from entry points (what can be invoked?)", "Identify MAJOR domain concepts (high-level entities)", "Identify MINOR domain concepts (supporting entities)", "Identify relationships between concepts", "Document operation names, parameters, return values", "Document concept names, properties, relationships"]}, {"step": 3, "title": "Create Epics Based on Higher-Order Goals", "checklist": ["Group operations by higher-order goals (what is user/system trying to accomplish?)", "Create epics from goals, not from implementation structure", "Each epic represents a major capability or lifecycle stage", "Validate: Epic name describes a goal, not a technical operation"]}, {"step": 4, "title": "Create Sub-Epics Based on Distinct Behaviors", "checklist": ["For each epic, identify distinct behaviors (different ways to accomplish goal)", "Group behaviors into sub-epics (different types, modes, contexts)", "Each sub-epic represents a distinct path or scenario", "Validate: Sub-epic name describes a behavior, not a technical mechanism"]}, {"step": 5, "title": "Identify Distinct Behaviors from Tests and Code Flow", "checklist": ["Trace through acceptance tests: what happens step by step?", "Trace through CLI commands: what's the execution flow?", "Trace through MCP tool calls: what's the sequence?", "Identify distinct behaviors at each step", "Document typical execution order", "Document error handling and alternative paths"]}, {"step": 6, "title": "Lay Out Story Journey from End-to-End Flow", "checklist": ["Start with entry point (how does user/system initiate?)", "Follow code flow through operations (what happens step by step?)", "Include error handling (what happens when things go wrong?)", "End with completion (how does it finish?)", "For each story, include:", "  - WHEN: trigger, condition, user action", "  - WHY: purpose, user need, system requirement", "  - OUTCOME: result, state change, user experience", "  - ACTOR: who performs the action", "Validate: Stories show complete journey, not isolated operations"]}, {"step": 7, "title": "Validate Story Map Quality", "checklist": ["Stories show user/system journey (not just list operations)", "Stories have context (when/why/outcome)", "Stories are specific (not generic like 'Add Sub-Epic')", "Stories represent complete accomplishments (not data access)", "Implementation details are steps, not stories", "Order follows user journey, not technical sequential_order", "Epics/sub-epics based on goals, not implementation structure"]}], "common_mistakes": ["Starting with internal classes instead of entry points", "Creating epics from class structure instead of goals", "Creating stories from every method call", "Missing context (when/why) in stories", "Making implementation details into stories", "Ordering by technical sequential_order instead of user journey", "Generic stories without specificity"]}}, {"rule_file": "use_active_behavioral_language.json", "rule_content": {"description": "When shaping stories, use active behavioral language with action verbs. Describe behaviors, not tasks or capabilities.", "context": "when shaping stories", "examples": [{"do": {"description": "Use action verbs to describe what happens", "content": ["Use action verbs to describe what happens", "Example: User submits order, System validates payment", "Favor active behavioral language over functional/capability breakup", "Use story maps to outline user and system behavior (NOT tasks)", "Use action verbs: submits, views, validates, sends, displays", "Describe behaviors: [Actor] [action] [object] - but actor NOT in name", "Use active behavior language: Place order (active behavior), Validate payment (active behavior)", "", "CRITICAL NAMING RULE - Actor NOT in Name:", "- Epic/Sub-Epic/Story names must be Verb-Noun format: '[Verb] [Noun]'", "- Actor is documented separately, NOT included in the name", "- Verb can be in various forms: imperative ('Add'), infinitive ('To Add'), third person ('Adds') - all are acceptable", "- Noun can be singular or plural based on context - DO NOT pluralize unnecessarily", "- Prepositional phrases and context are part of the noun phrase and should be preserved (e.g., 'Add Minion To Mob' is correct)", "- Examples: Epic 'Places Order' (actor: Customer, documented separately)", "- Examples: Sub-Epic 'Validates Payment' (actor: PaymentValidator, documented separately)", "- Examples: Story 'Updates Stock' (actor: InventoryManager, documented separately)", "- Examples: Story 'Add Minion To Mob' (verb-noun with context preserved - CORRECT)", "- Examples: Story 'Group Minions' (verb-noun, plural noun is correct for context - CORRECT)", "", "ACTOR SELECTION (documented separately, not in name):", "- For user/system stories: Use human/system actors (User, System, Developer, Customer)", "- For technical stories (deep internal): Domain concepts can be actors (OrderProcessor, PaymentValidator, InventoryManager, Cart, Product)", "- Actor is implicit or explicitly documented, but NOT in the name string"]}, "dont": {"description": "Avoid capability nouns and task language", "content": ["Avoid capability nouns that describe functions rather than behaviors", "Don't use functional or capability-based language instead of behavioral language", "Don't use capability nouns: Management, Processing, Administration", "Don't use task verbs: implement, create, build, set up", "Don't use task language", "", "Wrong Examples:", "- Order Management, Payment Processing (capability nouns)", "- Focus on tasks instead of behaviors", "- Order Management (capability), Implement order placement (task)", "", "Wrong Examples (actor in name):", "- Epic: 'Customer Places Order' (actor in name - WRONG)", "- Sub-Epic: 'OrderProcessor Validates Payment' (actor in name - WRONG)", "- Sub-Epic: 'Cart Adds Product' (actor in name - WRONG)", "- Story: 'InventoryManager Updates Stock' (actor in name - WRONG)", "", "Correct: Name is Verb-Noun only, actor documented separately"]}}]}}, {"rule_file": "use_outcome_verbs_not_communication_verbs.json", "rule_content": {"description": "Use Outcome Verbs, Not Communication Verbs", "examples": [{"do": {"description": "Use verbs that describe artifacts/outcomes", "content": ["Use verbs that describe artifacts/outcomes", "Examples: Animation, Feedback, Indicators, Configuration", "Name concepts by what they ARE or CREATE", "Examples: Power Activation Animation, Combat Outcome Feedback", "Focus on tangible results", "Examples: Hit Indicators, Save Result Feedback"]}, "dont": {"description": "Don't use generic communication verbs", "content": ["Don't use generic communication verbs", "Examples: showing, displaying, visualizing, presenting", "Don't use vague enablement verbs", "Examples: providing, enabling, allowing", "Don't name concepts by their mechanism", "Wrong Examples: Visualizing Power Activation, Showing Combat Results"]}}]}}], "token_estimate": 24071}}}, "11": {"action_state": "story_bot.1_shape.render_output", "status": "started", "timestamp": "2025-12-09T19:11:33.369936"}, "12": {"action_state": "story_bot.1_shape.render_output", "status": "completed", "timestamp": "2025-12-09T19:11:33.406546", "outputs": {"instructions": {"action": "render_output", "behavior": "1_shape", "base_instructions": ["\n**PROJECT PATH: C:\\dev\\augmented-teams\\demo\\mob_minion**\nAll render outputs must be written to paths relative to this project path, NOT to the bot's own directories.", "Render story map documents", "Render domain model documents", "Instantiate synchronizer class synchronizers.story_scenarios.StoryScenariosSynchronizer and call render method with renderer_command='render', input_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json, and output_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\docs\\stories", "Instantiate synchronizer class synchronizers.story_io.DrawIOSynchronizer and call render method with renderer_command='render-outline', input_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json, and output_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-map-outline.drawio"], "render_instructions": {"behaviorName": "shape", "instructions": ["Hey, going to be going away for a little while to render the output. Go get a cup of coffee \ud83d\ude0a", "", "**RENDER STORY MAP AND DOMAIN MODEL - DRAWIO AND MARKDOWN GENERATION:**", "", "Render the story graph and domain model to visual diagrams and markdown documents.", "", "**Configuration Files:**", "- Story map markdown render: render_story_map_md.json", "- Story map DrawIO render: render_story_map_outline_drawio.json", "- Domain model description render: render_domain_model_description.json", "- Domain model diagram render: render_domain_model_diagram.json", "- Templates: templates/story-map-outline.drawio, templates/story-map.md, templates/domain-model-description-template.md, templates/domain-model-diagram-template.md", "", "**Process:**", "1. Read story-graph.json from docs/stories/", "2. Render story map to DrawIO diagram and markdown document", "3. Render domain model to description and diagram documents", "4. Generate all outputs in project area docs/stories/", "", "**Outputs:**", "- File: {project_area}/docs/stories/story-map-outline.drawio", "- File: {project_area}/docs/stories/story-map.md", "- File: {project_area}/docs/stories/{solution_name_slug}-domain-model-description.md", "- File: {project_area}/docs/stories/{solution_name_slug}-domain-model-diagram.md", "", "**Next Step:** Proceed to synchronize step after rendering is complete."]}, "render_configs": [{"file": "behaviors\\1_shape\\2_content\\2_render\\render_domain_model_description.json", "config": {"name": "render_domain_model_description", "type": "template", "path": "docs/stories", "input": "story-graph.json", "template": "templates/domain-model-description-template.md", "output": "{solution_name_slug}-domain-model-description.md", "instructions": "Transform the domain_concepts from story-graph.json into a domain model description markdown document using the domain-model-description-template.md template file. Extract domain_concepts from all epics and sub_epics in story-graph.json. The description should use natural language that domain experts understand, explaining what each concept represents in the business domain, describing relationships and constraints between concepts, and using examples to illustrate domain concepts."}, "template": "# Domain Model Description: {solution_name}\n\n**File Name**: `{solution_name_slug}-domain-model-description.md`\n**Location**: `{solution_folder}/{solution_name_slug}-domain-model-description.md`\n\n## Solution Purpose\n{solution_purpose}\n\n---\n\n## Domain Model Descriptions\n\n{domain_model_descriptions}\n\n---\n\n## Source Material\n\n{source_material}\n"}, {"file": "behaviors\\1_shape\\2_content\\2_render\\render_domain_model_diagram.json", "config": {"name": "render_domain_model_diagram", "type": "template", "path": "docs/stories", "input": "story-graph.json", "template": "templates/domain-model-diagram-template.md", "output": "{solution_name_slug}-domain-model-diagram.md", "instructions": "Transform the domain_concepts from story-graph.json into a domain model diagram markdown document using the domain-model-diagram-template.md template file. Extract domain_concepts from all epics and sub_epics in story-graph.json. Generate Mermaid diagrams from the extracted domain_concepts structure."}, "template": "# Domain Model Diagram: {solution_name}\n\n**File Name**: `{solution_name_slug}-domain-model-diagram.md`\n**Location**: `{solution_folder}/{solution_name_slug}-domain-model-diagram.md`\n\n## Solution Purpose\n{solution_purpose}\n\n---\n\n## Domain Model Diagram\n\n```mermaid\nclassDiagram\n    class {ConceptName} {\n        +{responsibility}()\n        +{responsibility}()\n        +{responsibility}()\n    }\n    \n    class {AnotherConcept} {\n        +{responsibility}()\n        +{responsibility}()\n    }\n    \n    %% Inheritance\n    {ChildConcept} --|> {ParentConcept}\n    \n    %% Associations\n    {ConceptName} --> {CollaboratorConcept} : {relationship_label}\n    {ConceptName} --> {AnotherConcept} : uses\n```\n\n**Example:**\n```mermaid\nclassDiagram\n    class Payment {\n        +Validates card number()\n        +Authorizes transaction()\n        +Processes payment()\n    }\n    \n    class Order {\n        +Creates order()\n        +Calculates total()\n        +Updates status()\n    }\n    \n    Order --> Payment : processes\n```\n\n**Diagram Notes:**\n- Domain concepts are shown as classes with their responsibilities\n- Responsibilities are listed as methods in the class (format: +{responsibility}())\n- Relationships show dependencies and associations between concepts\n- Inheritance relationships show specialization (--|>)\n- Associations show usage and collaboration (-->)\n\n---\n\n## Source Material\n\n{source_material}\n"}, {"file": "behaviors\\1_shape\\2_content\\2_render\\render_domain_model_outline.json", "config": {"name": "render_domain_model_scaffold", "type": "template", "path": "src", "input": "story-graph.json", "template": "templates/domain_outline.md", "output": "domain_outline.md", "instructions": "Generate source code scaffold files in the src directory based on the domain_concepts from story-graph.json. Extract domain_concepts from all epics and sub_epics in story-graph.json. Create actual source code files (Python .py files, TypeScript .ts files, or appropriate language files) for each bounded context and aggregate. Note: This is currently a placeholder - no builder or template is specified."}, "template": "{concept}\n    {responsibility}: {collaborator},{collaborator},...\n    {responsibility}: {collaborator},{collaborator},...\n    {responsibility}: {collaborator},{collaborator},...\n\n{concept}\nInstructions:\n- Use clear, concise domain concepts and responsibilities.\n- List each responsibility as: {responsibility}: {collaborator},{collaborator},...\n- Only include meaningful relationships; avoid unnecessary boilerplate or filler.\n- Ensure each domain concept is followed by its set of responsibilities.\n"}, {"file": "behaviors\\1_shape\\2_content\\2_render\\render_story_files.json", "config": {"name": "render_story_files", "type": "synchronizer", "path": "docs/stories", "input": "story-graph.json", "synchronizer": "synchronizers.story_scenarios.StoryScenariosSynchronizer", "output": "docs/stories", "instructions": "Render story-graph.json to story markdown files. The synchronizer reads the story graph and generates markdown files for all Bot/system stories (excluding Human/AI Chat stories). Each story file is placed in the appropriate epic/feature folder structure."}}, {"file": "behaviors\\1_shape\\2_content\\2_render\\render_story_map_md.json", "config": {"name": "render_story_map", "type": "builder", "builder": "render_story_map_txt.py", "path": "docs/stories", "input": "story-graph.json", "template": "templates/story-map.md", "output": "story-map.txt", "instructions": "Render story-graph.json to story-map.txt format using the render_story_map_txt.py builder script. The builder reads story-graph.json and generates a formatted text file with epics, sub-epics, and stories."}, "template": "(E) Epic Name\n    (E) Sub-Epic Name\n        (E) Nested Sub-Epic Name (optional)\n            (S) Actor --> Story Name\n            (S) Actor --> Story Name\n            or (S) Actor --> Story Name\n                (AC) Actor --> Acceptance Criteria\n                (AC) Actor --> Acceptance Criteria\n            (S) Actor --> Story Name\n                (AC) Actor --> Acceptance Criteria\n                (AC) Actor --> Acceptance Criteria\n        (E) Another Nested Sub-Epic Name\n            (S) Actor --> Story Name\n            (S) Actor --> Story Name\n\n(E) {epic_name}\n    (E) {sub_epic_name}\n        (S) {actor} --> {story_name}\n        (S) {actor} --> {story_name}\n        or (S) {actor} --> {story_name}\n            (AC) {actor} --> {acceptance_criteria}\n            (AC) {actor} --> {acceptance_criteria}\n            (S) {actor} --> {story_name}\n                (AC) {actor} --> {acceptance_criteria}\n                (AC) {actor} --> {acceptance_criteria}\n        (S) {actor} --> {story_name}\n\n## Instructions\n\n- **Epics (E)**: Top-level features, no connectors\n- **Sub-Epics (E)**: Nested epics, no connectors\n- **Stories (S)**: User stories with actors, format: `Actor --> Story Name`\n- **Acceptance Criteria (AC)**: Nested under stories, format: `Actor --> Acceptance Criteria`\n- **Connectors**: \n  - \"and\" is the default - do NOT show in output (only stored in JSON)\n  - \"or\" shown explicitly for alternatives\n  - \"opt\" shown explicitly for optional items\n- **Indentation**: Use spaces (4 spaces per level), not tabs\n- **First item**: No connector (even if default \"and\")\n- **Nesting**: Stories can contain nested stories or acceptance criteria\n- **Language**: Use active behavioral language (verb-noun format)\n- **Epic/Sub-Epic names**: Verb-Noun format (actor NOT in name)\n- **Story/AC names**: Actor-Verb-Noun format (actor shown with \"-->\")\n"}, {"file": "behaviors\\1_shape\\2_content\\2_render\\render_story_map_outline_drawio.json", "config": {"name": "render_story_map_outline_drawio", "type": "synchronizer", "path": "docs/stories", "input": "story-graph.json", "synchronizer": "synchronizers.story_io.DrawIOSynchronizer", "renderer_command": "render-outline", "output": "story-map-outline.drawio", "drawio_file": "story-map-outline.drawio", "force_outline": true, "instructions": "Render story-graph.json to DrawIO format using the story_io CLI. Execute: python -m agile_bot.bots.story_bot.src.synchronizers.story_io.story_io_cli render-outline --story-graph {project_path}/docs/stories/story-graph.json --drawio-file {project_path}/docs/stories/story-map-outline.drawio --output {project_path}/docs/stories/story-map-outline.drawio --force-outline"}}, {"file": "behaviors\\1_shape\\2_content\\2_render\\render_story_map_txt.json", "config": {"name": "render_story_map_txt", "type": "template", "path": "docs/stories", "input": "story-graph.json", "template": "templates/story-map.txt", "output": "story-map.txt", "instructions": "Render story-graph.json to story-map.txt format using the story-map.txt template file. This is a direct template rendering (no builder script)."}, "template": "(E) \n    (E) Sub-Epic(s)\n        (E) Sub-Epic(s) - additional are optional\n            or - connector type\n                (S) Story and | or common across group \n                    (AC) AC or steps\n\n(E) {epic_name}\n    (E) {sub_epic_name} \n            (S) {actor} --> {story_name} \n            or (S) {actor} --> {story_name}   --> or group type\n            or (S) {actor} --> {story_name}\n        or  --> second group connector type\n            (S) {actor} --> {story_name}\n            (AC) {actor} --> {acceptance_criteria}   --> and group type\n            (AC) {actor} --> {acceptance_criteria}\n        and  --> third group connector type\n            (S) {actor} --> {story_name}\n            (AC) {actor} --> {acceptance_criteria}  --> and type\n            (AC) {actor} --> {acceptance_criteria}  --> and type\n        or \n            (S) {actor} --> {story_name}\n            (AC) {actor} /default group type is and\n            (AC) {actor}\n        \n       \n(E) {epic_name}\n    (E) {sub_epic_name}\n        (E) {nested_sub_epic_name}\n           ...\n\nInstructions:\n- Use (E) for Epics and Sub-Epics\n- Use (S) for Stories\n- Use (AC) for Acceptance Criteria\n- Story Groups are MANDATORY - all stories must be in a story group\n- Story group TYPE is determined by the connector on stories WITHIN the group (and | or | opt)\n- Story group CONNECTOR appears on a line by itself BETWEEN groups (and | or | opt)\n- Default group type is \"and\" (no connector on first story in group)\n- First story group in a sub-epic has NO connector line before it\n- Group connector line (e.g., \"or\", \"and\") separates story groups\n- Within a group, all stories share the same type (and, or, or opt)\n- Show actors with \"--> \" before story names (e.g., \"Human --> Story Name\")\n- Use hierarchical indentation (spaces, not tabs)\n- Acceptance criteria are nested under stories with same indentation pattern\n- Use active behavioral language (verb-noun format)\n- Epic/Sub-Epic names: Verb-Noun format (actor NOT in name)\n- Story names: Actor-Verb-Noun format (actor in story with \"-->\")\n- Epics and Sub-Epics do NOT have connectors (only story groups have connectors)\n\n"}], "project_path": "C:\\dev\\augmented-teams\\demo\\mob_minion"}}}, "13": {"action_state": "story_bot.1_shape.validate_rules", "status": "started", "timestamp": "2025-12-09T19:11:50.470039"}, "14": {"action_state": "story_bot.1_shape.validate_rules", "status": "completed", "timestamp": "2025-12-09T19:11:50.488684", "outputs": {"instructions": {"action": "validate_rules", "behavior": "1_shape", "base_instructions": ["Load and review clarification.json and planning.json", "Check Content Data against all rules", "Generate a validation report", "", "**NEXT BEHAVIOR REMINDER:**", "After completing this behavior, the next behavior in sequence is `2_prioritization`. When the user is ready to continue, remind them: 'The next behavior in sequence is `2_prioritization`. Would you like to continue with `2_prioritization` or work on a different behavior?'"], "validation_rules": [{"rule_file": "apply_7_plus_minus_2_hierarchy.json", "rule_content": {"description": "Apply 7\u00b12 rule for hierarchy: epics contain 4-9 sub-epics, sub-epics contain 4-9 stories. Split when exceeding, merge when below minimum.", "examples": [{"do": {"description": "Maintain hierarchy within the 7\u00b12 cognitive limit range", "content": ["(E) Epic: Contains 4-9 sub-epics", "  - Split into additional Sub-Epics when > 9 sub-epics", "  - Merge with another epic when < 4 sub-epics", "(E) Sub-Epic: Contains 4-9 stories", "  - Split into 2 sub-epics when > 9 stories", "  - Merge with another sub-epic when < 4 stories", "(S) Story: Contains 2-9 acceptance criteria", "  - Split into 2 stories when > 9 AC", "  - Merge with another story when < 2 AC (single AC stories are too small)", "Apply 7\u00b12 cognitive limit principle (optimal range: 5-9, acceptable: 4-9)", "", "Example:", "(E) Manage Orders (10 sub-epics \u2192 SPLIT)", "  and (E) Manage Customer Orders (6 stories) \u2713", "  and (E) Manage Order Fulfillment (4 stories) \u2713", "", "(E) Place Order (12 stories \u2192 SPLIT)", "  and (S) Initiate Order (6 AC) \u2713", "  and (S) Complete Order (6 AC) \u2713", "", "(S) Validate Payment (11 AC \u2192 SPLIT)", "  and (AC) Check Payment Method (5 steps) \u2713", "  and (AC) Process Payment Transaction (6 steps) \u2713"]}, "dont": {"description": "Don't exceed thresholds or create items below minimum", "content": ["Create epics with > 9 sub-epics (use additional Sub-Epics instead)", "Create sub-epics with > 9 stories (split the sub-epic)", "Create stories with > 9 acceptance criteria (split the story)", "Create very small stories with < 2 AC (merge with related story)", "Ignore sizing thresholds during shaping, discovery, or exploration", "", "Wrong Examples:", "- (E) Epic with 15 sub-epics (too many, use additional Sub-Epics)", "- (E) Sub-Epic with 15 stories (too many, split sub-epic)", "- (S) Story with 15 AC (too many, split story)", "- (S) Story with 1 AC (too small, merge with related story)"]}}]}}, {"rule_file": "avoid_noun_redundancy.json", "rule_content": {"description": "When shaping stories, avoid noun redundancy in domain and concept names", "context": "when shaping stories", "examples": [{"do": {"description": "INTEGRATE first: nest related capabilities under one domain", "content": ["INTEGRATE first: nest related capabilities under one domain (90% of cases)", "Only then rename: use distinct nouns ONLY when integration doesn't make sense", "Test for uniqueness: Can you remove the qualifier and still know what it is?", "Use subject-area nouns when domains are genuinely separate", "Only when integration truly doesn't make sense"]}, "dont": {"description": "Don't rename without considering integration", "content": ["Don't rename without considering integration (this hides the real issue)", "Wrong: Repeat same noun with different prefixes: X Animation, Y Animation, Z Animation", "Don't use vague qualifiers to avoid integration", "Wrong: Animation 1, Animation System", "Don't create parallel domains that should be nested", "Wrong: Integrate related concepts rather than creating redundant structures"]}}]}}, {"rule_file": "avoid_technical_implementation_language.json", "rule_content": {"description": "When shaping stories, avoid technical implementation language in user-facing story elements", "context": "when shaping stories", "do": {"examples": [{"description": "Use business language in user-facing elements", "content": ["Customer places order, User views profile, Admin approves request"]}, {"description": "Focus on what user experiences, not how it's implemented", "content": ["Story describes user experience, not technical implementation"]}]}, "dont": {"examples": [{"description": "Don't use development task language", "content": ["implement, create, refactor, optimize, fix, build, set up"]}, {"description": "Don't use technical implementation details", "content": ["query database, call API, update table"]}, {"description": "Don't focus on delivery or development tasks", "content": ["Implement order system, Create database schema, Set up API endpoints"]}, {"description": "Don't focus on system internals", "content": ["Optimize query performance, Refactor authentication code, Update configuration"]}]}}}, {"rule_file": "avoid_technical_stories.json", "rule_content": {"description": "Technical stories represent implementation tasks that do not describe system behavior. They are normally avoided in favor of user stories and system stories. When technical stories are necessary, they should be marked with story_type: 'technical' and kept minimal.", "do": {"examples": [{"description": "Prefer user stories and system stories over technical stories", "content": ["Instead of 'Set up database schema', use 'Store user data' (user story)", "Instead of 'Create API endpoint', use 'Expose user data via API' (system story)", "Instead of 'Write unit tests', use 'Verify story behavior' (user story)"]}, {"description": "When technical stories are necessary, mark with story_type: 'technical'", "content": ["Story: 'Migrate legacy data format' with story_type: 'technical'", "Story: 'Refactor authentication module' with story_type: 'technical'", "Story: 'Update dependency versions' with story_type: 'technical'"]}, {"description": "Keep technical stories minimal and focused", "content": ["Technical stories should be rare exceptions", "Technical stories should still follow Verb-Noun format", "Technical stories should be clearly justified"]}]}, "dont": {"examples": [{"description": "Don't create technical stories for normal development work", "content": ["Avoid: 'Write code', 'Create class', 'Add method'", "Avoid: 'Set up CI/CD', 'Configure database', 'Install package'", "These are implementation details, not stories"]}, {"description": "Don't use technical stories to describe system behavior", "content": ["Use system stories for system-to-system behavior", "Use user stories for user-facing behavior", "Technical stories are for unavoidable implementation tasks only"]}]}}}, {"rule_file": "balance_fine_grained_testable_stories.json", "rule_content": {"description": "Balance fine-grained stories with testable and valuable independent units. Stories must deliver value and be independently testable.", "examples": [{"do": {"description": "Create stories that are complete interactions with value", "content": ["Create stories that are complete interactions with value", "Example: Customer places order (complete interaction, testable, valuable)", "Balance fine-grained stories with testable/valuable stories", "Ensure stories are fine-grained enough to enable frequent feedback", "Ensure stories are grouped into meaningful chunks for high quality feedback", "Stories that deliver measurable value independently"]}, "dont": {"description": "Avoid stories that are too small or too large", "content": ["Avoid stories that are too small and have no value alone", "Don't create stories that are too fine-grained without being testable or valuable", "Don't create stories that are too large to be testable or deliverable quickly", "", "Wrong Examples:", "- Add order button (too fine-grained, no value alone)", "- Change button color (too fine-grained, no value)", "- Customer places order and views history and updates profile (too large, multiple flows)"]}}]}}, {"rule_file": "create_lightweight_precise_docs.json", "rule_content": {"description": "Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.", "examples": [{"do": {"description": "Create lightweight but precise documentation during shaping", "content": ["Balance fine-grained stories with testable/valuable stories", "Ensure stories are fine-grained enough to enable frequent feedback", "Ensure stories are grouped into meaningful chunks for high quality feedback", "Validate that a business expert can understand the language of most of the stories", "Focus the language on the business domain", "Create lightweight but precise documentation", "Focus on structure and scope, not detailed specifications", "Make the map easy to walk through (it tells a story)", "", "Example:", "(E) Manage Orders", "  and (E) Place Order", "    and (S) Customer --> places order", "(Shows hierarchy and structure, not detailed specs)"]}, "dont": {"description": "Don't over-elaborate or add detailed specifications during shaping", "content": ["Create stories that are too fine-grained without being testable or valuable", "Create stories that are too large to be testable or deliverable quickly", "Add detailed technical specifications during shaping phase", "Over-elaborate story mapping during shaping", "", "Wrong Example:", "(E) Manage Orders", "  and (E) Place Order", "    and (S) Customer --> places order", "  \u2192 Detailed API specs, database schema, UI mockups", "(Too much detail for shaping phase)"]}}]}}, {"rule_file": "discover_relationships_from_story_map.json", "rule_content": {"description": "Domain Discovery determines relationships and responsibilities between core domain objects by walking through the story map, then suggests story refinements to rebuild the story map to complement the domain model.", "examples": [{"do": {"description": "Extract keywords from story map and determine relationships and responsibilities", "content": "Go through all stories in increment scope, extract keywords from story titles/descriptions/acceptance criteria, ask clarifying questions for each keyword, map relationships with multiplicities, document responsibilities"}, "dont": {"description": "Don't skip keyword identification or build domain model without story map analysis", "content": "Skip going through stories, ignore keywords in acceptance criteria, build domain model without asking what keywords mean, use technical terms instead of domain terms"}}]}}, {"rule_file": "enforce_behavioral_journey_flow.json", "rule_content": {"description": "When shaping stories, CRITICAL: Stories must show user/system journey flow, not just list operations. Stories must include context (when/why actions happen) and connect logically. Order by user journey, not technical sequential_order.", "context": "when shaping stories", "examples": [{"do": {"description": "Show user/system journey with context and flow", "content": ["Stories must show WHEN and WHY actions happen, not just WHAT", "Story maps must show logical flow: Initialize \u2192 Validate \u2192 Process \u2192 Confirm \u2192 Complete", "Each story must connect to previous/next stories in the journey", "Order stories by user journey flow, not by technical sequential_order", "", "Correct Examples (with journey context - Payment Domain):", "(E) Process Payment", "  and (E) Process Card Payment", "    and (S) User --> invokes process payment command", "    and (S) System --> validates payment details", "    and (S) System --> authorizes payment", "    and (S) System --> processes payment transaction", "    and (S) System --> confirms payment and sends notification", "", "(E) Refund Payment", "  and (E) Process Refund", "    and (S) User --> invokes refund payment command", "    and (S) System --> validates refund eligibility", "    and (S) System --> processes refund transaction", "    and (S) System --> confirms refund and sends notification", "", "(E) Process Payment", "  and (E) Validate Payment", "    and (S) User --> submits payment request", "    and (S) System --> validates card number", "    and (S) System --> validates amount", "    and (S) System --> validates currency", "    and (S) System --> returns validation result", "", "Note: Individual stories like 'Authorize Payment with Processor' are correct story format (verb-noun, specific), but they need to be part of a journey. Stories should NOT include actors in the name (actors are documented separately).", "", "Correct Individual Stories (but need journey context):", "- 'Authorize Payment with Processor' (correct story format, but needs: when? why? what happens next?)", "- 'Validate Payment Details' (correct story format, but needs: when? why? what triggers this?)", "- 'Process Payment Transaction' (correct story format, but needs: when? why? what happens before/after?)", "", "Journey Flow Requirements:", "- Start with initialization/entry point", "- Show logical progression through operations", "- Include error handling and alternative paths", "- End with completion/save operations", "- Connect stories logically (this leads to that)"]}, "dont": {"description": "Don't create isolated sets of functions that don't make sense linearly", "content": ["Don't group unrelated operations together that don't form a logical journey", "Don't create story maps with random functions that have no linear relationship", "Don't mix unrelated operations from different domains or contexts", "", "Wrong Examples (isolated sets of functions, no linear sense - Payment Domain):", "(E) Payment Operations", "  and (E) Process Payment", "  and (E) Generate Invoice", "  and (E) Send Email", "  and (E) Update Inventory", "  and (E) Calculate Tax", "(unrelated operations, no linear flow - why does email come after payment? why inventory? no journey)", "", "(E) Payment System", "  and (E) Authorize Payment", "  and (E) Create User Account", "  and (E) Process Refund", "  and (E) Generate Report", "  and (E) Delete Transaction", "(random operations, no logical sequence - account creation doesn't follow authorization, deletion doesn't follow processing)", "", "(E) Payment Flow", "  and (S) System --> validates payment", "  and (S) System --> sends notification", "  and (S) System --> authorizes payment", "  and (S) System --> updates database", "  and (S) System --> processes payment", "(wrong order, no linear sense - notification before authorization? database update before processing?)", "", "What Makes It NOT a Linear Journey:", "- Unrelated operations grouped together (payment + inventory + email + tax - why together?)", "- Operations from different contexts mixed (payment + user account + reporting - different domains)", "- No logical sequence (why does X come before Y? no reason)", "- Operations can be in any order (no dependencies, no flow)", "- Random collection of functions (like a function library, not a journey)", "- No user/system goal that connects them (what are we trying to accomplish?)"]}}]}}, {"rule_file": "enforce_functional_accomplishment.json", "rule_content": {"description": "CRITICAL: Stories must represent complete functional accomplishments, not data access operations or implementation steps. Stories must deliver value independently.", "examples": [{"do": {"description": "Create stories that accomplish complete functions", "content": ["Stories must represent complete functional accomplishments", "Stories must deliver value independently (INVEST principle)", "Stories must show end-to-end flow, not just data access", "", "Correct Examples (complete functional accomplishments):", "- 'User loads story graph and system displays epics in diagram' (complete: load + display = accomplishment)", "- 'Developer edits epic name and system updates diagram' (complete: edit + update = accomplishment)", "- 'User requests render and system generates DrawIO file' (complete: request + generate = accomplishment)", "- 'CLI invokes render command and system saves outline diagram' (complete: invoke + save = accomplishment)", "", "Functional Accomplishment Requirements:", "- Story must accomplish something meaningful for user/system", "- Story must be independently valuable (can be tested/delivered alone)", "- Story must show complete flow (start \u2192 process \u2192 outcome)", "- Story must have clear acceptance criteria (how do we know it's done?)"]}, "dont": {"description": "Don't create stories that are just data access or implementation steps", "content": ["Don't create stories that are just data access operations", "Don't create stories that are implementation steps without outcomes", "Don't create stories that aren't independently valuable", "", "Wrong Examples (not complete accomplishments):", "- 'Read All Epics from Diagram' (data access - not accomplishment, what happens with the data?)", "- 'Load All Features In Graph Epic' (data access - not accomplishment)", "- 'Serialize Components to JSON' (implementation step - not accomplishment, part of what story?)", "- 'Convert Diagram to StoryGraph Format' (implementation step - not accomplishment)", "- 'Calculate Component Positions' (implementation step - not accomplishment)", "", "Data Access/Implementation Indicators (REJECT as stories):", "- Just reads/loads data without using it", "- Just converts/formats data without purpose", "- Just calculates/computes without outcome", "- Just serializes/saves without context", "", "These should be STEPS within stories, not stories themselves:", "- Step: 'System reads epics from diagram' (within story: 'User views story map and system displays epics')", "- Step: 'System serializes components' (within story: 'User saves story graph and system writes JSON file')", "- Step: 'System calculates positions' (within story: 'User requests render and system generates positioned diagram')", "", "Instead, ask:", "- What does the user/system accomplish with this?", "- Is this independently valuable?", "- Can this be tested/delivered alone?", "- What's the complete flow from start to finish?"]}}]}}, {"rule_file": "enforce_specificity_in_stories.json", "rule_content": {"description": "CRITICAL: Stories must be specific about what, when, why, and who. Generic operations like 'Add Sub-Epic' or 'Read Epics' are insufficient - stories must include context and specificity.", "examples": [{"do": {"description": "Create specific stories with full context", "content": ["Stories must be specific about what, when, why, and who", "Stories must include context: when does it happen? why? what triggers it?", "Stories must specify actors, objects, and outcomes clearly", "", "Correct Examples (specific with context - Payment Domain):", "- 'User processes payment for order #12345 with amount $50.00 when customer completes checkout' (specific: user, order ID, amount, context)", "- 'Merchant invokes refund command from API and system reverses payment transaction' (specific: merchant, API, command, outcome)", "- 'System validates payment card number 4111-1111-1111-1111 when user submits payment form' (specific: system, card number, trigger)", "- 'User clicks Process Payment button and system prompts for payment method selection' (specific: user, action, UI element, system response)", "", "Specificity Requirements:", "- WHO: Specific actor (User, Merchant, Customer, System, PaymentProcessor, API)", "- WHAT: Specific action and object (processes payment for order #12345 with amount $50.00)", "- WHEN: Specific trigger/context (when customer completes checkout, when user submits payment form)", "- WHY: Purpose in journey (to complete purchase transaction, to reverse payment error)", "- OUTCOME: Specific result (payment processed, transaction ID returned, notification sent)"]}, "dont": {"description": "Don't create generic stories without context", "content": ["Don't create generic operations without specificity", "Don't omit context about when/why actions happen", "Don't use vague descriptions without details", "", "Wrong Examples (generic without context - Payment Domain):", "- 'Process Payment' (which payment? for which order? when? why?)", "- 'Authorize Payment' (which payment? with which card? when? why? what happens next?)", "- 'Exposes Payment API' (which endpoints? to whom? when? why?)", "- 'Refund Payment' (which payment? for which reason? when? why?)", "", "Generic Indicators (REJECT or require more specificity):", "- Single verb + noun without context: 'Process Payment', 'Authorize Payment', 'Refund Payment'", "- No specific objects: 'Process Payment' (which payment? which order?)", "- No context: 'Authorize Payment' (when? why? what triggers this?)", "- No outcome: 'Authorize Payment' (what happens with the authorization result?)", "", "Instead, ask:", "- Which specific object? (payment ID, order number, transaction ID, card number)", "- When does this happen? (trigger, context, user action - when customer completes checkout, when merchant requests refund)", "- Why does this happen? (purpose, user need, journey step - to complete purchase, to reverse error)", "- What's the outcome? (result, system response, user experience - payment processed, transaction ID returned, notification sent)"]}}]}}, {"rule_file": "establish_spine_vs_optional_enhanced_behavior.json", "rule_content": {"description": "Establish mandatory spine stories vs optional/enhanced behavior stories. When mapping stories, carefully distinguish between sequential spine (essential path) and optional paths, alternate routes, or additional functionality that is not strictly essential. Mandatory stories form the sequential spine (story AND story AND story). Optional stories are alternatives or enhancements (story OR story) that branch from the spine and can return to it. Sequential stories form the mandatory flow; optional stories are alternatives, enhancements, or non-essential sub-epics.", "examples": [{"do": {"description": "Identify the essential spine first", "content": ["Start by identifying the minimal essential path that delivers core value", "The spine represents the mandatory sequence: Story1 AND Story2 AND Story3", "Spine stories get sequential_order numbers (1, 2, 3, etc.)", "Spine stories are required for the sub-epic to deliver its core purpose", "Ask: 'What is the minimum path to deliver value?'", "Establish the mandatory spine before identifying optional/enhanced behaviors", "Explicitly distinguish between spine (mandatory) and optional/enhanced behaviors"]}, "dont": {"description": "Don't mark everything as sequential", "content": ["Don't assign sequential_order to all stories when some are optional", "Don't treat alternate routes as part of the spine", "Don't include enhancements in the mandatory sequential flow", "Don't confuse 'nice to have' with 'must have'", "Don't mark all stories as mandatory when some are alternatives or enhancements", "Don't fail to establish the spine before adding optional/enhanced behaviors"]}}, {"do": {"description": "Mark optional paths clearly", "content": ["Optional stories branch from or enhance the spine but are not required", "Mark optional stories with 'optional: true' in the story structure", "Optional stories may have sequential_order if they're part of an alternative flow (e.g., 2.1, 3.1, etc.)", "Optional stories represent: alternate routes, enhancements, nice-to-have sub-epics", "Ask: 'Can the sub-epic deliver value without this story?'", "Optional/enhanced stories can return to the spine after completion", "Sort optional/enhanced stories by priority of delivery within the same sub-epic"]}, "dont": {"description": "Don't omit optional markers", "content": ["Don't leave optional stories unmarked - be explicit", "Don't assume all stories in a sub-epic are mandatory", "Don't mix optional and mandatory without clear distinction", "Don't fail to identify the spine before adding optional paths", "Don't omit the optional marker - be explicit about spine vs optional/enhanced behaviors", "Don't create sub-epics where every story is mandatory when alternatives or enhancements exist"]}}, {"do": {"description": "Distinguish types of optional paths with concrete examples", "content": ["Spine (all stories with and), then OR optional branch (all stories with and), then OR enhanced (all stories with and):", "", "Correct Example:", "Spine (all stories with and):", "  (S) User --> creates account", "  and (S) User --> logs in", "  and (S) User --> views dashboard", "OR optional branch (all stories with and):", "  (S) User --> signs in with social media (optional)", "  and (S) User --> signs in with email (optional)", "OR enhanced (all stories with and):", "  (S) User --> customizes dashboard (enhanced)", "  and (S) User --> shares dashboard (enhanced)"]}, "dont": {"description": "Wrong mapping examples", "content": ["Wrong: All stories marked mandatory when some are clearly alternatives or enhancements", "  and (S) User --> creates account (1)", "  and (S) User --> logs in with email (2)", "  and (S) User --> logs in with social media (3) - social media should be optional", "", "Wrong: No distinction between essential path and optional sub-epics", "  and (S) User --> views dashboard (1)", "  and (S) User --> customizes dashboard (2)", "  and (S) User --> shares dashboard (3) - customization and sharing should be optional", "", "Wrong: Missing optional markers on alternative flows or enhanced behaviors", "Wrong: Optional/enhanced stories not sorted by priority", "Wrong: No clear spine established before adding optional behaviors"]}}]}}, {"rule_file": "extract_story_map_checklist.json", "rule_content": {"description": "Quick checklist for extracting story maps from code. Follow this process step-by-step.", "steps": [{"step": 1, "title": "Find Outermost Layer and Entry Points", "checklist": ["Locate CLI commands (main(), argparse, command handlers)", "Locate UI entry points (routes, event handlers, button clicks)", "Locate MCP server tool definitions (tool names, parameters)", "Locate API contracts (REST endpoints, GraphQL, WSDL)", "Locate WebSocket handlers, message queues, event listeners", "Locate acceptance tests (end-to-end, integration, BDD/Gherkin)", "Document all entry points with their parameters and return values"]}, {"step": 2, "title": "Analyze Operations and Domain Concepts", "checklist": ["List all operations from entry points (what can be invoked?)", "Identify MAJOR domain concepts (high-level entities)", "Identify MINOR domain concepts (supporting entities)", "Identify relationships between concepts", "Document operation names, parameters, return values", "Document concept names, properties, relationships"]}, {"step": 3, "title": "Create Epics Based on Higher-Order Goals", "checklist": ["Group operations by higher-order goals (what is user/system trying to accomplish?)", "Create epics from goals, not from implementation structure", "Each epic represents a major capability or lifecycle stage", "Validate: Epic name describes a goal, not a technical operation"]}, {"step": 4, "title": "Create Sub-Epics Based on Distinct Behaviors", "checklist": ["For each epic, identify distinct behaviors (different ways to accomplish goal)", "Group behaviors into sub-epics (different types, modes, contexts)", "Each sub-epic represents a distinct path or scenario", "Validate: Sub-epic name describes a behavior, not a technical mechanism"]}, {"step": 5, "title": "Identify Distinct Behaviors from Tests and Code Flow", "checklist": ["Trace through acceptance tests: what happens step by step?", "Trace through CLI commands: what's the execution flow?", "Trace through MCP tool calls: what's the sequence?", "Identify distinct behaviors at each step", "Document typical execution order", "Document error handling and alternative paths"]}, {"step": 6, "title": "Lay Out Story Journey from End-to-End Flow", "checklist": ["Start with entry point (how does user/system initiate?)", "Follow code flow through operations (what happens step by step?)", "Include error handling (what happens when things go wrong?)", "End with completion (how does it finish?)", "For each story, include:", "  - WHEN: trigger, condition, user action", "  - WHY: purpose, user need, system requirement", "  - OUTCOME: result, state change, user experience", "  - ACTOR: who performs the action", "Validate: Stories show complete journey, not isolated operations"]}, {"step": 7, "title": "Validate Story Map Quality", "checklist": ["Stories show user/system journey (not just list operations)", "Stories have context (when/why/outcome)", "Stories are specific (not generic like 'Add Sub-Epic')", "Stories represent complete accomplishments (not data access)", "Implementation details are steps, not stories", "Order follows user journey, not technical sequential_order", "Epics/sub-epics based on goals, not implementation structure"]}], "common_mistakes": ["Starting with internal classes instead of entry points", "Creating epics from class structure instead of goals", "Creating stories from every method call", "Missing context (when/why) in stories", "Making implementation details into stories", "Ordering by technical sequential_order instead of user journey", "Generic stories without specificity"]}}, {"rule_file": "extract_story_map_from_code.json", "rule_content": {"description": "CRITICAL: When creating story maps from code, analyze the outermost layer showing end-to-end journey. Locate acceptance tests, human code engagement points (CLI/UI), MCP server definitions, WSDL, API contracts. Analyze operations and domain for major/minor concepts. Create epics/sub-epics based on higher-order goals. Look at distinct behaviors and typical execution order to lay out story journey.", "examples": [{"do": {"description": "Find outermost layer and entry points", "content": ["Start with the OUTERMOST LAYER showing end-to-end journey", "Locate all HUMAN CODE ENGAGEMENT points:", "  - CLI commands and entry points (main(), command handlers)", "  - UI entry points (web routes, event handlers, button clicks)", "  - MCP server tool definitions (tool names, parameters, descriptions)", "  - API contracts (REST endpoints, GraphQL queries, WSDL operations)", "  - WebSocket handlers, message queues, event listeners", "", "Locate ACCEPTANCE TESTS:", "  - End-to-end tests that show complete user journeys", "  - Integration tests that show system-to-system flows", "  - Test scenarios that describe 'when X, then Y' behaviors", "  - BDD/Gherkin tests with Given-When-Then structure", "", "Example Entry Points to Find:", "- CLI: 'python -m story_io.story_io_cli render-outline --story-graph file.json'", "- MCP: Tool 'render_outline' with parameters 'story_graph_path', 'output_path'", "- API: POST /api/story-graph/render with body {storyGraph, outputFormat}", "- UI: Button 'Render Outline' that triggers render operation", "- Test: 'test_render_outline_from_json' that shows complete flow"]}, "dont": {"description": "Don't start with internal implementation details", "content": ["Don't start with internal classes or helper functions", "Don't start with data structures or domain models", "Don't start with utility functions or low-level operations", "", "Wrong Starting Points:", "- Internal class: 'StoryIODiagram.load_from_json()' (implementation detail)", "- Helper function: 'parse_story_graph()' (internal mechanism)", "- Data structure: 'Epic' class definition (domain model, not entry point)", "", "These are important but come AFTER identifying the journey"]}}, {"do": {"description": "Analyze operations and domain for major/minor concepts", "content": ["Analyze OPERATIONS from entry points:", "  - What operations are exposed? (render, sync, search, edit, save)", "  - What are the operation names? (render-outline, sync-increments, search-stories)", "  - What parameters do they take? (story_graph_path, output_path, query)", "  - What do they return? (DrawIO file, JSON report, search results)", "", "Analyze DOMAIN CONCEPTS:", "  - MAJOR CONCEPTS: High-level domain entities (StoryGraph, Diagram, Epic, Sub-Epic, Story)", "  - MINOR CONCEPTS: Supporting entities (Position, Boundary, User, Increment)", "  - OPERATIONS: Actions on concepts (Load, Read, Edit, Render, Synchronize, Search, Save)", "  - RELATIONSHIPS: How concepts relate (Epic contains Sub-Epics, Sub-Epic contains Stories)", "", "Example Analysis (Story-IO Domain):", "- Operations: render-outline, render-increments, sync-outline, sync-increments, search, add-user, merge", "- Major Concepts: StoryGraph (main entity), Diagram (visual representation), Epic/Sub-Epic/Story (hierarchy)", "- Minor Concepts: Position (2D coordinate), Boundary (rectangular area), User (story actor), Increment (priority grouping)", "- Relationships: StoryGraph contains Epics, Epic contains Sub-Epics, Sub-Epic contains Stories", "", "Example Analysis (Payment Domain):", "- Operations: process-payment, refund-payment", "- Major Concepts: Payment (main entity), Transaction (financial transaction), Card (payment method), Refund (reversal)", "- Minor Concepts: Amount (monetary value), Currency (USD, EUR), Status (pending, approved, declined), PaymentMethod (card, bank transfer)", "- Relationships: Payment contains Transaction, Payment uses Card, Payment can have Refund, Transaction has Status"]}, "dont": {"description": "Don't confuse implementation details with domain concepts", "content": ["Don't treat implementation classes as domain concepts", "Don't treat utility functions as operations", "Don't treat data structures as domain entities", "", "Wrong Analysis:", "- Implementation class: 'StoryIORenderer' (implementation detail, not domain concept)", "- Utility function: 'calculate_position()' (implementation detail, not operation)", "- Data structure: 'dict' or 'list' (implementation detail, not domain concept)", "", "Focus on WHAT the system does (domain), not HOW it does it (implementation)"]}}, {"do": {"description": "Create epics/sub-epics based on higher-order goals", "content": ["Group operations into EPICS based on HIGHER-ORDER GOALS:", "  - What is the user/system trying to accomplish?", "  - What are the major capabilities?", "  - What are the lifecycle stages?", "", "Example Epic Creation from Operations (Story-IO Domain):", "- Operations: render-outline, render-increments, render-exploration", "- Higher-Order Goal: 'Render StoryGraph' (user wants to visualize story map)", "- Epic: 'Render StoryGraph'", "", "- Operations: sync-outline, sync-increments, generate-sync-report, merge", "- Higher-Order Goal: 'Synchronize StoryGraph' (user wants to sync between formats)", "- Epic: 'Synchronize StoryGraph'", "", "Example Epic Creation from Operations (Payment Domain):", "- Operations: process-payment, process_payment, POST /api/payments/process", "- Higher-Order Goal: 'Process Payment' (user wants to process a payment transaction)", "- Epic: 'Process Payment'", "", "- Operations: refund-payment, refund_payment, POST /api/payments/refund", "- Higher-Order Goal: 'Refund Payment' (user wants to reverse a payment)", "- Epic: 'Refund Payment'", "", "Group operations into SUB-EPICS based on DISTINCT BEHAVIORS:", "  - What are the different ways to accomplish the epic goal?", "  - What are the different types or modes?", "  - What are the different contexts or scenarios?", "", "Example Sub-Epic Creation (Story-IO Domain):", "- Epic: 'Render StoryGraph'", "- Distinct Behaviors: Render outline (basic), Render increments (with priorities), Render exploration (with acceptance criteria)", "- Sub-Epics: 'Render Outline', 'Render Increments', 'Render Exploration'", "", "- Epic: 'Synchronize StoryGraph'", "- Distinct Behaviors: Sync outline structure, Sync increments, Generate comparison report, Merge graphs", "- Sub-Epics: 'Synchronize Outline', 'Synchronize Increments', 'Generate Sync Report', 'Merge StoryGraphs'", "", "Example Sub-Epic Creation (Payment Domain):", "- Epic: 'Process Payment'", "- Distinct Behaviors: Validate payment (required), Authorize payment (required), Process with card (common), Process with bank transfer (alternative), Process with wallet (alternative), Confirm payment (required)", "- Sub-Epics: 'Validate Payment', 'Authorize Payment', 'Process Card Payment', 'Process Bank Transfer', 'Process Wallet Payment', 'Confirm Payment'", "", "- Epic: 'Refund Payment'", "- Distinct Behaviors: Validate refund eligibility, Process refund, Confirm refund", "- Sub-Epics: 'Validate Refund', 'Process Refund', 'Confirm Refund'"]}, "dont": {"description": "Don't create epics/sub-epics from implementation structure", "content": ["Don't create epics based on class structure (StoryIODiagram, DrawIORenderer, PaymentProcessor, etc.)", "Don't create sub-epics based on method names (load_json, parse_xml, charge_card, etc.)", "Don't create epics/sub-epics from technical layers (data layer, service layer, etc.)", "", "Wrong Epic Creation:", "- Based on class: 'StoryIODiagram Operations' (implementation structure)", "- Based on method: 'JSON Loading' (technical mechanism)", "- Based on layer: 'Data Access Layer' (technical architecture)", "", "Focus on USER/SYSTEM GOALS, not technical structure"]}}, {"do": {"description": "Look at distinct behaviors and typical execution order", "content": ["Analyze DISTINCT BEHAVIORS from acceptance tests and code flow:", "  - What are the different scenarios?", "  - What are the different paths through the code?", "  - What are the different user actions?", "", "Example Behavior Analysis (Story-IO Domain):", "- Test: 'test_render_outline_from_json' shows: Load JSON \u2192 Parse \u2192 Generate XML \u2192 Calculate Positions \u2192 Apply Styles \u2192 Save", "- Distinct Behaviors: Load, Parse, Generate, Calculate, Apply, Save", "- These become STORIES in the journey", "", "Example Behavior Analysis (Payment Domain):", "- Test: 'test_process_payment_success' shows: Invoke \u2192 Validate \u2192 Authorize \u2192 Process \u2192 Confirm", "- Distinct Behaviors: Invoke (entry point), Validate (check input), Authorize (check funds/fraud), Process (execute transaction), Confirm (complete and notify)", "- These become STORIES in the journey", "", "Determine TYPICAL EXECUTION ORDER from code flow:", "  - Trace through acceptance tests: what happens first, second, third?", "  - Trace through CLI commands: what's the flow?", "  - Trace through MCP tool calls: what's the sequence?", "  - Look at error handling: what are alternative paths?", "", "Example Execution Order Analysis (Story-IO Domain):", "- CLI: 'render-outline --story-graph file.json --output file.drawio'", "- Code Flow: Parse args \u2192 Load story graph \u2192 Create diagram \u2192 Render outline \u2192 Save file", "- Typical Order: 1. Parse arguments, 2. Load story graph, 3. Render outline, 4. Save file", "- Stories: 'Parses Command Arguments' \u2192 'Loads StoryGraph from JSON' \u2192 'Renders Outline to DrawIO' \u2192 'Saves DrawIO File'", "", "Example Execution Order Analysis (Payment Domain):", "- CLI: 'process-payment --payment-id 123 --amount 50.00'", "- Code Flow: Parse args \u2192 Validate payment \u2192 Authorize payment \u2192 Process payment \u2192 Confirm payment", "- Typical Order: 1. User invokes process payment, 2. System validates payment details, 3. System authorizes payment, 4. System processes payment, 5. System confirms payment", "- Stories: 'User invokes process payment command' \u2192 'System validates payment details' \u2192 'System authorizes payment with payment processor' \u2192 'System processes payment transaction' \u2192 'System confirms payment and sends notification'", "", "Create STORY JOURNEY from execution order:", "  - Start with entry point (CLI invocation, UI click, MCP tool call)", "  - Follow the code flow through operations", "  - Include error handling and alternative paths", "  - End with completion (save, return result, display)", "", "Example Story Journey (Story-IO Domain):", "- Entry: 'User invokes render-outline command from CLI'", "- Flow: 'CLI parses arguments' \u2192 'CLI loads story graph' \u2192 'CLI invokes render' \u2192 'System renders outline' \u2192 'System saves file'", "- Error: 'If file not found, CLI displays error message'", "- Completion: 'CLI returns success message'", "", "Example Story Journey (Payment Domain):", "- Entry: 'User invokes process payment command' (WHEN: user wants to charge customer, WHY: to complete purchase, OUTCOME: CLI/MCP/API receives request)", "- Flow: 'System validates payment details' (WHEN: after request received, WHY: to ensure payment can be processed, OUTCOME: details validated) \u2192 'System authorizes payment' (WHEN: after validation, WHY: to check funds/fraud, OUTCOME: payment authorized) \u2192 'System processes payment' (WHEN: after authorization, WHY: to execute transaction, OUTCOME: payment processed) \u2192 'System confirms payment' (WHEN: after processing, WHY: to notify user, OUTCOME: payment confirmed)", "- Error: 'If validation fails, System displays validation error' (WHEN: validation fails, WHY: to inform user, OUTCOME: error shown, process stops)", "- Completion: 'System returns transaction ID' (WHEN: after confirmation, WHY: to provide reference, OUTCOME: transaction ID returned)"]}, "dont": {"description": "Don't create stories from code structure or method calls", "content": ["Don't create stories from every method call in code", "Don't create stories from internal function calls", "Don't create stories from data structure operations", "", "Wrong Story Creation:", "- From method: 'StoryIODiagram.__init__()' (internal initialization)", "- From function: 'parse_json()' (internal parsing)", "- From operation: 'dict.get()' (data access, not behavior)", "- From method: 'PaymentProcessor.charge_card()' (internal implementation)", "", "Focus on USER/SYSTEM VISIBLE BEHAVIORS, not internal implementation"]}}, {"do": {"description": "Lay out story journey from end-to-end flow", "content": ["Create STORY JOURNEY that shows complete end-to-end flow:", "  - Start: How does user/system initiate? (CLI command, UI click, API call)", "  - Middle: What happens step by step? (parse, load, process, transform)", "  - End: How does it complete? (save, return, display, notify)", "", "Include CONTEXT for each story:", "  - WHEN does it happen? (trigger, condition, user action)", "  - WHY does it happen? (purpose, user need, system requirement)", "  - WHAT is the outcome? (result, state change, user experience)", "  - ACTOR: Who performs the action? (User, System, CLI, MCP, API, etc.)", "", "Example Complete Story Journey (Story-IO Domain):", "(E) Render StoryGraph", "  and (E) Render Outline", "    and (S) User --> invokes render-outline command from CLI", "    and (S) CLI --> parses command arguments", "    and (S) CLI --> loads story graph from JSON file", "    and (S) System --> renders outline to DrawIO format", "    and (S) System --> saves DrawIO file", "", "Example Complete Story Journey (Payment Domain):", "(E) Process Payment", "  and (E) Process Card Payment", "    and (S) User --> invokes process payment command", "    and (S) System --> validates payment details", "    and (S) System --> authorizes payment with payment processor", "    and (S) System --> processes payment transaction", "    and (S) System --> confirms payment and sends notification", "", "Include ERROR HANDLING and ALTERNATIVE PATHS:", "  - What happens when file not found?", "  - What happens when parsing fails?", "  - What happens when validation fails?", "  - What happens when authorization fails?", "", "Example Error Handling (Story-IO Domain):", "  and (S) CLI --> displays error message if story graph file not found", "", "Example Error Handling (Payment Domain):", "  and (S) System --> displays validation error if validation fails", "  and (S) System --> displays authorization declined message if authorization fails"]}, "dont": {"description": "Don't create isolated stories without journey context", "content": ["Don't create stories that are just operations without context", "Don't create stories that don't connect to a journey", "Don't create stories without when/why/outcome/actor", "", "Wrong Story Creation:", "- (S) System --> loads StoryGraph (no context: when? why? what happens next?)", "- (S) System --> parses JSON (no context: when? why? what's the outcome?)", "- (S) System --> saves file (no context: when? why? what triggers this?)", "- (S) System --> processes payment (no context: when? why? what's the outcome?)", "", "Every story must be part of a JOURNEY with CONTEXT (when/why/outcome/actor)"]}}]}}, {"rule_file": "focus_real_actions_on_domain_concepts.json", "rule_content": {"description": "When shaping stories, stories must describe REAL ACTIONS that users or other actors (even system or technical actors) can perform, not capabilities or structural descriptions. Organize by lifecycle flow (Load, Read, Edit, Render, Synchronize, Search, Save). CRITICAL: Actor names must NOT appear in Epic/Sub-Epic/Story names - names are Verb-Noun only.", "context": "when shaping stories", "examples": [{"do": {"description": "Use real actions - actor separate from name", "content": ["Stories describe actions: Load, Read, Add, Remove, Render, Search, Save", "Organize by lifecycle: Load \u2192 Read \u2192 Edit \u2192 Render \u2192 Synchronize \u2192 Search \u2192 Save", "Use Verb-Noun format for names: '[Verb] [Noun]' - NO ACTOR in name", "Focus on what users/code CAN DO, not what things ARE", "", "NAMING RULE - Actor NOT in Name:", "- Epic name: 'Places Order' (NOT 'Customer Places Order')", "- Sub-Epic name: 'Validates Payment' (NOT 'PaymentValidator Validates Payment')", "- Story name: 'Processes Order Items' (NOT 'OrderProcessor Processes Order Items')", "- Actor is documented separately, not in the name itself", "", "ACTORS for User/System Stories (normal stories):", "- Use human/system actors: User, Developer, System, Customer, Admin", "- Actor is implicit or documented separately from name", "- Examples: Epic 'Places Order' has actor: Customer", "- Examples: Sub-Epic 'Validates Payment' has actor: System", "", "ACTORS for Technical Stories (deep internal class-level interactions):", "- Domain concepts CAN be actors: OrderProcessor, PaymentValidator, InventoryManager, Cart, Product", "- Actor is documented separately, NOT in name", "- Examples: Epic 'Loads Order Data' has actor: OrderProcessor (technical)", "- Examples: Sub-Epic 'Updates Inventory' has actor: InventoryManager (technical)", "- Examples: Story 'Calculates Total' has actor: Cart (technical)", "- This is acceptable when documenting class-to-class interactions internally"]}, "dont": {"description": "Avoid capabilities, structural descriptions, passive states, and actors in names", "content": ["Don't use capability nouns or structural descriptions", "Don't describe what things ARE or CONTAIN", "Don't use passive states or properties as stories", "CRITICAL: Don't put actor in Epic/Sub-Epic/Story names", "", "Wrong Examples (capabilities/structure):", "- 'PaymentValidator Contains Validation Logic' (capability, not action)", "- 'OrderProcessor Tracks Order Count' (passive state, not action)", "- 'Cart Hierarchy Foundation' (structural description)", "- 'Domain Components Implementation' (capability)", "- 'Product Represents Item' (structural description)", "", "Wrong Examples (actor in name):", "- Epic: 'Customer Places Order' (actor in name - WRONG)", "- Sub-Epic: 'OrderProcessor Validates Payment' (actor in name - WRONG)", "- Sub-Epic: 'Cart Adds Product' (actor in name - WRONG)", "- Story: 'InventoryManager Updates Stock' (actor in name - WRONG)", "", "Correct Examples (actor NOT in name):", "- Epic: 'Places Order' (actor: Customer, documented separately)", "- Sub-Epic: 'Validates Payment' (actor: PaymentValidator, documented separately)", "- Sub-Epic: 'Adds Product' (actor: Cart, documented separately)", "- Story: 'Updates Stock' (actor: InventoryManager, documented separately)", "", "These are not actions users/code can perform - they describe structure or capabilities", "Instead ask: What can users/code DO with this domain concept?", "- Instead of 'Contains Logic' \u2192 'Generates XML' or 'Renders Diagram'", "- Instead of 'Tracks Count' \u2192 'Reads Count' or 'Updates Count'", "- Instead of 'Represents X' \u2192 'Creates X' or 'Loads X'"]}}]}}, {"rule_file": "focus_user_and_system_activities.json", "rule_content": {"description": "Focus story maps on both user AND system activities, not tasks. Stories should outline user and system behavior patterns.", "examples": [{"do": {"description": "Include both user and system activities in story descriptions", "content": ["User submits order, System validates payment", "Customer views products, System displays inventory", "Use user activity patterns: User submits, Customer places", "Use system activity patterns: System validates, System sends", "Focus stories on user interactions and how the system behaves as observed by users", "Example: Customer places order with payment details", "", "ACTOR SELECTION (documented separately, NOT in name):", "- For user/system stories: Actors are User, System, Developer, Customer, Admin (human/system actors)", "- For technical stories (deep internal class-level): Domain concepts can be actors (StoryIODiagram, DrawIORenderer, DrawIOSynchronizer, User, Increment, Component)", "- Technical stories document class-to-class interactions where domain concepts act as actors", "", "CRITICAL NAMING RULE:", "- Actor must NOT appear in Epic/Sub-Epic/Story name", "- Name format: '[Verb] [Noun]' only", "- Examples: 'Loads StoryGraph' (actor: StoryIODiagram, documented separately)", "- Examples: 'Adds Sub-Epic' (actor: Epic, documented separately)", "- Examples: 'Changes Parent' (actor: Component, documented separately)"]}, "dont": {"description": "Avoid task-oriented language that describes implementation", "content": ["Avoid task-oriented language that describes implementation", "Don't use task language for building or setting up", "Don't focus only on user activities (ignore system activities)", "Don't focus only on tasks (instead of activities)", "Don't use development task language: implement, create, refactor, optimize, fix, build, set up", "Don't use technical implementation details: query database, call API, update table", "", "Wrong Examples:", "- Only user activities: User submits order, User views products (missing system activities)", "- Only tasks: Implement order submission, Create payment validation (not activities)", "- Implement order submission, Create payment validation", "- Build product listing page, Set up inventory display"]}}]}}, {"rule_file": "identify_system_stories.json", "rule_content": {"description": "System stories capture system-to-system interactions that are not user-facing. They represent internal system behavior that crosses system boundaries (e.g., microservice to microservice, component to component). System stories should be identified and marked with story_type: 'system'.", "do": {"examples": [{"description": "Identify system-to-system interactions", "content": ["Storage Microservice validates payload from Local Mgmt System", "API Gateway routes request to Authentication Service", "Message Queue delivers event to Notification Service"]}, {"description": "Mark system stories with story_type: 'system'", "content": ["Story: 'Validate Payload' with story_type: 'system'", "Story: 'Route Request' with story_type: 'system'", "Story: 'Deliver Event' with story_type: 'system'"]}, {"description": "Use system stories for internal system behavior", "content": ["System stories represent behavior that happens between systems/components", "System stories are not directly visible to end users", "System stories enable user-facing stories to function"]}]}, "dont": {"examples": [{"description": "Don't mark user-facing stories as system stories", "content": ["User clicks button \u2192 NOT a system story", "User views dashboard \u2192 NOT a system story", "User submits form \u2192 NOT a system story"]}, {"description": "Don't confuse system stories with technical stories", "content": ["System stories = system-to-system behavior (dark blue in DrawIO)", "Technical stories = implementation tasks (black/white in DrawIO, normally avoided)"]}]}}}, {"rule_file": "maximize_integration_of_related_concepts.json", "rule_content": {"description": "When shaping stories, maximize integration of related concepts", "context": "when shaping stories", "examples": [{"do": {"description": "Group concepts that the user sees as one capability", "content": ["Group concepts that the user sees as one capability", "Nest implementation details under the sub-epic they serve", "Keep related data and operations together", "Eliminate artificial boundaries based on code organization"]}, "dont": {"description": "Don't separate related concepts", "content": ["Don't separate related concepts into different major sections", "Wrong: Split based on code layers (data, business, presentation)", "Don't duplicate related concepts across multiple sections", "Wrong: Create gaps that break the user's mental model"]}}]}}, {"rule_file": "place_domain_concepts_by_relevance.json", "rule_content": {"description": "When shaping stories, place domain concepts locally or globally based on relevance to one or multiple sub_epics", "context": "when shaping stories", "examples": [{"do": {"description": "Place domain concepts at the most specific level, favoring local placement", "content": ["Favor local placement: Place domain_concepts at the sub_epic level when they are relevant to only that sub_epic", "Think about the core: Consider core domain concepts that span multiple sub_epics - these should be placed at the parent epic/sub_epic level", "Elevate when shared: If a domain concept is used by multiple child sub_epics, elevate it to the parent level", "Start local, elevate if needed: Begin with local placement, but elevate if the concept is referenced by multiple sub_epics", "", "Correct Examples (Local Placement):", "- Sub-Epic 'Validates Payment' has domain_concept: 'Payment' (only used in this sub-epic)", "- Sub-Epic 'Processes Order' has domain_concept: 'Order' (only used in this sub-epic)", "- Sub-Epic 'Updates Inventory' has domain_concept: 'InventoryItem' (only used in this sub-epic)", "", "Correct Examples (Global Placement):", "- Epic 'Process Payment' has domain_concept: 'Payment' (used by multiple sub-epics: Validate Payment, Authorize Payment, Process Transaction)", "- Epic 'Manage Orders' has domain_concept: 'Order' (used by multiple sub-epics: Create Order, Update Order, Cancel Order)", "- Sub-Epic 'Order Management' has domain_concept: 'Customer' (used by multiple child sub-epics: Create Customer Order, Update Customer Order)"]}, "dont": {"description": "Don't place domain concepts at wrong levels or duplicate them unnecessarily", "content": ["Don't place domain concepts at epic level when they're only used in one sub-epic", "Wrong: Epic 'Payment System' has domain_concept: 'PaymentValidator' (only used in 'Validates Payment' sub-epic - should be local)", "Don't duplicate domain concepts at multiple levels", "Wrong: Both Epic and Sub-Epic have 'Payment' concept when it's only used in one sub-epic", "Don't place core domain concepts too locally if they're used across multiple epics", "Wrong: Core concept 'User' placed only in one sub-epic when it's used across multiple epics", "Don't ignore shared usage - if multiple sub-epics reference a concept, elevate it", "Wrong: 'Order' concept placed in each sub-epic separately when all sub-epics use it (should be at parent level)"]}}]}}, {"rule_file": "prevent_generic_capabilities.json", "rule_content": {"description": "CRITICAL: Stories must describe specific actions with actors, not generic capabilities. Reject stories that describe what system IS (capabilities) vs what system DOES (behaviors).", "examples": [{"do": {"description": "Use specific actions with actors and outcomes", "content": ["Stories must have specific actors performing specific actions", "Stories must describe what system DOES (behaviors), not what system IS (capabilities)", "Stories must have specific outcomes, not generic descriptions", "", "Correct Examples (specific behaviors with actors):", "- 'User invokes MCP tool and system routes to StoryIO handler' (specific: user, MCP tool, routing action)", "- 'Developer adds sub-epic Render Exploration to epic Render StoryGraph' (specific: developer, sub-epic name, epic name)", "- 'System loads story graph from JSON file when user requests render' (specific: system, load action, trigger)", "- 'CLI determines workspace root from current directory' (specific: CLI, determine action, source)", "", "Actor Requirements:", "- Every story must have an actor (User, System, Developer, CLI, StoryIODiagram, etc.)", "- Actor must be documented separately (not in name)", "- Actor must be specific (not generic 'Component' or 'System')", "- Actor must perform the action (not just be present)"]}, "dont": {"description": "Don't use generic capabilities or passive descriptions", "content": ["Don't describe what system IS (capabilities)", "Don't use generic action descriptions without actors", "Don't use passive states or properties as stories", "", "Wrong Examples (generic capabilities):", "- 'Exposes Tools' (capability - what tools? when? to whom? what happens?)", "- 'Provides Server Interface' (capability - what interface? when? why?)", "- 'Contains Validation Logic' (capability - not an action)", "- 'Tracks Order Count' (passive state - not an action)", "", "Capability Indicators (REJECT):", "- Describes what system IS: 'Exposes', 'Provides', 'Contains', 'Represents'", "- No specific actor or action", "- No specific outcome or trigger", "- Generic description without context", "", "Instead, ask:", "- Who performs this action? (actor)", "- When does this happen? (trigger/context)", "- What specific outcome occurs? (result)", "- Why does this happen? (purpose in journey)"]}}]}}, {"rule_file": "prevent_implementation_details_as_stories.json", "rule_content": {"description": "CRITICAL: Implementation operations (serialize, convert, calculate, generate XML, apply formatting) must be steps within stories, not stories themselves. Stories must focus on user/system outcomes, not technical mechanisms.", "examples": [{"do": {"description": "Keep implementation details as steps within stories", "content": ["Implementation operations must be steps within stories", "Stories must focus on user/system outcomes, not technical mechanisms", "Stories must describe what user/system experiences, not how it's implemented", "", "Correct Examples (outcomes, not mechanisms):", "- Story: 'User saves story graph and system writes JSON file' \u2192 Steps: 'System converts diagram to story graph format', 'System serializes components to JSON', 'System writes file'", "- Story: 'User requests render and system generates DrawIO diagram' \u2192 Steps: 'System generates DrawIO XML', 'System calculates component positions', 'System applies styles', 'System saves file'", "- Story: 'User edits epic and system updates diagram' \u2192 Steps: 'System updates epic data', 'System recalculates layout', 'System refreshes diagram'", "", "Story vs Step Distinction:", "- Story = User/system outcome (what they experience)", "- Step = Implementation detail (how it's done)", "- Story = Independently valuable (can be tested/delivered)", "- Step = Part of story (not independently valuable)"]}, "dont": {"description": "Don't make implementation operations into stories", "content": ["Don't create stories for implementation operations", "Don't expose technical mechanisms as user stories", "Don't break implementation steps into separate stories", "", "Wrong Examples (implementation details as stories):", "- 'Convert Diagram to StoryGraph Format' (implementation - should be step in 'Save StoryGraph' story)", "- 'Serialize Components to JSON' (implementation - should be step in 'Save StoryGraph' story)", "- 'Generate DrawIO XML from StoryGraph' (implementation - should be step in 'Render Outline' story)", "- 'Calculate Component Positions' (implementation - should be step in 'Render Outline' story)", "- 'Apply Component Styles' (implementation - should be step in 'Render Outline' story)", "- 'Save DrawIO XML to File' (implementation - should be step in 'Render Outline' story)", "", "Implementation Operation Indicators (REJECT as stories):", "- Serialize, deserialize, convert, transform, format", "- Calculate, compute, generate, create (technical artifacts)", "- Apply, set, configure (technical settings)", "- Save, write, store (without user context)", "", "These are implementation mechanisms, not user/system behaviors", "They should be steps within stories that describe outcomes", "", "Instead, ask:", "- What does the user/system experience? (story)", "- How is it implemented? (step within story)", "- What's the outcome? (story)", "- What's the mechanism? (step)"]}}]}}, {"rule_file": "refine_scope_to_functional_accomplishment.json", "rule_content": {"description": "Refine Scope to Functional Accomplishment", "examples": [{"do": {"description": "Focus on functional outcomes, not mechanisms", "content": ["Focus on functional outcomes, not mechanisms", "Frame domains by what they accomplish for users", "Ask about user enablement: What does this enable the user to do or understand?", "State the transformation or capability provided", "Be specific about the functional benefit"]}, "dont": {"description": "Don't frame domains by their technical implementation", "content": ["Don't frame domains by their technical implementation", "Wrong: Focus on 'how' before 'what'", "Don't use generic system capabilities as domain names", "Wrong: Describe mechanisms instead of outcomes"]}}]}}, {"rule_file": "size_stories_3_to_12_days.json", "rule_content": {"description": "Size stories to fall within 3-12 day effort range for effective planning and frequent delivery.", "examples": [{"do": {"description": "Create stories that represent complete flows within the effort range", "content": ["Create stories that represent complete flows within the effort range", "Example: Customer places order (complete flow, 3-5 days)", "Break/group stories so that most fall into a 3-12 day effort range", "Enable frequent feedback by decomposing the work into smaller items"]}, "dont": {"description": "Avoid stories that are too large or too small", "content": ["Avoid stories that are too large and span multiple weeks", "Don't arbitrarily decompose stories to a functional level, regardless of size", "", "Wrong Examples:", "- Order management system (too large, 20+ days)", "- Create stories that are too small without considering value"]}}]}}, {"rule_file": "story_map_code_approach.json", "rule_content": {"description": "Quick checklist for extracting story maps from code. Follow this process step-by-step.", "steps": [{"step": 1, "title": "Find Outermost Layer and Entry Points", "checklist": ["Locate CLI commands (main(), argparse, command handlers)", "Locate UI entry points (routes, event handlers, button clicks)", "Locate MCP server tool definitions (tool names, parameters)", "Locate API contracts (REST endpoints, GraphQL, WSDL)", "Locate WebSocket handlers, message queues, event listeners", "Locate acceptance tests (end-to-end, integration, BDD/Gherkin)", "Document all entry points with their parameters and return values"]}, {"step": 2, "title": "Analyze Operations and Domain Concepts", "checklist": ["List all operations from entry points (what can be invoked?)", "Identify MAJOR domain concepts (high-level entities)", "Identify MINOR domain concepts (supporting entities)", "Identify relationships between concepts", "Document operation names, parameters, return values", "Document concept names, properties, relationships"]}, {"step": 3, "title": "Create Epics Based on Higher-Order Goals", "checklist": ["Group operations by higher-order goals (what is user/system trying to accomplish?)", "Create epics from goals, not from implementation structure", "Each epic represents a major capability or lifecycle stage", "Validate: Epic name describes a goal, not a technical operation"]}, {"step": 4, "title": "Create Sub-Epics Based on Distinct Behaviors", "checklist": ["For each epic, identify distinct behaviors (different ways to accomplish goal)", "Group behaviors into sub-epics (different types, modes, contexts)", "Each sub-epic represents a distinct path or scenario", "Validate: Sub-epic name describes a behavior, not a technical mechanism"]}, {"step": 5, "title": "Identify Distinct Behaviors from Tests and Code Flow", "checklist": ["Trace through acceptance tests: what happens step by step?", "Trace through CLI commands: what's the execution flow?", "Trace through MCP tool calls: what's the sequence?", "Identify distinct behaviors at each step", "Document typical execution order", "Document error handling and alternative paths"]}, {"step": 6, "title": "Lay Out Story Journey from End-to-End Flow", "checklist": ["Start with entry point (how does user/system initiate?)", "Follow code flow through operations (what happens step by step?)", "Include error handling (what happens when things go wrong?)", "End with completion (how does it finish?)", "For each story, include:", "  - WHEN: trigger, condition, user action", "  - WHY: purpose, user need, system requirement", "  - OUTCOME: result, state change, user experience", "  - ACTOR: who performs the action", "Validate: Stories show complete journey, not isolated operations"]}, {"step": 7, "title": "Validate Story Map Quality", "checklist": ["Stories show user/system journey (not just list operations)", "Stories have context (when/why/outcome)", "Stories are specific (not generic like 'Add Sub-Epic')", "Stories represent complete accomplishments (not data access)", "Implementation details are steps, not stories", "Order follows user journey, not technical sequential_order", "Epics/sub-epics based on goals, not implementation structure"]}], "common_mistakes": ["Starting with internal classes instead of entry points", "Creating epics from class structure instead of goals", "Creating stories from every method call", "Missing context (when/why) in stories", "Making implementation details into stories", "Ordering by technical sequential_order instead of user journey", "Generic stories without specificity"]}}, {"rule_file": "use_active_behavioral_language.json", "rule_content": {"description": "When shaping stories, use active behavioral language with action verbs. Describe behaviors, not tasks or capabilities.", "context": "when shaping stories", "examples": [{"do": {"description": "Use action verbs to describe what happens", "content": ["Use action verbs to describe what happens", "Example: User submits order, System validates payment", "Favor active behavioral language over functional/capability breakup", "Use story maps to outline user and system behavior (NOT tasks)", "Use action verbs: submits, views, validates, sends, displays", "Describe behaviors: [Actor] [action] [object] - but actor NOT in name", "Use active behavior language: Place order (active behavior), Validate payment (active behavior)", "", "CRITICAL NAMING RULE - Actor NOT in Name:", "- Epic/Sub-Epic/Story names must be Verb-Noun format: '[Verb] [Noun]'", "- Actor is documented separately, NOT included in the name", "- Verb can be in various forms: imperative ('Add'), infinitive ('To Add'), third person ('Adds') - all are acceptable", "- Noun can be singular or plural based on context - DO NOT pluralize unnecessarily", "- Prepositional phrases and context are part of the noun phrase and should be preserved (e.g., 'Add Minion To Mob' is correct)", "- Examples: Epic 'Places Order' (actor: Customer, documented separately)", "- Examples: Sub-Epic 'Validates Payment' (actor: PaymentValidator, documented separately)", "- Examples: Story 'Updates Stock' (actor: InventoryManager, documented separately)", "- Examples: Story 'Add Minion To Mob' (verb-noun with context preserved - CORRECT)", "- Examples: Story 'Group Minions' (verb-noun, plural noun is correct for context - CORRECT)", "", "ACTOR SELECTION (documented separately, not in name):", "- For user/system stories: Use human/system actors (User, System, Developer, Customer)", "- For technical stories (deep internal): Domain concepts can be actors (OrderProcessor, PaymentValidator, InventoryManager, Cart, Product)", "- Actor is implicit or explicitly documented, but NOT in the name string"]}, "dont": {"description": "Avoid capability nouns and task language", "content": ["Avoid capability nouns that describe functions rather than behaviors", "Don't use functional or capability-based language instead of behavioral language", "Don't use capability nouns: Management, Processing, Administration", "Don't use task verbs: implement, create, build, set up", "Don't use task language", "", "Wrong Examples:", "- Order Management, Payment Processing (capability nouns)", "- Focus on tasks instead of behaviors", "- Order Management (capability), Implement order placement (task)", "", "Wrong Examples (actor in name):", "- Epic: 'Customer Places Order' (actor in name - WRONG)", "- Sub-Epic: 'OrderProcessor Validates Payment' (actor in name - WRONG)", "- Sub-Epic: 'Cart Adds Product' (actor in name - WRONG)", "- Story: 'InventoryManager Updates Stock' (actor in name - WRONG)", "", "Correct: Name is Verb-Noun only, actor documented separately"]}}]}}, {"rule_file": "use_outcome_verbs_not_communication_verbs.json", "rule_content": {"description": "Use Outcome Verbs, Not Communication Verbs", "examples": [{"do": {"description": "Use verbs that describe artifacts/outcomes", "content": ["Use verbs that describe artifacts/outcomes", "Examples: Animation, Feedback, Indicators, Configuration", "Name concepts by what they ARE or CREATE", "Examples: Power Activation Animation, Combat Outcome Feedback", "Focus on tangible results", "Examples: Hit Indicators, Save Result Feedback"]}, "dont": {"description": "Don't use generic communication verbs", "content": ["Don't use generic communication verbs", "Examples: showing, displaying, visualizing, presenting", "Don't use vague enablement verbs", "Examples: providing, enabling, allowing", "Don't name concepts by their mechanism", "Wrong Examples: Visualizing Power Activation, Showing Combat Results"]}}]}}], "content_to_validate": {"project_location": "C:\\dev\\augmented-teams\\demo\\mob_minion", "rendered_outputs": ["C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-description.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-diagram.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json"], "clarification_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\clarification.json", "planning_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\planning.json", "report_path": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\validation-report.md"}}}}, "15": {"action_state": "story_bot.2_prioritization.gather_context", "status": "started", "timestamp": "2025-12-09T19:12:36.861053"}, "16": {"action_state": "story_bot.2_prioritization.gather_context", "status": "completed", "timestamp": "2025-12-09T19:12:36.896564", "outputs": {"instructions": {"action": "gather_context", "behavior": "2_prioritization", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["Which areas of the story map carry the most business or delivery risk?", "Which areas are expected to deliver the most value if delivered early?", "Which areas are the most complex or hardest to implement, relative to their value?", "Do you want thin slices to be as end-to-end as possible?", "Are there any components, capabilities, or services that need to be reused across multiple stories or features?", "Are there any project or program constraints that impact delivery order?", "Are there users or groups that must go first to enable others to follow?"], "evidence": ["Story map from Shape stage (epics, features, and initial story breakdown)", "Business cases or initiative briefs", "Project charters and delivery timelines", "Capability or architectural dependency maps", "User rollout or onboarding strategies", "Risk registers or readiness checklists", "Value modeling or impact estimation docs"]}}}}, "17": {"action_state": "story_bot.2_prioritization.gather_context", "status": "started", "timestamp": "2025-12-09T19:14:29.129078"}, "18": {"action_state": "story_bot.2_prioritization.gather_context", "status": "completed", "timestamp": "2025-12-09T19:14:29.158223", "outputs": {"instructions": {"action": "gather_context", "behavior": "2_prioritization", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["Which areas of the story map carry the most business or delivery risk?", "Which areas are expected to deliver the most value if delivered early?", "Which areas are the most complex or hardest to implement, relative to their value?", "Do you want thin slices to be as end-to-end as possible?", "Are there any components, capabilities, or services that need to be reused across multiple stories or features?", "Are there any project or program constraints that impact delivery order?", "Are there users or groups that must go first to enable others to follow?"], "evidence": ["Story map from Shape stage (epics, features, and initial story breakdown)", "Business cases or initiative briefs", "Project charters and delivery timelines", "Capability or architectural dependency maps", "User rollout or onboarding strategies", "Risk registers or readiness checklists", "Value modeling or impact estimation docs"]}}}}, "19": {"action_state": "story_bot.2_prioritization.gather_context", "status": "started", "timestamp": "2025-12-09T19:14:33.061213"}, "20": {"action_state": "story_bot.2_prioritization.gather_context", "status": "completed", "timestamp": "2025-12-09T19:14:33.107070", "outputs": {"instructions": {"action": "gather_context", "behavior": "2_prioritization", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["Which areas of the story map carry the most business or delivery risk?", "Which areas are expected to deliver the most value if delivered early?", "Which areas are the most complex or hardest to implement, relative to their value?", "Do you want thin slices to be as end-to-end as possible?", "Are there any components, capabilities, or services that need to be reused across multiple stories or features?", "Are there any project or program constraints that impact delivery order?", "Are there users or groups that must go first to enable others to follow?"], "evidence": ["Story map from Shape stage (epics, features, and initial story breakdown)", "Business cases or initiative briefs", "Project charters and delivery timelines", "Capability or architectural dependency maps", "User rollout or onboarding strategies", "Risk registers or readiness checklists", "Value modeling or impact estimation docs"]}}}}, "21": {"action_state": "story_bot.2_prioritization.gather_context", "status": "started", "timestamp": "2025-12-09T19:14:44.349549"}, "22": {"action_state": "story_bot.2_prioritization.gather_context", "status": "completed", "timestamp": "2025-12-09T19:14:44.385293", "outputs": {"instructions": {"action": "gather_context", "behavior": "2_prioritization", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["Which areas of the story map carry the most business or delivery risk?", "Which areas are expected to deliver the most value if delivered early?", "Which areas are the most complex or hardest to implement, relative to their value?", "Do you want thin slices to be as end-to-end as possible?", "Are there any components, capabilities, or services that need to be reused across multiple stories or features?", "Are there any project or program constraints that impact delivery order?", "Are there users or groups that must go first to enable others to follow?"], "evidence": ["Story map from Shape stage (epics, features, and initial story breakdown)", "Business cases or initiative briefs", "Project charters and delivery timelines", "Capability or architectural dependency maps", "User rollout or onboarding strategies", "Risk registers or readiness checklists", "Value modeling or impact estimation docs"]}}}}, "23": {"action_state": "story_bot.2_prioritization.gather_context", "status": "started", "timestamp": "2025-12-09T19:20:45.116178"}, "24": {"action_state": "story_bot.2_prioritization.gather_context", "status": "completed", "timestamp": "2025-12-09T19:20:45.146846", "outputs": {"instructions": {"action": "gather_context", "behavior": "2_prioritization", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["Which areas of the story map carry the most business or delivery risk?", "Which areas are expected to deliver the most value if delivered early?", "Which areas are the most complex or hardest to implement, relative to their value?", "Do you want thin slices to be as end-to-end as possible?", "Are there any components, capabilities, or services that need to be reused across multiple stories or features?", "Are there any project or program constraints that impact delivery order?", "Are there users or groups that must go first to enable others to follow?"], "evidence": ["Story map from Shape stage (epics, features, and initial story breakdown)", "Business cases or initiative briefs", "Project charters and delivery timelines", "Capability or architectural dependency maps", "User rollout or onboarding strategies", "Risk registers or readiness checklists", "Value modeling or impact estimation docs"]}}}}, "25": {"action_state": "story_bot.2_prioritization.gather_context", "status": "started", "timestamp": "2025-12-09T19:22:15.310734"}, "26": {"action_state": "story_bot.2_prioritization.gather_context", "status": "completed", "timestamp": "2025-12-09T19:22:15.343037", "outputs": {"instructions": {"action": "gather_context", "behavior": "2_prioritization", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["Which areas of the story map carry the most business or delivery risk?", "Which areas are expected to deliver the most value if delivered early?", "Which areas are the most complex or hardest to implement, relative to their value?", "Do you want thin slices to be as end-to-end as possible?", "Are there any components, capabilities, or services that need to be reused across multiple stories or features?", "Are there any project or program constraints that impact delivery order?", "Are there users or groups that must go first to enable others to follow?"], "evidence": ["Story map from Shape stage (epics, features, and initial story breakdown)", "Business cases or initiative briefs", "Project charters and delivery timelines", "Capability or architectural dependency maps", "User rollout or onboarding strategies", "Risk registers or readiness checklists", "Value modeling or impact estimation docs"]}}}}, "27": {"action_state": "story_bot.2_prioritization.build_knowledge", "status": "started", "timestamp": "2025-12-09T19:22:21.409040"}, "28": {"action_state": "story_bot.2_prioritization.build_knowledge", "status": "started", "timestamp": "2025-12-09T19:22:27.854656"}, "29": {"action_state": "story_bot.2_prioritization.build_knowledge", "status": "completed", "timestamp": "2025-12-09T19:22:27.872543", "outputs": {"instructions": {"knowledge_graph_template": {"_explanation": {"hierarchical": "sub_epics can contain: nested sub_epics or story_groups. sequential_order is always an integer (1, 2, 3, 4) - unique within parent, no decimals.", "connector": "Story groups: 'and' or 'or' (null for first group). Stories within groups: 'and' or 'or' (null for first story). Epics and sub_epics don't have connectors.", "domain_placement": "domain_concepts: 'local' if relevant to single sub_epic, 'global' if relevant to multiple sub_epics. Place at most specific level (local preferred), but elevate to parent if used by multiple children."}, "epics": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "domain_concepts": [{"name": "", "responsibilities": [{"name": "", "collaborators": []}]}], "sub_epics": [{"name": "", "users": [], "sequential_order": 1, "domain_concepts": [{"name": "", "responsibilities": [{"name": "", "collaborators": []}]}], "features": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "stories": [{"name": "", "users": [], "sequential_order": 1}]}]}], "features": [{"name": "", "users": [], "sequential_order": 1, "stories": [{"name": "", "users": [], "sequential_order": 1}]}]}], "increments": [{"name": "", "priority": 1, "epics": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "domain_concepts": [{"name": "", "responsibilities": [{"name": "", "collaborators": []}]}], "features": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "stories": [{"name": "", "users": [], "sequential_order": 1}]}]}]}, {"name": "", "priority": 2, "epics": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "domain_concepts": [{"name": "", "responsibilities": [{"name": "", "collaborators": []}]}], "features": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "stories": [{"name": "", "users": [], "sequential_order": 1}]}]}]}, {"name": "", "priority": 3, "epics": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "domain_concepts": [{"name": "", "responsibilities": [{"name": "", "collaborators": []}]}], "features": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "stories": [{"name": "", "users": [], "sequential_order": 1}]}]}]}]}, "knowledge_graph_config": {"name": "build_story_graph_increments", "path": "docs/stories", "template": "story_graph_increments.json", "output": "story-graph.json"}, "template_path": "C:\\dev\\augmented-teams\\agile_bot\\bots\\story_bot\\behaviors\\2_prioritization\\2_content\\1_knowledge_graph\\story_graph_increments.json", "config_path": "C:\\dev\\augmented-teams\\agile_bot\\bots\\story_bot\\behaviors\\2_prioritization\\2_content\\1_knowledge_graph\\build_story_graph_increments.json", "validation_rules": [{"rule_file": "apply_quality_tradeoffs_for_minimal_spine.json", "rule_content": {"description": "Apply quality trade-offs to create thin slicing spine and later increments. Decide what quality the spine will have, what parts will be manual, what logic can be excluded, and how to prioritize adding quality in later increments.", "examples": [{"do": {"description": "Make deliberate quality trade-offs to minimize spine size", "content": ["Decide what quality the spine of functionality will be to make it minimal", "Identify what parts will be manual (all manual, specific processes manual, manual back office, manual data access for admin)", "Determine what logic can be excluded to make it smaller (no exception handling, stub certain systems, hard code certain stuff)", "Plan what quality improvements will be added in later increments and how to prioritize them", "Use bare bones UX for the spine - minimal interface, basic functionality only", "Document quality trade-offs explicitly: what's manual, what's stubbed, what's hard-coded, what's excluded", "Consider repeating stories where introducing similar behavior but with additional qualities - use adjective + Noun + Verb pattern", "Name stories with quality adjectives: 'Manually Create Billing Report' (spine) vs 'Automatically Create Billing Report' (later increment)", "Name increments after the quality improvements they add: 'Automated Payment Processing', 'Dynamic Shipping Calculation', 'Admin Interface for Orders'", "", "Quality Trade-off Categories:", "- Manual Processes: All manual, specific processes are manual, manual back office, manual data access for admin", "- Logic Exclusion: No exception handling, stub certain systems, hard code certain stuff", "- UX Quality: Bare bones UX, minimal interface, basic functionality only", "- Integration: Stub external systems, hard code integrations, manual data transfer", "- Validation: Minimal validation, no edge case handling, basic error messages", "", "Example - Thin Slicing Spine Quality Decisions:", "Increment 1 (Thin Slicing Spine): Basic Order Placement - NOW", "  Stories:", "  - Manually Process Order Fulfillment", "  - Create Order with Stubbed Payment", "  - Display Order with Hard-coded Shipping Rates", "  Quality Trade-offs:", "  - Manual: Order fulfillment is manual (admin processes orders manually)", "  - Stubbed: Payment system is stubbed (returns success without actual processing)", "  - Hard-coded: Shipping rates are hard-coded (no dynamic calculation)", "  - No exception handling: Basic error messages only, no retry logic", "  - Bare bones UX: Simple form, no validation feedback, basic confirmation", "  - Manual admin: Admin accesses database directly to view orders", "", "Increment 2: Automated Payment Processing - NEXT", "  Stories:", "  - Automatically Process Payment (replaces stubbed payment)", "  - Handle Payment Exceptions", "  Quality Improvements:", "  - Replace payment stub with real payment gateway", "  - Add payment error handling and retry logic", "", "Increment 3: Automated Fulfillment and Dynamic Shipping - LATER", "  Stories:", "  - Automatically Process Order Fulfillment (replaces manual fulfillment)", "  - Calculate Dynamic Shipping Rates (replaces hard-coded rates)", "  - View Orders via Admin Interface (replaces manual database access)", "  Quality Improvements:", "  - Replace manual fulfillment with automated system", "  - Add dynamic shipping rate calculation", "  - Add admin interface for order management", "", "Example - Repeating Stories with Quality Adjectives:", "Increment 1 (Thin Slicing Spine): Manual Billing Processing", "  - Manually Create Billing Report", "  - Manually Process Invoice", "", "Increment 2: Automated Billing Processing", "  - Automatically Create Billing Report (same behavior, automated quality)", "  - Automatically Process Invoice (same behavior, automated quality)", "", "Pattern: <Adjective> <Noun> <Verb>", "- Manually/Automatically/Stubbed/Hard-coded/Bare-bones + Create/Process/Display + Object", "", "Increment Naming Examples:", "- 'Automated Payment Processing' (adds automation quality)", "- 'Dynamic Shipping Calculation' (adds dynamic calculation quality)", "- 'Admin Interface for Orders' (adds interface quality, replaces manual access)", "- 'Exception Handling for Payments' (adds error handling quality)", "- 'Validated Form Input' (adds validation quality, replaces bare bones UX)"]}, "dont": {"description": "Don't build full quality into thin slicing spine or skip documenting trade-offs", "content": ["Don't build full quality into the thin slicing spine - make it minimal", "Don't skip documenting quality trade-offs - be explicit about what's manual, stubbed, hard-coded", "Don't add exception handling, validation, or polish to the spine", "Don't integrate all systems in the spine - stub or hard-code where possible", "Don't build admin interfaces in the spine - use manual data access", "Don't create polished UX in the spine - use bare bones interface", "", "Wrong Examples:", "- Spine includes full exception handling and retry logic (too much quality)", "- Spine includes polished admin interface (should be manual data access)", "- Spine integrates all external systems (should stub or hard-code)", "- No documentation of what's manual vs automated (unclear trade-offs)", "- Spine includes comprehensive validation (should be minimal)", "- Quality trade-offs not prioritized for later increments", "- Increment named generically: 'Increment 2: Add Features' (should be 'Automated Payment Processing')", "- Increment name doesn't reflect quality: 'Payment System' (should be 'Automated Payment Processing' or 'Payment Integration Quality')"]}}]}}, {"rule_file": "archive_not_delete.json", "rule_content": {"description": "NEVER delete files or folders. Archive obsolete items to map/z_archive/[timestamp]/ instead.", "examples": [{"do": {"description": "Move obsolete folders to archive", "content": ["Move old folder to map/z_archive/20250121-143022/old-folder/"]}, "dont": {"description": "Never delete files or folders", "content": ["Delete obsolete folder (WRONG - should archive)"]}}]}}, {"rule_file": "design_vertical_slice_increments.json", "rule_content": {"description": "CRITICAL: Increments MUST be designed as vertical slices that deliver end-to-end working flows across multiple features/epics, NOT horizontal layers that complete one feature/epic at a time. Each increment must demonstrate complete working flow from start to finish.", "examples": [{"do": {"description": "Design increments as vertical slices - end-to-end flows across multiple epics/features", "content": ["Design increments as VERTICAL SLICES across multiple epics/features (thin end-to-end flows)", "Ensure each increment delivers a complete working flow from start to finish", "Include PARTIAL features from multiple epics in each increment", "Build increments that demonstrate end-to-end capability (data entry \u2192 processing \u2192 validation \u2192 persistence \u2192 display)", "Start with simplest end-to-end flow (basic happy path for simplest user/scenario)", "Layer subsequent increments to add complexity, additional users, edge cases, variations", "Think \"What's the thinnest slice that demonstrates the entire system working together?\"", "", "Layering Strategy:", "- Increment 1: Simplest user + simplest scenario + happy path only \u2192 Full end-to-end", "- Increment 2: Add complexity (more options, validations) + Additional user types \u2192 Full end-to-end", "- Increment 3: Add edge cases + Error handling + Advanced features \u2192 Full end-to-end", "- Increment 4: Add variations + Alternative flows + Optimizations \u2192 Full end-to-end", "", "Integration Points to Consider (each increment should demonstrate):", "- Data entry/input", "- Business logic/processing", "- Validation/error handling", "- Persistence/storage", "- Retrieval/loading", "- Display/output", "", "Example - Vertical Slice (End-to-End):", "Value Increment 1: Basic Character Creation Flow - NOW", "  Epic: Create Character (PARTIAL - minimal creation)", "    Feature: Enter Basic Info (2 stories - name, archetype only)", "    Feature: Assign Abilities (1 story - simple point buy)", "  Epic: Manage Character (PARTIAL - basic persistence)", "    Feature: Save Character (1 story - save to file)", "    Feature: Load Character (1 story - load from file)", "  Epic: Display Character (PARTIAL - basic view)", "    Feature: View Character Sheet (1 story - show basic info)", "", "Why: Each increment delivers COMPLETE END-TO-END flow. Increment 1 = basic creation \u2192 save \u2192 load \u2192 view."]}, "dont": {"description": "Don't design increments as horizontal layers - complete one feature/epic at a time", "content": ["Design increments as horizontal layers (complete Feature A, then Feature B, then Feature C)", "Build one epic/feature completely before touching another", "Create increments that only touch one area of the system", "Build increments that can't demonstrate working end-to-end flow", "Complete all features for one user type before starting another user type", "", "Example - Horizontal Layer (WRONG):", "Value Increment 1: Character Creation - NOW", "  Epic: Create Character (COMPLETE)", "    Feature: Enter Basic Info (ALL stories)", "    Feature: Assign Abilities (ALL stories)", "    Feature: Select Skills (ALL stories)", "", "Why Wrong: Increment 1 can't be tested end-to-end (no save/load). Can't deliver working software until Increment 2. Integration risks discovered late."]}}]}}, {"rule_file": "folder_structure_matches_hierarchy.json", "rule_content": {"description": "Folder structure must exactly match story map hierarchy. Epic/feature folders created inside docs/stories/ directory.", "examples": [{"do": {"description": "Create folders matching story map structure", "content": ["docs/stories/\ud83c\udfaf Epic Name/\u2699\ufe0f Feature Name/"]}, "dont": {"description": "Don't create folders at wrong level or with wrong names", "content": ["docs/stories/\ud83c\udfaf Epic Name/ (wrong level)", "OR", "docs/stories/Epic Name/ (missing emoji)"]}}]}}, {"rule_file": "identify_marketable_increments.json", "rule_content": {"description": "Identify marketable increments of value during prioritization, creating increment-organized view of the story map with delivery priorities and relative sizing.", "examples": [{"do": {"description": "Identify marketable increments with priorities and sizing", "content": ["Identify marketable increments of value during prioritization", "Create story-map-increments.md with MVI as top level", "Order increments by delivery priority (NOW/NEXT/LATER)", "Do just enough story mapping to extrapolate how many epics, features, and stories make up an increment", "Can have partial epics/features in an increment", "Use relative sizing to compare increments against previously delivered work", "", "Example:", "MVI 1: Basic Billing - NOW", "  Relative Size: Compared to Payment System v1", "  Epic: Direct Pay Billing (PARTIAL - 1 of 2 features)", "    Feature: Generate Customer Billing (5 stories)", "", "MVI 2: Advanced Features - NEXT", "  Epic: Direct Pay Billing (PARTIAL - remaining feature)", "    Feature: Configure Pricing (approx 5 stories)"]}, "dont": {"description": "Don't skip increment identification or use wrong priorities", "content": ["Over-elaborate story mapping during prioritization", "Skip increment identification", "Use High/Medium/Low (use NOW/NEXT/LATER instead)", "", "Wrong Example:", "Increment: API endpoints (no priority, no sizing)", "Priority: High/Medium/Low (WRONG - use NOW/NEXT/LATER)"]}}]}}], "token_estimate": 5190}}}, "30": {"action_state": "story_bot.2_prioritization.render_output", "status": "started", "timestamp": "2025-12-09T19:23:44.252245"}, "31": {"action_state": "story_bot.2_prioritization.render_output", "status": "completed", "timestamp": "2025-12-09T19:23:44.284993", "outputs": {"instructions": {"action": "render_output", "behavior": "2_prioritization", "base_instructions": ["\n**PROJECT PATH: C:\\dev\\augmented-teams\\demo\\mob_minion**\nAll render outputs must be written to paths relative to this project path, NOT to the bot's own directories.", "Render story map documents", "Render domain model documents", "Instantiate synchronizer class synchronizers.story_io.DrawIOSynchronizer and call render method with renderer_command='render-increments', input_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story_graph_increments.json, and output_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-map-increments.drawio"], "render_configs": [{"file": "behaviors\\2_prioritization\\2_content\\2_render\\render_increments_backlog.json", "config": {"name": "render_increments_backlog", "path": "docs/stories", "template": "story-map-increments-backlog-template.md"}}, {"file": "behaviors\\2_prioritization\\2_content\\2_render\\render_increments_backlog_txt.json", "config": {"name": "render_increments_backlog_txt", "path": "docs/stories", "renderer": "render_increments_backlog_txt.py", "template": "templates/story-map-increments-backlog.txt", "output": "story-map-increments-backlog.txt"}, "template": "# Incremental Backlog\n\n## Increment {priority}: {increment_name}\n\n- {actor} --> {story_name}\n- {actor} --> {story_name}\n- {actor} --> {story_name}\n\n## Increment {priority}: {increment_name}\n\n- {actor} --> {story_name}\n- {actor} --> {story_name}\n\nInstructions:\n- Flat list of stories per increment\n- No epic/sub-epic hierarchy shown\n- Format: \"- Actor --> Story Name\"\n- Stories listed in sequential order within increment\n- Simple backlog view for sprint planning\n\n"}, {"file": "behaviors\\2_prioritization\\2_content\\2_render\\render_increments_drawio.json", "config": {"name": "render_increments_drawio", "path": "docs/stories", "input": "story_graph_increments.json", "synchronizer": "synchronizers.story_io.DrawIOSynchronizer", "renderer_command": "render-increments", "output": "story-map-increments.drawio"}}, {"file": "behaviors\\2_prioritization\\2_content\\2_render\\render_increments_md.json", "config": {"name": "render_increments_md", "path": "docs/stories", "template": "story-map-increments.md"}}, {"file": "behaviors\\2_prioritization\\2_content\\2_render\\render_increments_txt.json", "config": {"name": "render_increments_txt", "path": "docs/stories", "renderer": "render_increments_txt.py", "template": "templates/story-map-increments.txt", "output": "story-map-increments.txt"}, "template": "## Increment {priority}: {increment_name}\n\n(E) {epic_name}\n    (E) {sub_epic_name}\n        (S) {actor} --> {story_name}\n        (S) {actor} --> {story_name}\n        (S) {actor} --> {story_name}\n    (E) {sub_epic_name}\n        (E) {nested_sub_epic_name}\n            (S) {actor} --> {story_name}\n            (S) {actor} --> {story_name}\n\n(E) {epic_name}\n    (E) {sub_epic_name}\n        (S) {actor} --> {story_name}\n\nInstructions:\n- Use (E) for Epics and Sub-Epics\n- Use (S) for Stories with 'Actor --> Story Name' format\n- Increments section uses FLAT story lists (no story groups, no connectors)\n- Stories shown directly under sub-epics in sequential order\n- Show actors with \"--> \" before story names\n- Use hierarchical indentation (spaces, not tabs)\n- Epic/Sub-Epic names: Verb-Noun format\n- Story names: Actor-Verb-Noun format\n\n"}], "project_path": "C:\\dev\\augmented-teams\\demo\\mob_minion"}}}, "32": {"action_state": "story_bot.2_prioritization.render_output", "status": "started", "timestamp": "2025-12-10T00:01:12.448766"}, "33": {"action_state": "story_bot.2_prioritization.render_output", "status": "completed", "timestamp": "2025-12-10T00:01:12.681698", "outputs": {"instructions": {"action": "render_output", "behavior": "2_prioritization", "base_instructions": ["\n**PROJECT PATH: C:\\dev\\augmented-teams\\demo\\mob_minion**\nAll render outputs must be written to paths relative to this project path, NOT to the bot's own directories.", "Instruction for render_output", "Instantiate synchronizer class synchronizers.story_io.DrawIOSynchronizer and call render method with renderer_command='render-increments', input_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json, and output_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-map-increments.drawio"], "render_configs": [{"file": "behaviors\\2_prioritization\\2_content\\2_render\\render_increments_backlog.json", "config": {"name": "render_increments_backlog", "path": "docs/stories", "template": "story-map-increments-backlog-template.md"}}, {"file": "behaviors\\2_prioritization\\2_content\\2_render\\render_increments_backlog_txt.json", "config": {"name": "render_increments_backlog_txt", "path": "docs/stories", "renderer": "render_increments_backlog_txt.py", "template": "templates/story-map-increments-backlog.txt", "output": "story-map-increments-backlog.txt"}, "template": "# Incremental Backlog\n\n## Increment {priority}: {increment_name}\n\n- {actor} --> {story_name}\n- {actor} --> {story_name}\n- {actor} --> {story_name}\n\n## Increment {priority}: {increment_name}\n\n- {actor} --> {story_name}\n- {actor} --> {story_name}\n\nInstructions:\n- Flat list of stories per increment\n- No epic/sub-epic hierarchy shown\n- Format: \"- Actor --> Story Name\"\n- Stories listed in sequential order within increment\n- Simple backlog view for sprint planning\n\n"}, {"file": "behaviors\\2_prioritization\\2_content\\2_render\\render_increments_drawio.json", "config": {"name": "render_increments_drawio", "path": "docs/stories", "input": "story-graph.json", "synchronizer": "synchronizers.story_io.DrawIOSynchronizer", "renderer_command": "render-increments", "output": "story-map-increments.drawio"}}, {"file": "behaviors\\2_prioritization\\2_content\\2_render\\render_increments_md.json", "config": {"name": "render_increments_md", "path": "docs/stories", "template": "story-map-increments.md"}}, {"file": "behaviors\\2_prioritization\\2_content\\2_render\\render_increments_txt.json", "config": {"name": "render_increments_txt", "path": "docs/stories", "renderer": "render_increments_txt.py", "template": "templates/story-map-increments.txt", "output": "story-map-increments.txt"}, "template": "## Increment {priority}: {increment_name}\n\n(E) {epic_name}\n    (E) {sub_epic_name}\n        (S) {actor} --> {story_name}\n        (S) {actor} --> {story_name}\n        (S) {actor} --> {story_name}\n    (E) {sub_epic_name}\n        (E) {nested_sub_epic_name}\n            (S) {actor} --> {story_name}\n            (S) {actor} --> {story_name}\n\n(E) {epic_name}\n    (E) {sub_epic_name}\n        (S) {actor} --> {story_name}\n\nInstructions:\n- Use (E) for Epics and Sub-Epics\n- Use (S) for Stories with 'Actor --> Story Name' format\n- Increments section uses FLAT story lists (no story groups, no connectors)\n- Stories shown directly under sub-epics in sequential order\n- Show actors with \"--> \" before story names\n- Use hierarchical indentation (spaces, not tabs)\n- Epic/Sub-Epic names: Verb-Noun format\n- Story names: Actor-Verb-Noun format\n\n"}], "project_path": "C:\\dev\\augmented-teams\\demo\\mob_minion"}}}, "34": {"action_state": "story_bot.2_prioritization.validate_rules", "status": "started", "timestamp": "2025-12-10T00:01:18.506323"}, "35": {"action_state": "story_bot.2_prioritization.validate_rules", "status": "completed", "timestamp": "2025-12-10T00:01:18.533329", "outputs": {"instructions": {"action": "validate_rules", "behavior": "2_prioritization", "base_instructions": ["Load and review clarification.json and planning.json", "Check Content Data against all rules listed above", "Generate a validation report", "Save the validation report to validation-report.md in docs/stories/", "", "**NEXT BEHAVIOR REMINDER:**", "After completing this behavior, the next behavior in sequence is `3_arrange`. When the user is ready to continue, remind them: 'The next behavior in sequence is `3_arrange`. Would you like to continue with `3_arrange` or work on a different behavior?'"], "validation_rules": [{"rule_file": "apply_quality_tradeoffs_for_minimal_spine.json", "rule_content": {"description": "Apply quality trade-offs to create thin slicing spine and later increments. Decide what quality the spine will have, what parts will be manual, what logic can be excluded, and how to prioritize adding quality in later increments.", "examples": [{"do": {"description": "Make deliberate quality trade-offs to minimize spine size", "content": ["Decide what quality the spine of functionality will be to make it minimal", "Identify what parts will be manual (all manual, specific processes manual, manual back office, manual data access for admin)", "Determine what logic can be excluded to make it smaller (no exception handling, stub certain systems, hard code certain stuff)", "Plan what quality improvements will be added in later increments and how to prioritize them", "Use bare bones UX for the spine - minimal interface, basic functionality only", "Document quality trade-offs explicitly: what's manual, what's stubbed, what's hard-coded, what's excluded", "Consider repeating stories where introducing similar behavior but with additional qualities - use adjective + Noun + Verb pattern", "Name stories with quality adjectives: 'Manually Create Billing Report' (spine) vs 'Automatically Create Billing Report' (later increment)", "Name increments after the quality improvements they add: 'Automated Payment Processing', 'Dynamic Shipping Calculation', 'Admin Interface for Orders'", "", "Quality Trade-off Categories:", "- Manual Processes: All manual, specific processes are manual, manual back office, manual data access for admin", "- Logic Exclusion: No exception handling, stub certain systems, hard code certain stuff", "- UX Quality: Bare bones UX, minimal interface, basic functionality only", "- Integration: Stub external systems, hard code integrations, manual data transfer", "- Validation: Minimal validation, no edge case handling, basic error messages", "", "Example - Thin Slicing Spine Quality Decisions:", "Increment 1 (Thin Slicing Spine): Basic Order Placement - NOW", "  Stories:", "  - Manually Process Order Fulfillment", "  - Create Order with Stubbed Payment", "  - Display Order with Hard-coded Shipping Rates", "  Quality Trade-offs:", "  - Manual: Order fulfillment is manual (admin processes orders manually)", "  - Stubbed: Payment system is stubbed (returns success without actual processing)", "  - Hard-coded: Shipping rates are hard-coded (no dynamic calculation)", "  - No exception handling: Basic error messages only, no retry logic", "  - Bare bones UX: Simple form, no validation feedback, basic confirmation", "  - Manual admin: Admin accesses database directly to view orders", "", "Increment 2: Automated Payment Processing - NEXT", "  Stories:", "  - Automatically Process Payment (replaces stubbed payment)", "  - Handle Payment Exceptions", "  Quality Improvements:", "  - Replace payment stub with real payment gateway", "  - Add payment error handling and retry logic", "", "Increment 3: Automated Fulfillment and Dynamic Shipping - LATER", "  Stories:", "  - Automatically Process Order Fulfillment (replaces manual fulfillment)", "  - Calculate Dynamic Shipping Rates (replaces hard-coded rates)", "  - View Orders via Admin Interface (replaces manual database access)", "  Quality Improvements:", "  - Replace manual fulfillment with automated system", "  - Add dynamic shipping rate calculation", "  - Add admin interface for order management", "", "Example - Repeating Stories with Quality Adjectives:", "Increment 1 (Thin Slicing Spine): Manual Billing Processing", "  - Manually Create Billing Report", "  - Manually Process Invoice", "", "Increment 2: Automated Billing Processing", "  - Automatically Create Billing Report (same behavior, automated quality)", "  - Automatically Process Invoice (same behavior, automated quality)", "", "Pattern: <Adjective> <Noun> <Verb>", "- Manually/Automatically/Stubbed/Hard-coded/Bare-bones + Create/Process/Display + Object", "", "Increment Naming Examples:", "- 'Automated Payment Processing' (adds automation quality)", "- 'Dynamic Shipping Calculation' (adds dynamic calculation quality)", "- 'Admin Interface for Orders' (adds interface quality, replaces manual access)", "- 'Exception Handling for Payments' (adds error handling quality)", "- 'Validated Form Input' (adds validation quality, replaces bare bones UX)"]}, "dont": {"description": "Don't build full quality into thin slicing spine or skip documenting trade-offs", "content": ["Don't build full quality into the thin slicing spine - make it minimal", "Don't skip documenting quality trade-offs - be explicit about what's manual, stubbed, hard-coded", "Don't add exception handling, validation, or polish to the spine", "Don't integrate all systems in the spine - stub or hard-code where possible", "Don't build admin interfaces in the spine - use manual data access", "Don't create polished UX in the spine - use bare bones interface", "", "Wrong Examples:", "- Spine includes full exception handling and retry logic (too much quality)", "- Spine includes polished admin interface (should be manual data access)", "- Spine integrates all external systems (should stub or hard-code)", "- No documentation of what's manual vs automated (unclear trade-offs)", "- Spine includes comprehensive validation (should be minimal)", "- Quality trade-offs not prioritized for later increments", "- Increment named generically: 'Increment 2: Add Features' (should be 'Automated Payment Processing')", "- Increment name doesn't reflect quality: 'Payment System' (should be 'Automated Payment Processing' or 'Payment Integration Quality')"]}}]}}, {"rule_file": "archive_not_delete.json", "rule_content": {"description": "NEVER delete files or folders. Archive obsolete items to map/z_archive/[timestamp]/ instead.", "examples": [{"do": {"description": "Move obsolete folders to archive", "content": ["Move old folder to map/z_archive/20250121-143022/old-folder/"]}, "dont": {"description": "Never delete files or folders", "content": ["Delete obsolete folder (WRONG - should archive)"]}}]}}, {"rule_file": "design_vertical_slice_increments.json", "rule_content": {"description": "CRITICAL: Increments MUST be designed as vertical slices that deliver end-to-end working flows across multiple features/epics, NOT horizontal layers that complete one feature/epic at a time. Each increment must demonstrate complete working flow from start to finish.", "examples": [{"do": {"description": "Design increments as vertical slices - end-to-end flows across multiple epics/features", "content": ["Design increments as VERTICAL SLICES across multiple epics/features (thin end-to-end flows)", "Ensure each increment delivers a complete working flow from start to finish", "Include PARTIAL features from multiple epics in each increment", "Build increments that demonstrate end-to-end capability (data entry \u2192 processing \u2192 validation \u2192 persistence \u2192 display)", "Start with simplest end-to-end flow (basic happy path for simplest user/scenario)", "Layer subsequent increments to add complexity, additional users, edge cases, variations", "Think \"What's the thinnest slice that demonstrates the entire system working together?\"", "", "Layering Strategy:", "- Increment 1: Simplest user + simplest scenario + happy path only \u2192 Full end-to-end", "- Increment 2: Add complexity (more options, validations) + Additional user types \u2192 Full end-to-end", "- Increment 3: Add edge cases + Error handling + Advanced features \u2192 Full end-to-end", "- Increment 4: Add variations + Alternative flows + Optimizations \u2192 Full end-to-end", "", "Integration Points to Consider (each increment should demonstrate):", "- Data entry/input", "- Business logic/processing", "- Validation/error handling", "- Persistence/storage", "- Retrieval/loading", "- Display/output", "", "Example - Vertical Slice (End-to-End):", "Value Increment 1: Basic Character Creation Flow - NOW", "  Epic: Create Character (PARTIAL - minimal creation)", "    Feature: Enter Basic Info (2 stories - name, archetype only)", "    Feature: Assign Abilities (1 story - simple point buy)", "  Epic: Manage Character (PARTIAL - basic persistence)", "    Feature: Save Character (1 story - save to file)", "    Feature: Load Character (1 story - load from file)", "  Epic: Display Character (PARTIAL - basic view)", "    Feature: View Character Sheet (1 story - show basic info)", "", "Why: Each increment delivers COMPLETE END-TO-END flow. Increment 1 = basic creation \u2192 save \u2192 load \u2192 view."]}, "dont": {"description": "Don't design increments as horizontal layers - complete one feature/epic at a time", "content": ["Design increments as horizontal layers (complete Feature A, then Feature B, then Feature C)", "Build one epic/feature completely before touching another", "Create increments that only touch one area of the system", "Build increments that can't demonstrate working end-to-end flow", "Complete all features for one user type before starting another user type", "", "Example - Horizontal Layer (WRONG):", "Value Increment 1: Character Creation - NOW", "  Epic: Create Character (COMPLETE)", "    Feature: Enter Basic Info (ALL stories)", "    Feature: Assign Abilities (ALL stories)", "    Feature: Select Skills (ALL stories)", "", "Why Wrong: Increment 1 can't be tested end-to-end (no save/load). Can't deliver working software until Increment 2. Integration risks discovered late."]}}]}}, {"rule_file": "folder_structure_matches_hierarchy.json", "rule_content": {"description": "Folder structure must exactly match story map hierarchy. Epic/feature folders created inside docs/stories/ directory.", "examples": [{"do": {"description": "Create folders matching story map structure", "content": ["docs/stories/\ud83c\udfaf Epic Name/\u2699\ufe0f Feature Name/"]}, "dont": {"description": "Don't create folders at wrong level or with wrong names", "content": ["docs/stories/\ud83c\udfaf Epic Name/ (wrong level)", "OR", "docs/stories/Epic Name/ (missing emoji)"]}}]}}, {"rule_file": "identify_marketable_increments.json", "rule_content": {"description": "Identify marketable increments of value during prioritization, creating increment-organized view of the story map with delivery priorities and relative sizing.", "examples": [{"do": {"description": "Identify marketable increments with priorities and sizing", "content": ["Identify marketable increments of value during prioritization", "Create story-map-increments.md with MVI as top level", "Order increments by delivery priority (NOW/NEXT/LATER)", "Do just enough story mapping to extrapolate how many epics, features, and stories make up an increment", "Can have partial epics/features in an increment", "Use relative sizing to compare increments against previously delivered work", "", "Example:", "MVI 1: Basic Billing - NOW", "  Relative Size: Compared to Payment System v1", "  Epic: Direct Pay Billing (PARTIAL - 1 of 2 features)", "    Feature: Generate Customer Billing (5 stories)", "", "MVI 2: Advanced Features - NEXT", "  Epic: Direct Pay Billing (PARTIAL - remaining feature)", "    Feature: Configure Pricing (approx 5 stories)"]}, "dont": {"description": "Don't skip increment identification or use wrong priorities", "content": ["Over-elaborate story mapping during prioritization", "Skip increment identification", "Use High/Medium/Low (use NOW/NEXT/LATER instead)", "", "Wrong Example:", "Increment: API endpoints (no priority, no sizing)", "Priority: High/Medium/Low (WRONG - use NOW/NEXT/LATER)"]}}]}}], "content_to_validate": {"project_location": "C:\\dev\\augmented-teams\\demo\\mob_minion", "rendered_outputs": ["C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-description.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-diagram.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json"], "clarification_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\clarification.json", "planning_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\planning.json", "report_path": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\validation-report.md"}}}}, "36": {"action_state": "story_bot.4_discovery.gather_context", "status": "started", "timestamp": "2025-12-10T00:01:27.090460"}, "37": {"action_state": "story_bot.4_discovery.gather_context", "status": "completed", "timestamp": "2025-12-10T00:01:27.126466", "outputs": {"instructions": {"action": "gather_context", "behavior": "4_discovery", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["What is the full scope of the next increment or release?", "What are the major workflows or process segments it touches?", "What systems, teams, or roles are involved across this flow?", "What story groupings or capabilities define this increment?", "What order or sequence do these stories need to follow?", "Where are the major transitions or integration points in the flow?", "Are any stories or features dependent on others being completed first?"], "evidence": ["Story map from Shape stage (overarching epics, features, and stories)", "Increments document from Prioritization stage (defined slices with priorities and sizing)", "User experience and customer journey maps", "Workflow diagrams or journey maps", "Program increment plans or release outlines", "Architecture or integration diagrams", "Dependency trackers or milestone maps"]}}}}, "38": {"action_state": "story_bot.4_discovery.gather_context", "status": "started", "timestamp": "2025-12-10T00:02:12.718861"}, "39": {"action_state": "story_bot.4_discovery.gather_context", "status": "completed", "timestamp": "2025-12-10T00:02:12.752901", "outputs": {"instructions": {"action": "gather_context", "behavior": "4_discovery", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["What is the full scope of the next increment or release?", "What are the major workflows or process segments it touches?", "What systems, teams, or roles are involved across this flow?", "What story groupings or capabilities define this increment?", "What order or sequence do these stories need to follow?", "Where are the major transitions or integration points in the flow?", "Are any stories or features dependent on others being completed first?"], "evidence": ["Story map from Shape stage (overarching epics, features, and stories)", "Increments document from Prioritization stage (defined slices with priorities and sizing)", "User experience and customer journey maps", "Workflow diagrams or journey maps", "Program increment plans or release outlines", "Architecture or integration diagrams", "Dependency trackers or milestone maps"]}}}}, "40": {"action_state": "story_bot.4_discovery.gather_context", "status": "started", "timestamp": "2025-12-10T00:02:15.063380"}, "41": {"action_state": "story_bot.4_discovery.gather_context", "status": "completed", "timestamp": "2025-12-10T00:02:15.098944", "outputs": {"instructions": {"action": "gather_context", "behavior": "4_discovery", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["What is the full scope of the next increment or release?", "What are the major workflows or process segments it touches?", "What systems, teams, or roles are involved across this flow?", "What story groupings or capabilities define this increment?", "What order or sequence do these stories need to follow?", "Where are the major transitions or integration points in the flow?", "Are any stories or features dependent on others being completed first?"], "evidence": ["Story map from Shape stage (overarching epics, features, and stories)", "Increments document from Prioritization stage (defined slices with priorities and sizing)", "User experience and customer journey maps", "Workflow diagrams or journey maps", "Program increment plans or release outlines", "Architecture or integration diagrams", "Dependency trackers or milestone maps"]}}}}, "42": {"action_state": "story_bot.4_discovery.gather_context", "status": "started", "timestamp": "2025-12-10T00:06:21.098337"}, "43": {"action_state": "story_bot.4_discovery.gather_context", "status": "completed", "timestamp": "2025-12-10T00:06:21.134074", "outputs": {"instructions": {"action": "gather_context", "behavior": "4_discovery", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["What is the full scope of the next increment or release?", "What are the major workflows or process segments it touches?", "What systems, teams, or roles are involved across this flow?", "What story groupings or capabilities define this increment?", "What order or sequence do these stories need to follow?", "Where are the major transitions or integration points in the flow?", "Are any stories or features dependent on others being completed first?"], "evidence": ["Story map from Shape stage (overarching epics, features, and stories)", "Increments document from Prioritization stage (defined slices with priorities and sizing)", "User experience and customer journey maps", "Workflow diagrams or journey maps", "Program increment plans or release outlines", "Architecture or integration diagrams", "Dependency trackers or milestone maps"]}}}}, "44": {"action_state": "story_bot.4_discovery.render_output", "status": "started", "timestamp": "2025-12-10T00:06:30.328143"}, "45": {"action_state": "story_bot.4_discovery.render_output", "status": "completed", "timestamp": "2025-12-10T00:06:30.509002", "outputs": {"instructions": {"action": "render_output", "behavior": "4_discovery", "base_instructions": ["\n**PROJECT PATH: C:\\dev\\augmented-teams\\demo\\mob_minion**\nAll render outputs must be written to paths relative to this project path, NOT to the bot's own directories.", "Instruction for render_output", "Instantiate synchronizer class synchronizers.story_io.DrawIOSynchronizer and call render method with renderer_command='render-discovery', input_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story_graph_increments.json, and output_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-map-discovery-{increment_names}.drawio", "Instantiate synchronizer class synchronizers.story_io.DrawIOSynchronizer and call render method with renderer_command='render-discovery', input_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json, and output_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-map-discovery-{increment_names}.drawio", "Instantiate synchronizer class synchronizers.story_io.DrawIOSynchronizer and call render method with renderer_command='render-outline', input_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json, and output_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-map-outline.drawio"], "render_instructions": {"behaviorName": "discovery", "instructions": ["**CRITICAL: Discovery Diagram Filename Requirements:**", "", "When rendering discovery diagrams using render-discovery command:", "", "1. **MANDATORY: Filename MUST include increment identifier**", "   - The renderer automatically modifies the output filename to include increment information", "   - Single increment: Appends increment name (sanitized) or priority number", "     - Example: 'story-map-discovery.drawio' \u2192 'story-map-discovery-Foundation-Create-Mob-and-Basic-Actions.drawio'", "     - Example: 'story-map-discovery.drawio' \u2192 'story-map-discovery-Increment-1.drawio' (if no name)", "   - Multiple increments: Appends priority numbers", "     - Example: 'story-map-discovery.drawio' \u2192 'story-map-discovery-Increments-1-2.drawio'", "", "2. **Filename Sanitization:**", "   - Increment names are sanitized: spaces \u2192 '-', special chars removed, alphanumeric + '-' + '_' only", "   - Long names may be truncated if needed (max 200 chars total filename)", "", "3. **When calling render-discovery CLI:**", "   - You may provide a base filename like 'story-map-discovery.drawio'", "   - The renderer will automatically append increment identifier", "   - OR provide full filename with increment info already included (renderer will not duplicate)", "", "4. **Verification:**", "   - After rendering, verify the output filename includes increment identifier", "   - Check the returned 'output_path' in the result to confirm final filename", "", "**This ensures discovery diagrams are uniquely identifiable by increment.**"]}, "render_configs": [{"file": "behaviors\\4_discovery\\2_content\\2_render\\render_discovery_increment_drawio.json", "config": {"name": "render_discovery_increment_drawio", "description": "Render discovery increment(s) to DrawIO diagram. Supports multiple increments.", "path": "docs/stories", "input": "story_graph_increments.json", "synchronizer": "synchronizers.story_io.DrawIOSynchronizer", "renderer_command": "render-discovery", "output": "story-map-discovery-{increment_names}.drawio", "parameters": {"increment_names": "{increment_names}"}}}, {"file": "behaviors\\4_discovery\\2_content\\2_render\\render_story_map.md.json", "config": {"name": "render_story_map", "path": "docs/stories", "template": "story-map.md", "output": "story-map.md"}, "template": "Levels have following meaning\nEpic\n    Feature\n        Story\n            AC\n\n{users} {epic}\n    {users} {sub Epric}\n        {users} {feature}\n                    {user} {story} or {user}{story} or {user}{story} or {user}{story}\n                    {user} {story}\n                    {user} {story}\n                {feature} \n\nInstructions:\n- Use actor-verb-noun language only\n- Epic names: Actor-Verb-Noun format (e.g., \"User Requests Story Map\", \"MCP Server Intercepts Tool Call\")\n- Feature names: Actor-Verb-Noun format (e.g., \"AI Chat Analyzes Request\", \"MCP Server Loads Agent\")\n- Story names: Actor-Verb-Noun format (e.g., \"User Provides Request in Chat\", \"FastMCP Receives Tool Call\")\n- Use tab-based indentation for hierarchy (epic at root, feature with one tab, story with two tabs)\n- No emojis, no boilerplate, just hierarchical structure\n\ndomain structure\n"}, {"file": "behaviors\\4_discovery\\2_content\\2_render\\render_story_map_discovery_drawio.json", "config": {"name": "render_story_map_discovery_drawio", "description": "Render discovery story map to DrawIO diagram. CRITICAL: Output filename MUST include increment identifier. The renderer automatically appends increment name(s) or priority number(s) to the filename. For single increment: uses increment name (sanitized) or priority number. For multiple increments: uses priority numbers like 'Increments-1-2-3'. Example: 'story-map-discovery.drawio' becomes 'story-map-discovery-Foundation-Create-Mob-and-Basic-Actions.drawio' or 'story-map-discovery-Increment-1.drawio'.", "path": "docs/stories", "input": "story-graph.json", "synchronizer": "synchronizers.story_io.DrawIOSynchronizer", "renderer_command": "render-discovery", "output": "story-map-discovery-{increment_names}.drawio", "parameters": {"increment_names": "{increment_names}"}}}, {"file": "behaviors\\4_discovery\\2_content\\2_render\\render_story_map_increments_backlog.md.json", "config": {"name": "render_story_map_increments_backlog", "path": "docs/stories", "template": "story-map-increments-backlog.md", "output": "{product_name_slug}-story-map-increments-backlog.md"}, "template": "# Incremental Backlog: {product_name}\n\n**Navigation:** [\ud83d\udccb Story Map](../map/{product_name_slug}-story-map.md) | [\ud83d\udcca Increments](../increments/{product_name_slug}-story-map-increments.md)\n\n**File Name**: `{product_name_slug}-story-map-increments-backlog.md`\n**Location**: `{solution_folder}/docs/stories/{product_name_slug}-story-map-increments-backlog.md`\n\n> **Purpose**: Flat list view of stories per increment for backlog management and sprint planning.\n\n## Increment <number>: <increment_name>\n\n- \ud83d\udcdd <Story Name>\n- \ud83d\udcdd <Story Name>\n- \ud83d\udcdd <Story Name>\n\n## Increment <number>: <increment_name>\n\n- \ud83d\udcdd <Story Name>\n- \ud83d\udcdd <Story Name>\n\n**Example:**\n## Increment 1: Initialize Behavior and Workflow\n\n- \ud83d\udcdd User provides project path in chat window\n- \ud83d\udcdd Project loads agent configuration from agent.json\n- \ud83d\udcdd Workflow creates first behavior state\n- \ud83d\udcdd Behavior presents clarification questions\n\n## Increment 2: Complete Story Shaping Flow\n\n- \ud83d\udcdd User answers clarification questions\n- \ud83d\udcdd AI generates story map structure\n- \ud83d\udcdd User reviews story map\n\n{increments_backlog}\n\n---\n\n## Source Material\n\n{source_material}\n\n"}, {"file": "behaviors\\4_discovery\\2_content\\2_render\\render_story_map_outline_drawio.json", "config": {"name": "render_story_map_outline_drawio", "path": "docs/stories", "input": "story-graph.json", "synchronizer": "synchronizers.story_io.DrawIOSynchronizer", "renderer_command": "render-outline", "output": "story-map-outline.drawio"}}], "project_path": "C:\\dev\\augmented-teams\\demo\\mob_minion"}}}, "46": {"action_state": "story_bot.5_exploration.gather_context", "status": "started", "timestamp": "2025-12-10T00:37:28.373695"}, "47": {"action_state": "story_bot.5_exploration.gather_context", "status": "completed", "timestamp": "2025-12-10T00:37:28.404242", "outputs": {"instructions": {"action": "gather_context", "behavior": "5_exploration", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["Which increment are we exploring?", "What is the overarching outcome or user goal that unites this increment?", "What is the first thing the user will try to do in this flow?", "What system reactions are expected for each user input?", "Are we capturing both behavioral (user-system) and domain (concept-relationship) criteria?", "Where do we 'pass the ball' between the user and system in this flow?", "What are the likely unknowns, edge cases, or domain complexities?", "Are there domain rules or constraints that govern this behavior?", "Do we need to split or merge stories based on how many acceptance criteria arise?", "Is this increment too large? Should it be broken into smaller increments?", "What is the right amount of acceptance criteria for each story?", "How will we walk through the first acceptance criteria to confirm clarity and alignment?", "What parts of this increment are likely to involve integration or coordination across systems?", "Where might technical uncertainty or architectural complexity push us toward more granular stories or smaller increments?"], "evidence": ["Story map from Shape stage (overarching epics, features, and stories)", "Discovery refinements from Discovery stage (enumerated stories for increment in focus)", "User interaction diagrams", "Low fidelity UX flows", "User Journeys or Workflow Diagrams", "Domain Models or Business Rules Documentation", "Behavior Maps or Interaction Scenarios", "Assumptions and Known Risks Logged from Earlier Phases"]}}}}, "48": {"action_state": "story_bot.5_exploration.decide_planning_criteria", "status": "started", "timestamp": "2025-12-10T00:37:54.564705"}, "49": {"action_state": "story_bot.5_exploration.decide_planning_criteria", "status": "completed", "timestamp": "2025-12-10T00:37:54.587729", "outputs": {"instructions": {"assumptions": ["Each story should include both behavioral and domain acceptance criteria", "Acceptance criteria define the end-to-end flow, not just isolated rules", "Behavioral criteria follow a 'When trigger, Then response' format", "Domain criteria describe structured responsibilities or rules around business concepts", "Exploration will result in story reshaping: merging, splitting, or re-scoping is expected", "ACs with same logic but different data should be consolidated", "ACs with different formulas should remain separate", "Domain AC belongs at increment level (aggregated from features), Behavioral AC at story level", "Story documentation (scenarios) belongs in specification_scenarios phase, NOT exploration phase"], "decision_criteria": {"acceptance_criteria_consolidation": {"description": "Acceptance criteria consolidation", "question": "When should we reuse or split acceptance criteria based on the same/Similar logic/formula?", "outcome": "Determines AC consolidation candidates", "options": ["Same logic, different data \u2192 Consolidate", "Different formulas \u2192 Keep separate", "Different validation rules \u2192 Keep separate"]}, "acceptance_criteria_count": {"description": "Acceptance criteria count", "question": "How do we know when a story has the right number of acceptance criteria?", "outcome": "Guides when to split or merge stories", "options": ["Stop when criteria capture a full back-and-forth (user-system-user). Ensures atomic and testable slices.", "Stop when each user goal or intent is covered. Emphasizes outcome-focused criteria.", "Ensure each criteria can be validated independently. Supports automated testability.", "Keep criteria grouped by domain rule or concept. Useful for business-heavy stories.", "Constrained to a certain reasonable number of acceptance criteria EG under 9"]}, "acceptance_criteria_granularity": {"description": "Acceptance criteria granularity", "question": "What level of granularity are we aiming for when exploring stories?", "outcome": "Determines how detailed each story's acceptance criteria and scope will be", "options": ["User-System Behavioral \u2013 Focus on each point of interaction (user input, system response). Ideal when precision in behavior is key.", "Business Rule \u2013 Explicit business rules being called out as acceptance criteria. Focus on domain rules and business logic that govern behavior.", "Inner System \u2013 Focus on technical interaction points, system-to-system communication, and internal system behavior", "Technical Planning Level \u2013 Technical activity-style acceptance criteria (e.g., 'this must be built', 'that must be built').  Sometimes useful for planning and coordination."]}}}}}, "50": {"action_state": "story_bot.5_exploration.build_knowledge", "status": "started", "timestamp": "2025-12-10T00:37:56.923823"}, "51": {"action_state": "story_bot.5_exploration.build_knowledge", "status": "completed", "timestamp": "2025-12-10T00:37:56.964899", "outputs": {"instructions": {"knowledge_graph_template": {"_explanation": {"hierarchical": "sub_epics can contain: nested sub_epics or story_groups. sequential_order is always an integer (1, 2, 3, 4) - unique within parent, no decimals.", "connector": "Story groups: 'and' or 'or' (null for first group). Stories within groups: 'and' or 'or' (null for first story). Epics and sub_epics don't have connectors.", "domain_placement": "domain_concepts: 'local' if relevant to single sub_epic, 'global' if relevant to multiple sub_epics. Place at most specific level (local preferred), but elevate to parent if used by multiple children.", "exploration_additions": "Stories include: optional, priority, Steps, acceptance_criteria. Story groups are used instead of features.", "increments_structure": "The 'increments' section is a MINIMAL REFERENCE VIEW. Stories in increments contain ONLY: name, users (optional), sequential_order. All story details (story_type, connector, Steps, acceptance_criteria, etc.) come from the main 'epics' section. Increments are just a copy of the outline view at the story level to map which stories belong to which increment."}, "epics": [{"name": "", "sequential_order": 1, "estimated_stories": null, "domain_concepts": [{"name": "", "responsibilities": [{"name": "", "collaborators": []}]}], "sub_epics": [{"name": "", "sequential_order": 1, "estimated_stories": null, "domain_concepts": [{"name": "", "responsibilities": [{"name": "", "collaborators": []}]}], "sub_epics": [], "story_groups": [{"type": "and", "connector": null, "sequential_order": 1, "stories": [{"name": "", "sequential_order": 1, "connector": null, "users": [], "story_type": "user", "optional": false, "priority": 1, "Steps": null, "acceptance_criteria": []}, {"name": "", "sequential_order": 2, "connector": "and", "users": [], "story_type": "user", "optional": false, "priority": 1, "Steps": null, "acceptance_criteria": []}]}, {"type": "and", "connector": "or", "sequential_order": 2, "stories": [{"name": "", "sequential_order": 1, "connector": null, "users": [], "story_type": "user", "optional": false, "priority": 1, "Steps": null, "acceptance_criteria": []}]}]}], "story_groups": []}], "increments": [{"name": "", "priority": 1, "epics": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "sub_epics": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "stories": [{"name": "", "users": [], "sequential_order": 1}]}]}]}]}, "knowledge_graph_config": {"name": "build_story_graph_explored", "path": "docs/stories", "template": "story-graph-explored-outline.json", "output": "story-graph-explored.json"}, "template_path": "C:\\dev\\augmented-teams\\agile_bot\\bots\\story_bot\\behaviors\\5_exploration\\2_content\\1_knowledge_graph\\story-graph-explored-outline.json", "config_path": "C:\\dev\\augmented-teams\\agile_bot\\bots\\story_bot\\behaviors\\5_exploration\\2_content\\1_knowledge_graph\\build_story_graph_explored.json", "validation_rules": [{"rule_file": "behavioral_ac_at_story_level.json", "rule_content": {"description": "Behavioral AC belongs at story level, written in increment exploration document (NOT story documents). Use When/Then format (NO Given clauses - save for scenarios). NEVER use consecutive WHEN statements - use AND WHEN for conditional branching.", "examples": [{"do": {"description": "AC in increment exploration document with When/Then format", "content": "Increment exploration document: Story 1 - Acceptance Criteria: (AC) WHEN user enters name (AC) THEN system saves to character sheet"}, "dont": {"description": "Don't put AC in story documents or use Given clauses", "content": "Story document: Acceptance Criteria: Given user is logged in, When... (WRONG - AC in story doc, has Given)"}}, {"do": {"description": "Use AND for additional conditions after WHEN, not consecutive WHEN", "content": "(AC) WHEN action completes (AC) AND Human says done (AC) THEN system saves state"}, "dont": {"description": "Don't use consecutive WHEN statements or 'AND WHEN'", "content": "(AC) WHEN action completes (AC) WHEN Human says done (WRONG - two WHEN in a row) OR (AC) AND WHEN next_action exists (WRONG - should be just AND on separate line)"}}, {"do": {"description": "THEN must be on its own line, not combined with WHEN", "content": "(AC) WHEN next_action is not null (AC) THEN Action injects instructions"}, "dont": {"description": "Don't combine WHEN and THEN on same line", "content": "(AC) WHEN next_action is not null, THEN Action injects instructions (WRONG - THEN should be separate line)"}}, {"do": {"description": "Don't prefix AC lines with 'and' or 'or'", "content": "(AC) WHEN condition (AC) THEN outcome (AC) AND detail"}, "dont": {"description": "Don't add 'and' before (AC)", "content": "and (AC) WHEN condition and (AC) THEN outcome (WRONG - remove 'and' before (AC))"}}]}}, {"rule_file": "enumerate_all_ac_permutations.json", "rule_content": {"description": "Enumerate ALL acceptance criteria permutations. Apply exhaustive logic decomposition at AC level.", "examples": [{"do": {"description": "List all validation paths and calculation branches", "content": "When user enters STR rank, then system validates (1-20 range) - When user enters invalid rank, then system shows error - When user enters valid rank, then system calculates modifier"}, "dont": {"description": "Don't skip AC permutations", "content": "When user enters rank, then system saves (missing validation and calculation ACs)"}}]}}, {"rule_file": "given_uses_state_language.json", "rule_content": {"description": "Given statements must use state-oriented language (not action-oriented). Given describes STATE, not actions.", "examples": [{"do": {"description": "Given uses state language", "content": "Given user is logged in (state) - Given character sheet exists (state)"}, "dont": {"description": "Given doesn't use action language", "content": "Given user logs in (action - WRONG) - Given system creates character (action - WRONG)"}}]}}, {"rule_file": "present_ac_consolidation.json", "rule_content": {"description": "Present AC consolidation review BEFORE finalizing. Identify similar ACs, ask domain expert questions, wait for user confirmation.", "examples": [{"do": {"description": "Present AC consolidation questions and wait for answers", "content": "CONSOLIDATION REVIEW: These ACs use same logic? [List ACs] \u2192 User answers \u2192 Apply decisions"}, "dont": {"description": "Don't automatically consolidate ACs without user confirmation", "content": "Auto-consolidate similar ACs (WRONG - must ask user first)"}}]}}, {"rule_file": "scenarios_cover_all_cases.json", "rule_content": {"description": "Scenarios must cover happy path, edge cases, and error cases based on acceptance criteria.", "examples": [{"do": {"description": "Complete scenario coverage", "content": "Happy path: User enters valid data \u2192 System saves. Edge case: User enters boundary value \u2192 System validates. Error case: User enters invalid data \u2192 System shows error."}, "dont": {"description": "Don't skip scenario types", "content": "Only happy path scenarios (missing edge cases and error cases)"}}]}}, {"rule_file": "scenarios_on_story_docs.json", "rule_content": {"description": "CRITICAL SCOPE: Scenarios work on STORY documents (\ud83d\udcdd *.md files), NOT feature documents. NEVER creates feature specification documents.", "examples": [{"do": {"description": "Add scenarios to story documents", "content": "docs/stories/Epic/Feature/\ud83d\udcdd Story Name.md - Scenarios section added"}, "dont": {"description": "Don't create feature specification documents", "content": "docs/stories/Epic/Feature/Feature Specification.md (WRONG - scenarios go in story docs)"}}]}}, {"rule_file": "use_background_for_common_setup.json", "rule_content": {"description": "Use Background for repeated Given steps across 3+ scenarios. Background contains only Given/And steps (no When/Then).", "examples": [{"do": {"description": "Background for shared context", "content": "Background: Given user is logged in And character sheet exists (used by 5 scenarios)"}, "dont": {"description": "Don't use Background for unique Given steps or include When/Then", "content": "Background: Given user logs in (action - WRONG) OR Background: When user clicks button (When/Then - WRONG)"}}]}}, {"rule_file": "use_scenario_outline_when_needed.json", "rule_content": {"description": "Use Scenario Outline with Examples when story warrants concrete data: formulas need validation, domain has named entities, parameter variations exist.", "examples": [{"do": {"description": "Scenario Outline for formulas or domain entities", "content": "Scenario Outline: Calculate ability modifier - Examples table with Rank 10\u21920, Rank 12\u2192+1, Rank 14\u2192+2"}, "dont": {"description": "Don't use Scenario Outline for simple behaviors", "content": "Scenario Outline: User clicks button (too simple - use regular scenario)"}}]}}], "token_estimate": 3164}}}, "52": {"action_state": "story_bot.5_exploration.render_output", "status": "started", "timestamp": "2025-12-10T00:38:24.989667"}, "53": {"action_state": "story_bot.5_exploration.render_output", "status": "completed", "timestamp": "2025-12-10T00:38:25.284368", "outputs": {"instructions": {"action": "render_output", "behavior": "5_exploration", "base_instructions": ["\n**PROJECT PATH: C:\\dev\\augmented-teams\\demo\\mob_minion**\nAll render outputs must be written to paths relative to this project path, NOT to the bot's own directories.", "Instruction for render_output", "Instantiate synchronizer class synchronizers.story_io.DrawIOSynchronizer and call render method with renderer_command='render-exploration', input_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph-explored.json, and output_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-map-explored-{scope}.drawio", "Instantiate synchronizer class synchronizers.story_io.DrawIOSynchronizer and call render method with renderer_command='render-exploration', input_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph-explored.json, and output_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-map-explored-{scope}.drawio"], "render_configs": [{"file": "behaviors\\5_exploration\\2_content\\2_render\\render_exploration_acceptance_criteria_drawio.json", "config": {"name": "render_exploration_acceptance_criteria_drawio", "description": "Render exploration acceptance criteria to DrawIO diagram. Supports multiple scopes.", "path": "docs/stories", "input": "story-graph-explored.json", "synchronizer": "synchronizers.story_io.DrawIOSynchronizer", "renderer_command": "render-exploration", "output": "story-map-explored-{scope}.drawio", "parameters": {"scope": "{scope}"}}}, {"file": "behaviors\\5_exploration\\2_content\\2_render\\render_story_exploration.md.json", "config": {"name": "render_story_exploration", "path": "docs/stories", "template": "story-exploration.md", "output": "{increment_name_slug}-exploration.md"}, "template": "# {increment_name} - Increment Exploration\n\n**Navigation:** [\ud83d\udccb Story Map](../map/{story_map_filename}) | [\ud83d\udcca Increments](../increments/{increments_filename})\n\n**File Name**: `{increment_name_slug}-exploration.md`\n**Location**: `{solution_folder}/docs/stories/{increment_name_slug}-exploration.md`\n\n**Priority:** {increment_priority}\n**Relative Size:** {increment_relative_size}\n\n## Increment Purpose\n\n<Actor> <verb> <noun> <outcome_description>\n\n**Example:**\nDelivers complete end-to-end flow for initializing a project and starting the first behavior so that users can begin story shaping workflows\n\n---\n\n## Domain AC (Increment Level)\n\n### Core Domain Concepts\n\n- <Concept>: <description>\n- <Concept>: <description>\n- <Concept>: <description>\n\n**Example:**\n- Agile Bot: Manages workflow execution and coordinates behaviors\n- Project: Provides project context and manages project state\n- Workflow: Manages behavior state transitions and action sequencing\n\n---\n\n### Domain Behaviors\n\n- <Concept> <verb> <noun>: <description>\n- <Concept> <verb> <noun>: <description>\n- <Concept> <verb> <noun>: <description>\n\n**Example:**\n- Agile Bot manages workflow execution: Coordinates behaviors and state transitions\n- Project provides project context: Supplies project path and agent configuration\n- Workflow manages behavior state: Tracks current behavior and available actions\n\n---\n\n### Domain Rules\n\n- <Rule description>: <constraint or requirement>\n- <Rule description>: <constraint or requirement>\n- <Rule description>: <constraint or requirement>\n\n**Example:**\n- Workflow State transitions are sequential: Must complete current action before moving to next\n- Agent configuration must exist: Project cannot initialize without valid agent.json\n- Behaviors must provide required context: Clarification questions must be answered before proceeding\n\n---\n\n## Stories ({story_count} total)\n\n### \ud83d\udcdd <Story Name>\n\n**Acceptance Criteria:**\n- **When** <action>, **then** <outcome>\n- **When** <action>, **then** <outcome>\n\n**Example:**\n### \ud83d\udcdd User provides project path in chat window\n\n**Acceptance Criteria:**\n- **When** user types project path, **then** AI Chat receives project path\n- **When** Project initializes with invalid path, **then** Project shows error message\n\n{stories_with_ac}\n\n---\n\n## Consolidation Decisions\n\n{consolidation_decisions}\n\n---\n\n## Domain Rules Referenced\n\n{domain_rules_referenced}\n\n---\n\n## Source Material\n\n{source_material}\n\n"}, {"file": "behaviors\\5_exploration\\2_content\\2_render\\render_story_exploration_drawio.json", "config": {"name": "render_story_exploration_drawio", "description": "Render exploration story map to DrawIO diagram. Supports multiple scopes.", "path": "docs/stories", "input": "story-graph-explored.json", "synchronizer": "synchronizers.story_io.DrawIOSynchronizer", "renderer_command": "render-exploration", "output": "story-map-explored-{scope}.drawio", "parameters": {"scope": "{scope}"}}}, {"file": "behaviors\\5_exploration\\2_content\\2_render\\render_story_map_txt.json", "config": {"name": "render_story_map", "path": "docs/stories", "template": "story-map.txt", "output": "story-map.txt"}}], "project_path": "C:\\dev\\augmented-teams\\demo\\mob_minion"}}}, "54": {"action_state": "story_bot.5_exploration.decide_planning_criteria", "status": "started", "timestamp": "2025-12-10T00:38:44.055448"}, "55": {"action_state": "story_bot.5_exploration.decide_planning_criteria", "status": "completed", "timestamp": "2025-12-10T00:38:44.083640", "outputs": {"instructions": {"assumptions": ["Each story should include both behavioral and domain acceptance criteria", "Acceptance criteria define the end-to-end flow, not just isolated rules", "Behavioral criteria follow a 'When trigger, Then response' format", "Domain criteria describe structured responsibilities or rules around business concepts", "Exploration will result in story reshaping: merging, splitting, or re-scoping is expected", "ACs with same logic but different data should be consolidated", "ACs with different formulas should remain separate", "Domain AC belongs at increment level (aggregated from features), Behavioral AC at story level", "Story documentation (scenarios) belongs in specification_scenarios phase, NOT exploration phase"], "decision_criteria": {"acceptance_criteria_consolidation": {"description": "Acceptance criteria consolidation", "question": "When should we reuse or split acceptance criteria based on the same/Similar logic/formula?", "outcome": "Determines AC consolidation candidates", "options": ["Same logic, different data \u2192 Consolidate", "Different formulas \u2192 Keep separate", "Different validation rules \u2192 Keep separate"]}, "acceptance_criteria_count": {"description": "Acceptance criteria count", "question": "How do we know when a story has the right number of acceptance criteria?", "outcome": "Guides when to split or merge stories", "options": ["Stop when criteria capture a full back-and-forth (user-system-user). Ensures atomic and testable slices.", "Stop when each user goal or intent is covered. Emphasizes outcome-focused criteria.", "Ensure each criteria can be validated independently. Supports automated testability.", "Keep criteria grouped by domain rule or concept. Useful for business-heavy stories.", "Constrained to a certain reasonable number of acceptance criteria EG under 9"]}, "acceptance_criteria_granularity": {"description": "Acceptance criteria granularity", "question": "What level of granularity are we aiming for when exploring stories?", "outcome": "Determines how detailed each story's acceptance criteria and scope will be", "options": ["User-System Behavioral \u2013 Focus on each point of interaction (user input, system response). Ideal when precision in behavior is key.", "Business Rule \u2013 Explicit business rules being called out as acceptance criteria. Focus on domain rules and business logic that govern behavior.", "Inner System \u2013 Focus on technical interaction points, system-to-system communication, and internal system behavior", "Technical Planning Level \u2013 Technical activity-style acceptance criteria (e.g., 'this must be built', 'that must be built').  Sometimes useful for planning and coordination."]}}}}}, "56": {"action_state": "story_bot.5_exploration.validate_rules", "status": "started", "timestamp": "2025-12-10T00:39:05.793083"}, "57": {"action_state": "story_bot.5_exploration.validate_rules", "status": "completed", "timestamp": "2025-12-10T00:39:05.828690", "outputs": {"instructions": {"action": "validate_rules", "behavior": "5_exploration", "base_instructions": ["Load and review clarification.json and planning.json", "Check Content Data against all rules listed above", "Generate a validation report", "Save the validation report to validation-report.md in docs/stories/", "", "**NEXT BEHAVIOR REMINDER:**", "After completing this behavior, the next behavior in sequence is `6_scenarios`. When the user is ready to continue, remind them: 'The next behavior in sequence is `6_scenarios`. Would you like to continue with `6_scenarios` or work on a different behavior?'"], "validation_rules": [{"rule_file": "behavioral_ac_at_story_level.json", "rule_content": {"description": "Behavioral AC belongs at story level, written in increment exploration document (NOT story documents). Use When/Then format (NO Given clauses - save for scenarios). NEVER use consecutive WHEN statements - use AND WHEN for conditional branching.", "examples": [{"do": {"description": "AC in increment exploration document with When/Then format", "content": "Increment exploration document: Story 1 - Acceptance Criteria: (AC) WHEN user enters name (AC) THEN system saves to character sheet"}, "dont": {"description": "Don't put AC in story documents or use Given clauses", "content": "Story document: Acceptance Criteria: Given user is logged in, When... (WRONG - AC in story doc, has Given)"}}, {"do": {"description": "Use AND for additional conditions after WHEN, not consecutive WHEN", "content": "(AC) WHEN action completes (AC) AND Human says done (AC) THEN system saves state"}, "dont": {"description": "Don't use consecutive WHEN statements or 'AND WHEN'", "content": "(AC) WHEN action completes (AC) WHEN Human says done (WRONG - two WHEN in a row) OR (AC) AND WHEN next_action exists (WRONG - should be just AND on separate line)"}}, {"do": {"description": "THEN must be on its own line, not combined with WHEN", "content": "(AC) WHEN next_action is not null (AC) THEN Action injects instructions"}, "dont": {"description": "Don't combine WHEN and THEN on same line", "content": "(AC) WHEN next_action is not null, THEN Action injects instructions (WRONG - THEN should be separate line)"}}, {"do": {"description": "Don't prefix AC lines with 'and' or 'or'", "content": "(AC) WHEN condition (AC) THEN outcome (AC) AND detail"}, "dont": {"description": "Don't add 'and' before (AC)", "content": "and (AC) WHEN condition and (AC) THEN outcome (WRONG - remove 'and' before (AC))"}}]}}, {"rule_file": "enumerate_all_ac_permutations.json", "rule_content": {"description": "Enumerate ALL acceptance criteria permutations. Apply exhaustive logic decomposition at AC level.", "examples": [{"do": {"description": "List all validation paths and calculation branches", "content": "When user enters STR rank, then system validates (1-20 range) - When user enters invalid rank, then system shows error - When user enters valid rank, then system calculates modifier"}, "dont": {"description": "Don't skip AC permutations", "content": "When user enters rank, then system saves (missing validation and calculation ACs)"}}]}}, {"rule_file": "given_uses_state_language.json", "rule_content": {"description": "Given statements must use state-oriented language (not action-oriented). Given describes STATE, not actions.", "examples": [{"do": {"description": "Given uses state language", "content": "Given user is logged in (state) - Given character sheet exists (state)"}, "dont": {"description": "Given doesn't use action language", "content": "Given user logs in (action - WRONG) - Given system creates character (action - WRONG)"}}]}}, {"rule_file": "present_ac_consolidation.json", "rule_content": {"description": "Present AC consolidation review BEFORE finalizing. Identify similar ACs, ask domain expert questions, wait for user confirmation.", "examples": [{"do": {"description": "Present AC consolidation questions and wait for answers", "content": "CONSOLIDATION REVIEW: These ACs use same logic? [List ACs] \u2192 User answers \u2192 Apply decisions"}, "dont": {"description": "Don't automatically consolidate ACs without user confirmation", "content": "Auto-consolidate similar ACs (WRONG - must ask user first)"}}]}}, {"rule_file": "scenarios_cover_all_cases.json", "rule_content": {"description": "Scenarios must cover happy path, edge cases, and error cases based on acceptance criteria.", "examples": [{"do": {"description": "Complete scenario coverage", "content": "Happy path: User enters valid data \u2192 System saves. Edge case: User enters boundary value \u2192 System validates. Error case: User enters invalid data \u2192 System shows error."}, "dont": {"description": "Don't skip scenario types", "content": "Only happy path scenarios (missing edge cases and error cases)"}}]}}, {"rule_file": "scenarios_on_story_docs.json", "rule_content": {"description": "CRITICAL SCOPE: Scenarios work on STORY documents (\ud83d\udcdd *.md files), NOT feature documents. NEVER creates feature specification documents.", "examples": [{"do": {"description": "Add scenarios to story documents", "content": "docs/stories/Epic/Feature/\ud83d\udcdd Story Name.md - Scenarios section added"}, "dont": {"description": "Don't create feature specification documents", "content": "docs/stories/Epic/Feature/Feature Specification.md (WRONG - scenarios go in story docs)"}}]}}, {"rule_file": "use_background_for_common_setup.json", "rule_content": {"description": "Use Background for repeated Given steps across 3+ scenarios. Background contains only Given/And steps (no When/Then).", "examples": [{"do": {"description": "Background for shared context", "content": "Background: Given user is logged in And character sheet exists (used by 5 scenarios)"}, "dont": {"description": "Don't use Background for unique Given steps or include When/Then", "content": "Background: Given user logs in (action - WRONG) OR Background: When user clicks button (When/Then - WRONG)"}}]}}, {"rule_file": "use_scenario_outline_when_needed.json", "rule_content": {"description": "Use Scenario Outline with Examples when story warrants concrete data: formulas need validation, domain has named entities, parameter variations exist.", "examples": [{"do": {"description": "Scenario Outline for formulas or domain entities", "content": "Scenario Outline: Calculate ability modifier - Examples table with Rank 10\u21920, Rank 12\u2192+1, Rank 14\u2192+2"}, "dont": {"description": "Don't use Scenario Outline for simple behaviors", "content": "Scenario Outline: User clicks button (too simple - use regular scenario)"}}]}}], "content_to_validate": {"project_location": "C:\\dev\\augmented-teams\\demo\\mob_minion", "rendered_outputs": ["C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-description.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-diagram.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json"], "clarification_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\clarification.json", "planning_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\planning.json", "report_path": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\validation-report.md"}}}}, "58": {"action_state": "story_bot.5_exploration.build_knowledge", "status": "started", "timestamp": "2025-12-10T00:56:18.891374"}, "59": {"action_state": "story_bot.5_exploration.build_knowledge", "status": "completed", "timestamp": "2025-12-10T00:56:18.979065", "outputs": {"instructions": {"knowledge_graph_template": {"_explanation": {"hierarchical": "sub_epics can contain: nested sub_epics or story_groups. sequential_order is always an integer (1, 2, 3, 4) - unique within parent, no decimals.", "connector": "Story groups: 'and' or 'or' (null for first group). Stories within groups: 'and' or 'or' (null for first story). Epics and sub_epics don't have connectors.", "domain_placement": "domain_concepts: 'local' if relevant to single sub_epic, 'global' if relevant to multiple sub_epics. Place at most specific level (local preferred), but elevate to parent if used by multiple children.", "exploration_additions": "Stories include: optional, priority, Steps, acceptance_criteria. Story groups are used instead of features.", "acceptance_criteria_format": "Each acceptance criteria is a SINGLE string containing one WHEN/THEN pair. Format: \"WHEN [condition]\\nTHEN [outcome]\" or \"WHEN [condition]\\nTHEN [outcome] AND [additional outcome]\". WHEN and THEN must be on separate lines (use \\n for newline). THEN and its AND must be together on the same line. Each WHEN condition starts a new acceptance criteria. Example: [\"WHEN user selects tokens\\nTHEN system highlights tokens AND tokens are stored\", \"WHEN user selects zero tokens\\nTHEN system shows error message\"]", "increments_structure": "The 'increments' section is a MINIMAL REFERENCE VIEW. Stories in increments contain ONLY: name, users (optional), sequential_order. All story details (story_type, connector, Steps, acceptance_criteria, etc.) come from the main 'epics' section. Increments are just a copy of the outline view at the story level to map which stories belong to which increment."}, "epics": [{"name": "", "sequential_order": 1, "estimated_stories": null, "domain_concepts": [{"name": "", "responsibilities": [{"name": "", "collaborators": []}]}], "sub_epics": [{"name": "", "sequential_order": 1, "estimated_stories": null, "domain_concepts": [{"name": "", "responsibilities": [{"name": "", "collaborators": []}]}], "sub_epics": [], "story_groups": [{"type": "and", "connector": null, "sequential_order": 1, "stories": [{"name": "", "sequential_order": 1, "connector": null, "users": [], "story_type": "user", "optional": false, "priority": 1, "Steps": null, "acceptance_criteria": ["WHEN [condition]\nTHEN [outcome]", "WHEN [condition]\nTHEN [outcome] AND [additional outcome]"]}, {"name": "", "sequential_order": 2, "connector": "and", "users": [], "story_type": "user", "optional": false, "priority": 1, "Steps": null, "acceptance_criteria": ["WHEN [condition]\nTHEN [outcome]", "WHEN [condition]\nTHEN [outcome] AND [additional outcome]"]}]}, {"type": "and", "connector": "or", "sequential_order": 2, "stories": [{"name": "", "sequential_order": 1, "connector": null, "users": [], "story_type": "user", "optional": false, "priority": 1, "Steps": null, "acceptance_criteria": ["WHEN [condition]\nTHEN [outcome]", "WHEN [condition]\nTHEN [outcome] AND [additional outcome]"]}]}]}], "story_groups": []}], "increments": [{"name": "", "priority": 1, "epics": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "sub_epics": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "stories": [{"name": "", "users": [], "sequential_order": 1}]}]}]}]}, "knowledge_graph_config": {"name": "build_story_graph_explored", "path": "docs/stories", "template": "story-graph-explored.json", "output": "story-graph.json"}, "template_path": "C:\\dev\\augmented-teams\\agile_bot\\bots\\story_bot\\behaviors\\5_exploration\\2_content\\1_knowledge_graph\\story-graph-explored.json", "config_path": "C:\\dev\\augmented-teams\\agile_bot\\bots\\story_bot\\behaviors\\5_exploration\\2_content\\1_knowledge_graph\\build_story_graph_explored.json", "existing_file": {"path": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json", "exists": true, "has_epics": true, "has_increments": true, "has_domain_concepts": true, "structure_summary": {"epic_count": 3, "has_increments": true}}, "update_mode": true, "update_instructions": {"mode": "update_existing", "message": "**CRITICAL: Output file 'story-graph.json' already exists at 'docs/stories/story-graph.json'. You MUST UPDATE this existing file by adding/modifying only the content needed for this behavior. DO NOT create a new file.**", "existing_file_path": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json", "preserve_existing": ["epics", "domain_concepts"], "add_or_modify": ["knowledge_graph"]}, "validation_rules": [{"rule_file": "behavioral_ac_at_story_level.json", "rule_content": {"description": "Behavioral AC belongs at story level, written in story-graph.json (main epics section). Use When/Then format (NO Given clauses - save for scenarios). Each acceptance criteria is a SINGLE string containing one WHEN/THEN pair. AND can be part of the same acceptance criteria, but THEN and its AND must be together in the same string.", "examples": [{"do": {"description": "Each acceptance criteria is a single string with WHEN/THEN", "content": "acceptance_criteria: [\"WHEN user enters name THEN system saves to character sheet\"]"}, "dont": {"description": "Don't split WHEN/THEN across multiple strings", "content": "acceptance_criteria: [\"WHEN user enters name\", \"THEN system saves to character sheet\"] (WRONG - should be one string)"}}, {"do": {"description": "THEN and its AND belong together in same acceptance criteria", "content": "acceptance_criteria: [\"WHEN action completes THEN system saves state AND system shows success message\"]"}, "dont": {"description": "Don't separate THEN and its AND into different strings", "content": "acceptance_criteria: [\"WHEN action completes\", \"THEN system saves state\", \"AND system shows success message\"] (WRONG - THEN and AND should be together)"}}, {"do": {"description": "Multiple separate ANDs become separate acceptance criteria if they are separate outcomes", "content": "acceptance_criteria: [\"WHEN tokens are selected THEN system queries Foundry VTT API\", \"WHEN tokens are selected THEN system retrieves actor ID for each token\"]"}, "dont": {"description": "Don't put separate outcomes in one acceptance criteria - but if AND is part of same outcome, keep together", "content": "acceptance_criteria: [\"WHEN tokens are selected THEN system queries Foundry VTT API AND system retrieves actor ID AND system stores position\"] (WRONG - if these are separate outcomes, they should be separate acceptance criteria)"}}, {"do": {"description": "Each WHEN condition starts a new acceptance criteria", "content": "acceptance_criteria: [\"WHEN Game Master selects tokens THEN system highlights tokens\", \"WHEN Game Master selects zero tokens THEN system shows error message\"]"}, "dont": {"description": "Don't combine different WHEN conditions", "content": "acceptance_criteria: [\"WHEN Game Master selects tokens THEN system highlights tokens WHEN Game Master selects zero tokens THEN system shows error\"] (WRONG - each WHEN needs its own acceptance criteria)"}}, {"do": {"description": "Correct format: WHEN/THEN/AND together in one string", "content": "acceptance_criteria: [\"WHEN Game Master selects tokens THEN system highlights selected tokens AND selected tokens are stored in temporary selection state\", \"WHEN Game Master selects zero tokens THEN system shows error message indicating at least one token must be selected\"]"}, "dont": {"description": "Wrong format: split across multiple strings", "content": "acceptance_criteria: [\"WHEN Game Master selects tokens\", \"THEN system highlights selected tokens\", \"AND selected tokens are stored in temporary selection state\"] (WRONG - should be one string)"}}]}}, {"rule_file": "enumerate_all_ac_permutations.json", "rule_content": {"description": "Enumerate ALL acceptance criteria permutations. Apply exhaustive logic decomposition at AC level.", "examples": [{"do": {"description": "List all validation paths and calculation branches", "content": "When user enters STR rank, then system validates (1-20 range) - When user enters invalid rank, then system shows error - When user enters valid rank, then system calculates modifier"}, "dont": {"description": "Don't skip AC permutations", "content": "When user enters rank, then system saves (missing validation and calculation ACs)"}}]}}, {"rule_file": "given_uses_state_language.json", "rule_content": {"description": "Given statements must use state-oriented language (not action-oriented). Given describes STATE, not actions.", "examples": [{"do": {"description": "Given uses state language", "content": "Given user is logged in (state) - Given character sheet exists (state)"}, "dont": {"description": "Given doesn't use action language", "content": "Given user logs in (action - WRONG) - Given system creates character (action - WRONG)"}}]}}, {"rule_file": "present_ac_consolidation.json", "rule_content": {"description": "Present AC consolidation review BEFORE finalizing. Identify similar ACs, ask domain expert questions, wait for user confirmation.", "examples": [{"do": {"description": "Present AC consolidation questions and wait for answers", "content": "CONSOLIDATION REVIEW: These ACs use same logic? [List ACs] \u2192 User answers \u2192 Apply decisions"}, "dont": {"description": "Don't automatically consolidate ACs without user confirmation", "content": "Auto-consolidate similar ACs (WRONG - must ask user first)"}}]}}, {"rule_file": "scenarios_cover_all_cases.json", "rule_content": {"description": "Scenarios must cover happy path, edge cases, and error cases based on acceptance criteria.", "examples": [{"do": {"description": "Complete scenario coverage", "content": "Happy path: User enters valid data \u2192 System saves. Edge case: User enters boundary value \u2192 System validates. Error case: User enters invalid data \u2192 System shows error."}, "dont": {"description": "Don't skip scenario types", "content": "Only happy path scenarios (missing edge cases and error cases)"}}]}}, {"rule_file": "scenarios_on_story_docs.json", "rule_content": {"description": "CRITICAL SCOPE: Scenarios work on STORY documents (\ud83d\udcdd *.md files), NOT feature documents. NEVER creates feature specification documents.", "examples": [{"do": {"description": "Add scenarios to story documents", "content": "docs/stories/Epic/Feature/\ud83d\udcdd Story Name.md - Scenarios section added"}, "dont": {"description": "Don't create feature specification documents", "content": "docs/stories/Epic/Feature/Feature Specification.md (WRONG - scenarios go in story docs)"}}]}}, {"rule_file": "use_background_for_common_setup.json", "rule_content": {"description": "Use Background for repeated Given steps across 3+ scenarios. Background contains only Given/And steps (no When/Then).", "examples": [{"do": {"description": "Background for shared context", "content": "Background: Given user is logged in And character sheet exists (used by 5 scenarios)"}, "dont": {"description": "Don't use Background for unique Given steps or include When/Then", "content": "Background: Given user logs in (action - WRONG) OR Background: When user clicks button (When/Then - WRONG)"}}]}}, {"rule_file": "use_scenario_outline_when_needed.json", "rule_content": {"description": "Use Scenario Outline with Examples when story warrants concrete data: formulas need validation, domain has named entities, parameter variations exist.", "examples": [{"do": {"description": "Scenario Outline for formulas or domain entities", "content": "Scenario Outline: Calculate ability modifier - Examples table with Rank 10\u21920, Rank 12\u2192+1, Rank 14\u2192+2"}, "dont": {"description": "Don't use Scenario Outline for simple behaviors", "content": "Scenario Outline: User clicks button (too simple - use regular scenario)"}}]}}], "token_estimate": 3991}}}, "60": {"action_state": "story_bot.6_scenarios.build_knowledge", "status": "started", "timestamp": "2025-12-10T00:56:49.777712"}, "61": {"action_state": "story_bot.6_scenarios.build_knowledge", "status": "started", "timestamp": "2025-12-10T00:56:49.973901"}, "62": {"action_state": "story_bot.6_scenarios.build_knowledge", "status": "started", "timestamp": "2025-12-10T00:59:08.730860"}, "63": {"action_state": "story_bot.6_scenarios.build_knowledge", "status": "started", "timestamp": "2025-12-10T00:59:25.283041"}, "64": {"action_state": "story_bot.6_scenarios.build_knowledge", "status": "started", "timestamp": "2025-12-10T00:59:47.106625"}, "65": {"action_state": "story_bot.6_scenarios.build_knowledge", "status": "started", "timestamp": "2025-12-10T00:59:57.023071"}, "66": {"action_state": "story_bot.6_scenarios.build_knowledge", "status": "started", "timestamp": "2025-12-10T01:00:45.336005"}, "67": {"action_state": "story_bot.6_scenarios.build_knowledge", "status": "started", "timestamp": "2025-12-10T01:02:33.609796"}, "68": {"action_state": "story_bot.6_scenarios.build_knowledge", "status": "started", "timestamp": "2025-12-10T01:04:28.152293"}, "69": {"action_state": "story_bot.scenarios.build_knowledge", "status": "started", "timestamp": "2025-12-10T01:04:43.879440"}, "70": {"action_state": "story_bot.6_scenarios.build_knowledge", "status": "started", "timestamp": "2025-12-10T01:05:04.428306"}, "71": {"action_state": "story_bot.6_scenarios.build_knowledge", "status": "completed", "timestamp": "2025-12-10T01:05:04.470812", "outputs": {"instructions": {"knowledge_graph_template": {"_explanation": {"hierarchical": "sub_epics can contain: nested sub_epics or story_groups. sequential_order is always an integer (1, 2, 3, 4) - unique within parent, no decimals.", "connector": "Story groups: 'and' or 'or' (null for first group). Stories within groups: 'and' or 'or' (null for first story). Epics and sub_epics don't have connectors.", "domain_placement": "domain_concepts: 'local' if relevant to single sub_epic, 'global' if relevant to multiple sub_epics. Place at most specific level (local preferred), but elevate to parent if used by multiple children.", "scenarios": "Each story contains scenarios (happy_path, edge_case, error_case) with background and steps in Gherkin format.", "scenario_outlines": "When decision criteria chooses Scenario Outline, stories may contain scenario_outlines with Examples tables for data-driven testing. Every variable in Steps must have a column in Examples table. Examples table must include both input and output/expected result variables.", "increments_structure": "The 'increments' section is a MINIMAL REFERENCE VIEW. Stories in increments contain ONLY: name, users (optional), sequential_order. All story details (story_type, connector, scenarios, scenario_outlines, Steps, acceptance_criteria, etc.) come from the main 'epics' section. Increments are just a copy of the outline view at the story level to map which stories belong to which increment."}, "epics": [{"name": "", "sequential_order": 1, "estimated_stories": null, "domain_concepts": [{"name": "", "responsibilities": [{"name": "", "collaborators": []}]}], "sub_epics": [{"name": "", "sequential_order": 1, "estimated_stories": null, "domain_concepts": [{"name": "", "responsibilities": [{"name": "", "collaborators": []}]}], "sub_epics": [], "story_groups": [{"type": "and", "connector": null, "sequential_order": 1, "stories": [{"name": "", "sequential_order": 1, "connector": null, "users": [], "story_type": "user", "scenarios": [{"name": "", "type": "happy_path|edge_case|error_case", "background": ["Given <common_setup_step>", "And <another_common_setup>"], "steps": ["Given <scenario_specific_state>", "And <scenario_specific_setup>", "When <user_action_or_system_event>", "Then <expected_outcome>", "And <another_expected_outcome>"]}], "scenario_outlines": [{"name": "", "type": "happy_path|edge_case|error_case", "background": ["Given <common_setup_step>", "And <another_common_setup>"], "steps": ["Given <scenario_specific_state> at \"<variable_path>\"", "And <entity> exists at \"<variable_file_path>\"", "When <action> with <variable_parameter>=\"<variable_value>\"", "Then <expected_outcome> equals \"<variable_expected_result>\"", "And <another_outcome> is \"<variable_result>\""], "examples": {"columns": ["variable_path", "variable_file_path", "variable_parameter", "variable_value", "variable_expected_result", "variable_result"], "rows": [["value1", "value2", "value3", "value4", "result1", "result2"], ["value5", "value6", "value7", "value8", "result3", "result4"]]}}]}]}]}], "stories": []}], "increments": [{"name": "", "priority": 1, "epics": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "sub_epics": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "stories": [{"name": "", "users": [], "sequential_order": 1}]}]}]}], "generated_artifacts": {"story_documents": {"description": "Story documents with scenarios section added", "location": "docs/stories/{epic_name}/{sub_epic_name}/{story_name}.md", "content": ["Story description", "Acceptance criteria", "Background (common setup steps)", "Scenarios (happy path, edge cases, error cases)", "Scenario Outlines with Examples tables (when decision criteria chosen)"]}, "structured_data": {"description": "JSON representation of stoy graph with scenarios added", "location": "docs/stories/story-graph.json", "content": ["Epic/sub_epic/story_group/story hierarchy", "Scenario definitions with steps", "Scenario Outline definitions with Examples tables (when decision criteria chosen)", "Background steps per story", "Scenario types (happy_path, edge_case, error_case)", "Connectors for story groups and stories"]}}}, "knowledge_graph_config": {"name": "build_story_scenarios", "description": "Build story graph with scenarios added to each story (and scenario outlines with examples if decision criteria chosen)", "input": "docs/stories/story-graph.json", "output": "docs/stories/story-graph.json", "template": "story-graph-scenarios.json", "process": ["Check decision criteria: agile_bot/bots/story_bot/behaviors/6_scenarios/1_guardrails/planning/decision_criteria/scenario_outline.json", "Load existing story graph from project area", "For each story in graph, analyze acceptance criteria", "Generate scenarios (happy_path, edge_case, error_case)", "IF decision criteria = 'Yes': Identify scenarios needing data variation and convert to Scenario Outlines with Examples tables", "Add scenarios to story in graph (and scenario_outlines if decision criteria = 'Yes')", "Save updated story graph to project area"]}, "template_path": "C:\\dev\\augmented-teams\\agile_bot\\bots\\story_bot\\behaviors\\6_scenarios\\2_content\\1_knowledge_graph\\story-graph-scenarios.json", "config_path": "C:\\dev\\augmented-teams\\agile_bot\\bots\\story_bot\\behaviors\\6_scenarios\\2_content\\1_knowledge_graph\\build_story_scenarios.json", "validation_rules": [{"rule_file": "given_describes_preconditions_not_functionality.json", "rule_content": {"description": "CRITICAL: Given statements describe PRECONDITIONS (what exists before the test), NOT the functionality being tested. If you're describing WHAT the system does or HOW it behaves, that belongs in Then statements, not Given.", "examples": [{"do": {"description": "Given describes preconditions only", "content": ["CORRECT:", "Given activity log is initialized at project_area/activity log", "Given user is logged in", "Given character sheet exists", "Given workflow state is persisted", "", "These describe STATE/EXISTENCE, not functionality."]}, "dont": {"description": "Don't describe functionality in Given - that's what you're testing", "content": ["WRONG:", "Given activity log tracks: timestamp, action_state, inputs, outputs, duration", "(This describes WHAT the activity log DOES - that's the functionality being tested!)", "", "Given system validates user input", "(This describes WHAT the system DOES - that's functionality, not a precondition!)", "", "Given bot routes to correct action based on workflow state", "(This describes HOW the bot BEHAVES - that's what you're testing!)", "", "Ask yourself: Am I describing WHAT EXISTS or WHAT THE SYSTEM DOES?", "- If describing WHAT EXISTS \u2192 Given (precondition)", "- If describing WHAT THE SYSTEM DOES \u2192 Then (expected behavior being tested)", "", "Common mistakes:", "- Describing data structure/format in Given (that's functionality to test in Then)", "- Describing system behavior in Given (that's what you're testing in Then)", "- Describing validation rules in Given (that's functionality to test in Then)", "", "CORRECT approach:", "Given activity log is initialized (precondition - it exists)", "When action completes", "Then activity log captures: timestamp, action_state, inputs, outputs, duration (functionality being tested)"]}}]}}, {"rule_file": "given_describes_state_not_actions.json", "rule_content": {"description": "CRITICAL: Given statements describe STATE/CONFIGURATION, never actions or events. The first action in a scenario is ALWAYS a When, never a Given. Given sets up preconditions, When triggers the behavior being tested.", "examples": [{"do": {"description": "Given describes state, When triggers action", "content": ["CORRECT:", "Given a bot with name 'test_bot'", "And bot has a behavior configured as 'shape'", "And behavior has action 'gather_context'", "When Tool invokes test_bot.Shape.GatherContext() method", "", "Given = STATE (bot exists, is configured)", "When = ACTION (tool invokes method)"]}, "dont": {"description": "Don't use Given for actions - first action is ALWAYS When", "content": ["WRONG:", "Given Tool has invoked test_bot.Shape.GatherContext() method", "", "This is WRONG because 'invoked' is an ACTION, not a state.", "The scenario's first action must be When, not Given.", "", "Other common mistakes:", "- Given user clicks button (WRONG - clicking is action, use When)", "- Given system sends message (WRONG - sending is action, use When)", "- Given API is called (WRONG - calling is action, use When)", "- Given tool executes (WRONG - executing is action, use When)"]}}, {"do": {"description": "Given = preconditions (state), When = trigger (action), Then = outcomes", "content": ["Structure of every scenario:", "", "Given <state/config> - What exists, is configured, is true BEFORE the action", "And <more state> - Additional preconditions", "When <action> - The ONE thing that triggers the behavior (external stimulus)", "Then <outcome> - What should happen as a result", "And <more outcomes> - Additional expected results", "", "Example:", "Given a bot with name 'test_bot' (STATE - bot exists)", "And bot has behavior configured as 'shape' (STATE - configured)", "When Tool invokes test_bot.Shape.GatherContext() (ACTION - trigger)", "Then Action loads instructions (OUTCOME - result)", "And Action merges instructions (OUTCOME - more results)"]}, "dont": {"description": "Don't confuse state with actions", "content": ["Ask yourself: Is this describing WHAT EXISTS or WHAT HAPPENS?", "", "If it describes WHAT EXISTS \u2192 Given", "If it describes WHAT HAPPENS \u2192 When (if first action) or Then (if result)", "", "WRONG patterns to avoid:", "- Given <something> happened (past tense action \u2192 use When)", "- Given <actor> does <action> (present tense action \u2192 use When)", "- Given <system> executes <process> (action \u2192 use When)"]}}]}}, {"rule_file": "given_uses_state_language.json", "rule_content": {"description": "Given statements must use state-oriented language (not action-oriented). Given describes STATE, not actions.", "examples": [{"do": {"description": "Given uses state language", "content": ["Given user is logged in (state)", "Given character sheet exists (state)"]}, "dont": {"description": "Given doesn't use action language", "content": ["Given user logs in (action - WRONG)", "Given system creates character (action - WRONG)"]}}]}}, {"rule_file": "scenarios_cover_all_cases.json", "rule_content": {"description": "Scenarios must cover happy path, edge cases, and error cases based on acceptance criteria.", "examples": [{"do": {"description": "Complete scenario coverage", "content": ["Happy path: User enters valid data \u2192 System saves.", "Edge case: User enters boundary value \u2192 System validates.", "Error case: User enters invalid data \u2192 System shows error."]}, "dont": {"description": "Don't skip scenario types", "content": ["Only happy path scenarios (missing edge cases and error cases)"]}}]}}, {"rule_file": "scenarios_on_story_docs.json", "rule_content": {"description": "CRITICAL SCOPE: Scenarios work on STORY documents (\ud83d\udcdd *.md files), NOT feature documents. NEVER creates feature specification documents.", "examples": [{"do": {"description": "Add scenarios to story documents", "content": ["docs/stories/Epic/Feature/\ud83d\udcdd Story Name.md - Scenarios section added"]}, "dont": {"description": "Don't create feature specification documents", "content": ["docs/stories/Epic/Feature/Feature Specification.md (WRONG - scenarios go in story docs)"]}}]}}, {"rule_file": "scenario_steps_start_with_scenario_specific_given.json", "rule_content": {"description": "CRITICAL: Each scenario's Steps section starts with Given steps for scenario-specific setup. Background steps are automatically applied before scenario Steps. Scenario Steps should contain setup specific to THIS scenario only, not common setup that belongs in Background.", "examples": [{"do": {"description": "What goes in scenario Steps Given section - Scenario-specific setup only", "content": ["**What goes in scenario Steps Given section:**", "- Setup specific to THIS scenario only", "- Variable-dependent setup (even if similar across scenarios)", "- Test data setup (paths, file names, etc.)", "- Scenario-specific preconditions", "- Any setup that is NOT true for ALL scenarios", "", "**GOOD Example structure:**", "- Background has: \"Given Agent is initialized with agent_name='story_bot'\" (common to ALL scenarios)", "- Background has: \"Given Project is finished initializing\" (common to ALL scenarios)", "- Scenario Steps start with: \"Given test project area is set up at test_data/projects/valid-project\" (scenario-specific)", "- Scenario Steps continue with: \"And valid base agent.json exists at test_data/agents/base/agent.json\" (scenario-specific)", "", "**Example scenario Steps:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And valid base agent.json exists at test_data/agents/base/agent.json", "When Project initializes with project_path='test_data/projects/valid-project'", "Then Project loads agent configuration from agent.json", "```"]}, "dont": {"description": "Don't put common setup in scenario Steps or scenario-specific setup in Background", "content": ["**BAD Example (what NOT to do):**", "- Background has: \"Given test project area is set up at test_data/projects/valid-project\" (WRONG - this is scenario-specific)", "- Scenario Steps start with: \"Given Agent is initialized\" (WRONG - this belongs in Background if true for all scenarios)", "", "**Common mistakes:**", "- Including common setup in scenario Steps that should be in Background", "- Including scenario-specific setup in Background that should be in scenario Steps", "- Repeating Background steps in scenario Steps (Background is automatically applied)", "", "**WRONG Example:**", "```gherkin", "Given Agent is initialized with agent_name='story_bot'", "And Project is finished initializing", "And test project area is set up at test_data/projects/valid-project", "When Project initializes", "```", "(WRONG - first two Given steps belong in Background, only last Given is scenario-specific)"]}}]}}, {"rule_file": "story_filename_matches_story_name.json", "rule_content": {"description": "CRITICAL: Story filenames must match the story name exactly (no actor prefix). Actor information belongs in story description or acceptance criteria, NOT in the filename.", "examples": [{"do": {"description": "Filename matches story name without actor", "content": ["CORRECT:", "Story name: 'Route To MCP Behavior Tool'", "Filename: \ud83d\udcdd Route To MCP Behavior Tool.md", "", "Story name: 'Saves Behavior State'", "Filename: \ud83d\udcdd Saves Behavior State.md", "", "Story name: 'Track Activity for Gather Context Action'", "Filename: \ud83d\udcdd Track Activity for Gather Context Action.md"]}, "dont": {"description": "Don't include actor name in filename", "content": ["WRONG:", "Story name: 'Route To MCP Behavior Tool'", "Filename: \ud83d\udcdd AI Chat Route To MCP Behavior Tool.md", "(Actor 'AI Chat' should NOT be in filename)", "", "Story name: 'Saves Behavior State'", "Filename: \ud83d\udcdd Bot Behavior Saves Behavior State.md", "(Actor 'Bot Behavior' should NOT be in filename)", "", "Story name: 'Track Activity for Gather Context Action'", "Filename: \ud83d\udcdd GatherContextAction Track Activity.md", "(Actor 'GatherContextAction' should NOT be in filename)", "", "Common mistakes:", "- Including actor/user name from story description in filename", "- Prefixing filename with 'AI Chat', 'Router', 'Bot Behavior', etc.", "- Adding class/component names to filename", "", "Actor information belongs in:", "- Story description", "- Acceptance criteria (WHEN actor does X...)", "- NOT in the filename"]}}]}}, {"rule_file": "use_background_for_common_setup.json", "rule_content": {"description": "CRITICAL: Background section is ONLY for common setup steps shared across 3+ scenarios. DO NOT include scenario-specific setup here. Background contains only Given/And steps (no When/Then). Scenario-specific setup goes in scenario Steps as Given steps, not in Background.", "examples": [{"do": {"description": "What belongs in Background - Setup steps that are TRUE for ALL scenarios (100% of scenarios)", "content": ["**What belongs in Background:**", "- Setup steps that are TRUE for ALL scenarios in this story (100% of scenarios)", "- Common preconditions that every single scenario needs", "- Shared system state that applies to all scenarios without exception", "- Steps that never vary between scenarios", "", "**Examples of valid Background steps:**", "- Given Agent is initialized with agent_name='story_bot' (true for ALL scenarios)", "- Given Cursor/VS Code chat window is open (true for ALL scenarios)", "- Given Project is finished initializing (true for ALL scenarios)", "", "**GOOD Example:**", "```gherkin", "Given Agent is initialized with agent_name='story_bot'", "And Project is finished initializing", "```", "These are true for ALL scenarios in that story."]}, "dont": {"description": "What does NOT belong in Background - Scenario-specific or variable-dependent setup", "content": ["**What does NOT belong in Background:**", "- Scenario-specific setup (goes in scenario Steps as Given)", "- Variable-dependent setup (goes in scenario Steps)", "- Setup that only applies to some scenarios (goes in scenario Steps)", "- Test data paths or file names (goes in scenario Steps)", "- Conditional setup (goes in scenario Steps)", "", "**Examples of invalid Background steps:**", "- Given test project area is set up at test_data/projects/valid-project (WRONG - scenario-specific, goes in Steps)", "- Given user has attached documents to chat window (WRONG if not true for ALL scenarios - check if all scenarios need this)", "", "**BAD Example:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And test agent base area is set up at test_data/agents/base", "```", "These are scenario-specific and belong in scenario Steps, not Background."]}}, {"do": {"description": "Background for shared context, scenario-specific Given in Steps", "content": ["## Background", "", "**Common setup steps shared across all scenarios:**", "", "```gherkin", "Given Agent is initialized with agent_name='story_bot'", "And Project is finished initializing", "```", "", "## Scenarios", "", "### Scenario: Agent loads configurations", "", "**Steps:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And valid base agent.json exists at test_data/agents/base/agent.json", "When Project initializes with project_path='test_data/projects/valid-project'", "Then Project loads agent configuration from agent.json", "```", "", "**Key points:**", "- Background has common setup (true for ALL scenarios)", "- Scenario Steps start with scenario-specific Given steps", "- Background steps are automatically applied before scenario Steps"]}, "dont": {"description": "Don't put scenario-specific setup in Background or repeat Background in each scenario", "content": ["**BAD Example (what NOT to do):**", "", "## Background", "", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "```", "", "### Scenario: Agent loads configurations", "", "**Background:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And Project is finished initializing", "```", "", "(WRONG - Background repeated in scenario, scenario-specific setup in Background)", "", "**Common mistakes:**", "- Background has scenario-specific setup (WRONG - this is scenario-specific)", "- Scenario Steps start with common setup (WRONG - this belongs in Background if true for all scenarios)", "- Background repeated in each scenario (WRONG - Background is at story level only)"]}}]}}, {"rule_file": "write_plain_english_scenarios.json", "rule_content": {"description": "Write scenarios in plain English. NO variables, NO placeholders, NO Scenario Outlines, NO Examples tables at this stage.", "examples": [{"do": {"description": "Plain English scenarios", "content": ["Given user has attached documents to chat window", "And user has typed request message 'start shaping'", "When AI Chat processes request", "Then AI Chat identifies story shaping keywords"]}, "dont": {"description": "Don't use variables or placeholders", "content": ["Given user has typed request message \"<request_message>\" (WRONG - has variable)", "Scenario Outline: AI Chat detects keywords (WRONG - Outline at this stage)", "Examples: | request_message | (WRONG - Examples at this stage)"]}}]}}], "token_estimate": 7484}}}, "72": {"action_state": "story_bot.5_exploration.validate_rules", "status": "started", "timestamp": "2025-12-10T01:06:04.718505"}, "73": {"action_state": "story_bot.5_exploration.validate_rules", "status": "completed", "timestamp": "2025-12-10T01:06:04.752557", "outputs": {"instructions": {"action": "validate_rules", "behavior": "5_exploration", "base_instructions": ["Load and review clarification.json and planning.json", "Check Content Data against all rules listed above", "Generate a validation report", "Save the validation report to validation-report.md in docs/stories/", "", "**NEXT BEHAVIOR REMINDER:**", "After completing this behavior, the next behavior in sequence is `6_scenarios`. When the user is ready to continue, remind them: 'The next behavior in sequence is `6_scenarios`. Would you like to continue with `6_scenarios` or work on a different behavior?'"], "validation_rules": [{"rule_file": "behavioral_ac_at_story_level.json", "rule_content": {"description": "Behavioral AC belongs at story level, written in story-graph.json (main epics section). Use When/Then format (NO Given clauses - save for scenarios). Each acceptance criteria is a SINGLE string containing one WHEN/THEN pair. AND can be part of the same acceptance criteria, but THEN and its AND must be together in the same string.", "examples": [{"do": {"description": "Each acceptance criteria is a single string with WHEN/THEN", "content": "acceptance_criteria: [\"WHEN user enters name THEN system saves to character sheet\"]"}, "dont": {"description": "Don't split WHEN/THEN across multiple strings", "content": "acceptance_criteria: [\"WHEN user enters name\", \"THEN system saves to character sheet\"] (WRONG - should be one string)"}}, {"do": {"description": "THEN and its AND belong together in same acceptance criteria", "content": "acceptance_criteria: [\"WHEN action completes THEN system saves state AND system shows success message\"]"}, "dont": {"description": "Don't separate THEN and its AND into different strings", "content": "acceptance_criteria: [\"WHEN action completes\", \"THEN system saves state\", \"AND system shows success message\"] (WRONG - THEN and AND should be together)"}}, {"do": {"description": "Multiple separate ANDs become separate acceptance criteria if they are separate outcomes", "content": "acceptance_criteria: [\"WHEN tokens are selected THEN system queries Foundry VTT API\", \"WHEN tokens are selected THEN system retrieves actor ID for each token\"]"}, "dont": {"description": "Don't put separate outcomes in one acceptance criteria - but if AND is part of same outcome, keep together", "content": "acceptance_criteria: [\"WHEN tokens are selected THEN system queries Foundry VTT API AND system retrieves actor ID AND system stores position\"] (WRONG - if these are separate outcomes, they should be separate acceptance criteria)"}}, {"do": {"description": "Each WHEN condition starts a new acceptance criteria", "content": "acceptance_criteria: [\"WHEN Game Master selects tokens THEN system highlights tokens\", \"WHEN Game Master selects zero tokens THEN system shows error message\"]"}, "dont": {"description": "Don't combine different WHEN conditions", "content": "acceptance_criteria: [\"WHEN Game Master selects tokens THEN system highlights tokens WHEN Game Master selects zero tokens THEN system shows error\"] (WRONG - each WHEN needs its own acceptance criteria)"}}, {"do": {"description": "Correct format: WHEN/THEN/AND together in one string", "content": "acceptance_criteria: [\"WHEN Game Master selects tokens THEN system highlights selected tokens AND selected tokens are stored in temporary selection state\", \"WHEN Game Master selects zero tokens THEN system shows error message indicating at least one token must be selected\"]"}, "dont": {"description": "Wrong format: split across multiple strings", "content": "acceptance_criteria: [\"WHEN Game Master selects tokens\", \"THEN system highlights selected tokens\", \"AND selected tokens are stored in temporary selection state\"] (WRONG - should be one string)"}}]}}, {"rule_file": "enumerate_all_ac_permutations.json", "rule_content": {"description": "Enumerate ALL acceptance criteria permutations. Apply exhaustive logic decomposition at AC level.", "examples": [{"do": {"description": "List all validation paths and calculation branches", "content": "When user enters STR rank, then system validates (1-20 range) - When user enters invalid rank, then system shows error - When user enters valid rank, then system calculates modifier"}, "dont": {"description": "Don't skip AC permutations", "content": "When user enters rank, then system saves (missing validation and calculation ACs)"}}]}}, {"rule_file": "given_uses_state_language.json", "rule_content": {"description": "Given statements must use state-oriented language (not action-oriented). Given describes STATE, not actions.", "examples": [{"do": {"description": "Given uses state language", "content": "Given user is logged in (state) - Given character sheet exists (state)"}, "dont": {"description": "Given doesn't use action language", "content": "Given user logs in (action - WRONG) - Given system creates character (action - WRONG)"}}]}}, {"rule_file": "present_ac_consolidation.json", "rule_content": {"description": "Present AC consolidation review BEFORE finalizing. Identify similar ACs, ask domain expert questions, wait for user confirmation.", "examples": [{"do": {"description": "Present AC consolidation questions and wait for answers", "content": "CONSOLIDATION REVIEW: These ACs use same logic? [List ACs] \u2192 User answers \u2192 Apply decisions"}, "dont": {"description": "Don't automatically consolidate ACs without user confirmation", "content": "Auto-consolidate similar ACs (WRONG - must ask user first)"}}]}}, {"rule_file": "scenarios_cover_all_cases.json", "rule_content": {"description": "Scenarios must cover happy path, edge cases, and error cases based on acceptance criteria.", "examples": [{"do": {"description": "Complete scenario coverage", "content": "Happy path: User enters valid data \u2192 System saves. Edge case: User enters boundary value \u2192 System validates. Error case: User enters invalid data \u2192 System shows error."}, "dont": {"description": "Don't skip scenario types", "content": "Only happy path scenarios (missing edge cases and error cases)"}}]}}, {"rule_file": "scenarios_on_story_docs.json", "rule_content": {"description": "CRITICAL SCOPE: Scenarios work on STORY documents (\ud83d\udcdd *.md files), NOT feature documents. NEVER creates feature specification documents.", "examples": [{"do": {"description": "Add scenarios to story documents", "content": "docs/stories/Epic/Feature/\ud83d\udcdd Story Name.md - Scenarios section added"}, "dont": {"description": "Don't create feature specification documents", "content": "docs/stories/Epic/Feature/Feature Specification.md (WRONG - scenarios go in story docs)"}}]}}, {"rule_file": "use_background_for_common_setup.json", "rule_content": {"description": "Use Background for repeated Given steps across 3+ scenarios. Background contains only Given/And steps (no When/Then).", "examples": [{"do": {"description": "Background for shared context", "content": "Background: Given user is logged in And character sheet exists (used by 5 scenarios)"}, "dont": {"description": "Don't use Background for unique Given steps or include When/Then", "content": "Background: Given user logs in (action - WRONG) OR Background: When user clicks button (When/Then - WRONG)"}}]}}, {"rule_file": "use_scenario_outline_when_needed.json", "rule_content": {"description": "Use Scenario Outline with Examples when story warrants concrete data: formulas need validation, domain has named entities, parameter variations exist.", "examples": [{"do": {"description": "Scenario Outline for formulas or domain entities", "content": "Scenario Outline: Calculate ability modifier - Examples table with Rank 10\u21920, Rank 12\u2192+1, Rank 14\u2192+2"}, "dont": {"description": "Don't use Scenario Outline for simple behaviors", "content": "Scenario Outline: User clicks button (too simple - use regular scenario)"}}]}}], "content_to_validate": {"project_location": "C:\\dev\\augmented-teams\\demo\\mob_minion", "rendered_outputs": ["C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-description.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-diagram.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json"], "clarification_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\clarification.json", "planning_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\planning.json", "report_path": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\validation-report.md"}}}}, "74": {"action_state": "story_bot.6_scenarios.build_knowledge", "status": "started", "timestamp": "2025-12-10T01:06:19.514041"}, "75": {"action_state": "story_bot.6_scenarios.build_knowledge", "status": "completed", "timestamp": "2025-12-10T01:06:19.554644", "outputs": {"instructions": {"knowledge_graph_template": {"_explanation": {"hierarchical": "sub_epics can contain: nested sub_epics or story_groups. sequential_order is always an integer (1, 2, 3, 4) - unique within parent, no decimals.", "connector": "Story groups: 'and' or 'or' (null for first group). Stories within groups: 'and' or 'or' (null for first story). Epics and sub_epics don't have connectors.", "domain_placement": "domain_concepts: 'local' if relevant to single sub_epic, 'global' if relevant to multiple sub_epics. Place at most specific level (local preferred), but elevate to parent if used by multiple children.", "scenarios": "Each story contains scenarios (happy_path, edge_case, error_case) with background and steps in Gherkin format.", "scenario_outlines": "When decision criteria chooses Scenario Outline, stories may contain scenario_outlines with Examples tables for data-driven testing. Every variable in Steps must have a column in Examples table. Examples table must include both input and output/expected result variables.", "increments_structure": "The 'increments' section is a MINIMAL REFERENCE VIEW. Stories in increments contain ONLY: name, users (optional), sequential_order. All story details (story_type, connector, scenarios, scenario_outlines, Steps, acceptance_criteria, etc.) come from the main 'epics' section. Increments are just a copy of the outline view at the story level to map which stories belong to which increment."}, "epics": [{"name": "", "sequential_order": 1, "estimated_stories": null, "domain_concepts": [{"name": "", "responsibilities": [{"name": "", "collaborators": []}]}], "sub_epics": [{"name": "", "sequential_order": 1, "estimated_stories": null, "domain_concepts": [{"name": "", "responsibilities": [{"name": "", "collaborators": []}]}], "sub_epics": [], "story_groups": [{"type": "and", "connector": null, "sequential_order": 1, "stories": [{"name": "", "sequential_order": 1, "connector": null, "users": [], "story_type": "user", "scenarios": [{"name": "", "type": "happy_path|edge_case|error_case", "background": ["Given <common_setup_step>", "And <another_common_setup>"], "steps": ["Given <scenario_specific_state>", "And <scenario_specific_setup>", "When <user_action_or_system_event>", "Then <expected_outcome>", "And <another_expected_outcome>"]}], "scenario_outlines": [{"name": "", "type": "happy_path|edge_case|error_case", "background": ["Given <common_setup_step>", "And <another_common_setup>"], "steps": ["Given <scenario_specific_state> at \"<variable_path>\"", "And <entity> exists at \"<variable_file_path>\"", "When <action> with <variable_parameter>=\"<variable_value>\"", "Then <expected_outcome> equals \"<variable_expected_result>\"", "And <another_outcome> is \"<variable_result>\""], "examples": {"columns": ["variable_path", "variable_file_path", "variable_parameter", "variable_value", "variable_expected_result", "variable_result"], "rows": [["value1", "value2", "value3", "value4", "result1", "result2"], ["value5", "value6", "value7", "value8", "result3", "result4"]]}}]}]}]}], "stories": []}], "increments": [{"name": "", "priority": 1, "epics": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "sub_epics": [{"name": "", "users": [], "sequential_order": 1, "estimated_stories": null, "stories": [{"name": "", "users": [], "sequential_order": 1}]}]}]}], "generated_artifacts": {"story_documents": {"description": "Story documents with scenarios section added", "location": "docs/stories/{epic_name}/{sub_epic_name}/{story_name}.md", "content": ["Story description", "Acceptance criteria", "Background (common setup steps)", "Scenarios (happy path, edge cases, error cases)", "Scenario Outlines with Examples tables (when decision criteria chosen)"]}, "structured_data": {"description": "JSON representation of stoy graph with scenarios added", "location": "docs/stories/story-graph.json", "content": ["Epic/sub_epic/story_group/story hierarchy", "Scenario definitions with steps", "Scenario Outline definitions with Examples tables (when decision criteria chosen)", "Background steps per story", "Scenario types (happy_path, edge_case, error_case)", "Connectors for story groups and stories"]}}}, "knowledge_graph_config": {"name": "build_story_scenarios", "description": "Build story graph with scenarios added to each story (and scenario outlines with examples if decision criteria chosen)", "input": "docs/stories/story-graph.json", "output": "docs/stories/story-graph.json", "template": "story-graph-scenarios.json", "process": ["Check decision criteria: agile_bot/bots/story_bot/behaviors/6_scenarios/1_guardrails/planning/decision_criteria/scenario_outline.json", "Load existing story graph from project area", "For each story in graph, analyze acceptance criteria", "Generate scenarios (happy_path, edge_case, error_case)", "IF decision criteria = 'Yes': Identify scenarios needing data variation and convert to Scenario Outlines with Examples tables", "Add scenarios to story in graph (and scenario_outlines if decision criteria = 'Yes')", "Save updated story graph to project area"]}, "template_path": "C:\\dev\\augmented-teams\\agile_bot\\bots\\story_bot\\behaviors\\6_scenarios\\2_content\\1_knowledge_graph\\story-graph-scenarios.json", "config_path": "C:\\dev\\augmented-teams\\agile_bot\\bots\\story_bot\\behaviors\\6_scenarios\\2_content\\1_knowledge_graph\\build_story_scenarios.json", "validation_rules": [{"rule_file": "given_describes_preconditions_not_functionality.json", "rule_content": {"description": "CRITICAL: Given statements describe PRECONDITIONS (what exists before the test), NOT the functionality being tested. If you're describing WHAT the system does or HOW it behaves, that belongs in Then statements, not Given.", "examples": [{"do": {"description": "Given describes preconditions only", "content": ["CORRECT:", "Given activity log is initialized at project_area/activity log", "Given user is logged in", "Given character sheet exists", "Given workflow state is persisted", "", "These describe STATE/EXISTENCE, not functionality."]}, "dont": {"description": "Don't describe functionality in Given - that's what you're testing", "content": ["WRONG:", "Given activity log tracks: timestamp, action_state, inputs, outputs, duration", "(This describes WHAT the activity log DOES - that's the functionality being tested!)", "", "Given system validates user input", "(This describes WHAT the system DOES - that's functionality, not a precondition!)", "", "Given bot routes to correct action based on workflow state", "(This describes HOW the bot BEHAVES - that's what you're testing!)", "", "Ask yourself: Am I describing WHAT EXISTS or WHAT THE SYSTEM DOES?", "- If describing WHAT EXISTS \u2192 Given (precondition)", "- If describing WHAT THE SYSTEM DOES \u2192 Then (expected behavior being tested)", "", "Common mistakes:", "- Describing data structure/format in Given (that's functionality to test in Then)", "- Describing system behavior in Given (that's what you're testing in Then)", "- Describing validation rules in Given (that's functionality to test in Then)", "", "CORRECT approach:", "Given activity log is initialized (precondition - it exists)", "When action completes", "Then activity log captures: timestamp, action_state, inputs, outputs, duration (functionality being tested)"]}}]}}, {"rule_file": "given_describes_state_not_actions.json", "rule_content": {"description": "CRITICAL: Given statements describe STATE/CONFIGURATION, never actions or events. The first action in a scenario is ALWAYS a When, never a Given. Given sets up preconditions, When triggers the behavior being tested.", "examples": [{"do": {"description": "Given describes state, When triggers action", "content": ["CORRECT:", "Given a bot with name 'test_bot'", "And bot has a behavior configured as 'shape'", "And behavior has action 'gather_context'", "When Tool invokes test_bot.Shape.GatherContext() method", "", "Given = STATE (bot exists, is configured)", "When = ACTION (tool invokes method)"]}, "dont": {"description": "Don't use Given for actions - first action is ALWAYS When", "content": ["WRONG:", "Given Tool has invoked test_bot.Shape.GatherContext() method", "", "This is WRONG because 'invoked' is an ACTION, not a state.", "The scenario's first action must be When, not Given.", "", "Other common mistakes:", "- Given user clicks button (WRONG - clicking is action, use When)", "- Given system sends message (WRONG - sending is action, use When)", "- Given API is called (WRONG - calling is action, use When)", "- Given tool executes (WRONG - executing is action, use When)"]}}, {"do": {"description": "Given = preconditions (state), When = trigger (action), Then = outcomes", "content": ["Structure of every scenario:", "", "Given <state/config> - What exists, is configured, is true BEFORE the action", "And <more state> - Additional preconditions", "When <action> - The ONE thing that triggers the behavior (external stimulus)", "Then <outcome> - What should happen as a result", "And <more outcomes> - Additional expected results", "", "Example:", "Given a bot with name 'test_bot' (STATE - bot exists)", "And bot has behavior configured as 'shape' (STATE - configured)", "When Tool invokes test_bot.Shape.GatherContext() (ACTION - trigger)", "Then Action loads instructions (OUTCOME - result)", "And Action merges instructions (OUTCOME - more results)"]}, "dont": {"description": "Don't confuse state with actions", "content": ["Ask yourself: Is this describing WHAT EXISTS or WHAT HAPPENS?", "", "If it describes WHAT EXISTS \u2192 Given", "If it describes WHAT HAPPENS \u2192 When (if first action) or Then (if result)", "", "WRONG patterns to avoid:", "- Given <something> happened (past tense action \u2192 use When)", "- Given <actor> does <action> (present tense action \u2192 use When)", "- Given <system> executes <process> (action \u2192 use When)"]}}]}}, {"rule_file": "given_uses_state_language.json", "rule_content": {"description": "Given statements must use state-oriented language (not action-oriented). Given describes STATE, not actions.", "examples": [{"do": {"description": "Given uses state language", "content": ["Given user is logged in (state)", "Given character sheet exists (state)"]}, "dont": {"description": "Given doesn't use action language", "content": ["Given user logs in (action - WRONG)", "Given system creates character (action - WRONG)"]}}]}}, {"rule_file": "scenarios_cover_all_cases.json", "rule_content": {"description": "Scenarios must cover happy path, edge cases, and error cases based on acceptance criteria.", "examples": [{"do": {"description": "Complete scenario coverage", "content": ["Happy path: User enters valid data \u2192 System saves.", "Edge case: User enters boundary value \u2192 System validates.", "Error case: User enters invalid data \u2192 System shows error."]}, "dont": {"description": "Don't skip scenario types", "content": ["Only happy path scenarios (missing edge cases and error cases)"]}}]}}, {"rule_file": "scenarios_on_story_docs.json", "rule_content": {"description": "CRITICAL SCOPE: Scenarios work on STORY documents (\ud83d\udcdd *.md files), NOT feature documents. NEVER creates feature specification documents.", "examples": [{"do": {"description": "Add scenarios to story documents", "content": ["docs/stories/Epic/Feature/\ud83d\udcdd Story Name.md - Scenarios section added"]}, "dont": {"description": "Don't create feature specification documents", "content": ["docs/stories/Epic/Feature/Feature Specification.md (WRONG - scenarios go in story docs)"]}}]}}, {"rule_file": "scenario_steps_start_with_scenario_specific_given.json", "rule_content": {"description": "CRITICAL: Each scenario's Steps section starts with Given steps for scenario-specific setup. Background steps are automatically applied before scenario Steps. Scenario Steps should contain setup specific to THIS scenario only, not common setup that belongs in Background.", "examples": [{"do": {"description": "What goes in scenario Steps Given section - Scenario-specific setup only", "content": ["**What goes in scenario Steps Given section:**", "- Setup specific to THIS scenario only", "- Variable-dependent setup (even if similar across scenarios)", "- Test data setup (paths, file names, etc.)", "- Scenario-specific preconditions", "- Any setup that is NOT true for ALL scenarios", "", "**GOOD Example structure:**", "- Background has: \"Given Agent is initialized with agent_name='story_bot'\" (common to ALL scenarios)", "- Background has: \"Given Project is finished initializing\" (common to ALL scenarios)", "- Scenario Steps start with: \"Given test project area is set up at test_data/projects/valid-project\" (scenario-specific)", "- Scenario Steps continue with: \"And valid base agent.json exists at test_data/agents/base/agent.json\" (scenario-specific)", "", "**Example scenario Steps:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And valid base agent.json exists at test_data/agents/base/agent.json", "When Project initializes with project_path='test_data/projects/valid-project'", "Then Project loads agent configuration from agent.json", "```"]}, "dont": {"description": "Don't put common setup in scenario Steps or scenario-specific setup in Background", "content": ["**BAD Example (what NOT to do):**", "- Background has: \"Given test project area is set up at test_data/projects/valid-project\" (WRONG - this is scenario-specific)", "- Scenario Steps start with: \"Given Agent is initialized\" (WRONG - this belongs in Background if true for all scenarios)", "", "**Common mistakes:**", "- Including common setup in scenario Steps that should be in Background", "- Including scenario-specific setup in Background that should be in scenario Steps", "- Repeating Background steps in scenario Steps (Background is automatically applied)", "", "**WRONG Example:**", "```gherkin", "Given Agent is initialized with agent_name='story_bot'", "And Project is finished initializing", "And test project area is set up at test_data/projects/valid-project", "When Project initializes", "```", "(WRONG - first two Given steps belong in Background, only last Given is scenario-specific)"]}}]}}, {"rule_file": "story_filename_matches_story_name.json", "rule_content": {"description": "CRITICAL: Story filenames must match the story name exactly (no actor prefix). Actor information belongs in story description or acceptance criteria, NOT in the filename.", "examples": [{"do": {"description": "Filename matches story name without actor", "content": ["CORRECT:", "Story name: 'Route To MCP Behavior Tool'", "Filename: \ud83d\udcdd Route To MCP Behavior Tool.md", "", "Story name: 'Saves Behavior State'", "Filename: \ud83d\udcdd Saves Behavior State.md", "", "Story name: 'Track Activity for Gather Context Action'", "Filename: \ud83d\udcdd Track Activity for Gather Context Action.md"]}, "dont": {"description": "Don't include actor name in filename", "content": ["WRONG:", "Story name: 'Route To MCP Behavior Tool'", "Filename: \ud83d\udcdd AI Chat Route To MCP Behavior Tool.md", "(Actor 'AI Chat' should NOT be in filename)", "", "Story name: 'Saves Behavior State'", "Filename: \ud83d\udcdd Bot Behavior Saves Behavior State.md", "(Actor 'Bot Behavior' should NOT be in filename)", "", "Story name: 'Track Activity for Gather Context Action'", "Filename: \ud83d\udcdd GatherContextAction Track Activity.md", "(Actor 'GatherContextAction' should NOT be in filename)", "", "Common mistakes:", "- Including actor/user name from story description in filename", "- Prefixing filename with 'AI Chat', 'Router', 'Bot Behavior', etc.", "- Adding class/component names to filename", "", "Actor information belongs in:", "- Story description", "- Acceptance criteria (WHEN actor does X...)", "- NOT in the filename"]}}]}}, {"rule_file": "use_background_for_common_setup.json", "rule_content": {"description": "CRITICAL: Background section is ONLY for common setup steps shared across 3+ scenarios. DO NOT include scenario-specific setup here. Background contains only Given/And steps (no When/Then). Scenario-specific setup goes in scenario Steps as Given steps, not in Background.", "examples": [{"do": {"description": "What belongs in Background - Setup steps that are TRUE for ALL scenarios (100% of scenarios)", "content": ["**What belongs in Background:**", "- Setup steps that are TRUE for ALL scenarios in this story (100% of scenarios)", "- Common preconditions that every single scenario needs", "- Shared system state that applies to all scenarios without exception", "- Steps that never vary between scenarios", "", "**Examples of valid Background steps:**", "- Given Agent is initialized with agent_name='story_bot' (true for ALL scenarios)", "- Given Cursor/VS Code chat window is open (true for ALL scenarios)", "- Given Project is finished initializing (true for ALL scenarios)", "", "**GOOD Example:**", "```gherkin", "Given Agent is initialized with agent_name='story_bot'", "And Project is finished initializing", "```", "These are true for ALL scenarios in that story."]}, "dont": {"description": "What does NOT belong in Background - Scenario-specific or variable-dependent setup", "content": ["**What does NOT belong in Background:**", "- Scenario-specific setup (goes in scenario Steps as Given)", "- Variable-dependent setup (goes in scenario Steps)", "- Setup that only applies to some scenarios (goes in scenario Steps)", "- Test data paths or file names (goes in scenario Steps)", "- Conditional setup (goes in scenario Steps)", "", "**Examples of invalid Background steps:**", "- Given test project area is set up at test_data/projects/valid-project (WRONG - scenario-specific, goes in Steps)", "- Given user has attached documents to chat window (WRONG if not true for ALL scenarios - check if all scenarios need this)", "", "**BAD Example:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And test agent base area is set up at test_data/agents/base", "```", "These are scenario-specific and belong in scenario Steps, not Background."]}}, {"do": {"description": "Background for shared context, scenario-specific Given in Steps", "content": ["## Background", "", "**Common setup steps shared across all scenarios:**", "", "```gherkin", "Given Agent is initialized with agent_name='story_bot'", "And Project is finished initializing", "```", "", "## Scenarios", "", "### Scenario: Agent loads configurations", "", "**Steps:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And valid base agent.json exists at test_data/agents/base/agent.json", "When Project initializes with project_path='test_data/projects/valid-project'", "Then Project loads agent configuration from agent.json", "```", "", "**Key points:**", "- Background has common setup (true for ALL scenarios)", "- Scenario Steps start with scenario-specific Given steps", "- Background steps are automatically applied before scenario Steps"]}, "dont": {"description": "Don't put scenario-specific setup in Background or repeat Background in each scenario", "content": ["**BAD Example (what NOT to do):**", "", "## Background", "", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "```", "", "### Scenario: Agent loads configurations", "", "**Background:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And Project is finished initializing", "```", "", "(WRONG - Background repeated in scenario, scenario-specific setup in Background)", "", "**Common mistakes:**", "- Background has scenario-specific setup (WRONG - this is scenario-specific)", "- Scenario Steps start with common setup (WRONG - this belongs in Background if true for all scenarios)", "- Background repeated in each scenario (WRONG - Background is at story level only)"]}}]}}, {"rule_file": "write_plain_english_scenarios.json", "rule_content": {"description": "Write scenarios in plain English. NO variables, NO placeholders, NO Scenario Outlines, NO Examples tables at this stage.", "examples": [{"do": {"description": "Plain English scenarios", "content": ["Given user has attached documents to chat window", "And user has typed request message 'start shaping'", "When AI Chat processes request", "Then AI Chat identifies story shaping keywords"]}, "dont": {"description": "Don't use variables or placeholders", "content": ["Given user has typed request message \"<request_message>\" (WRONG - has variable)", "Scenario Outline: AI Chat detects keywords (WRONG - Outline at this stage)", "Examples: | request_message | (WRONG - Examples at this stage)"]}}]}}], "token_estimate": 7484}}}, "76": {"action_state": "story_bot.6_scenarios.gather_context", "status": "started", "timestamp": "2025-12-10T01:11:08.148945"}, "77": {"action_state": "story_bot.6_scenarios.gather_context", "status": "completed", "timestamp": "2025-12-10T01:11:08.170804", "outputs": {"instructions": {"action": "gather_context", "behavior": "6_scenarios", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["What system and user actions initiate this story's flow?", "What is the intended system response after each user action?", "What preconditions or data states are required before this story can begin?", "What are the success criteria for the story (from a domain and user perspective)?", "What are the expected alternate flows, error paths, and edge cases?", "Are there any mandatory sequencing constraints within or across stories?", "What domain rules, calculations, or business policies does this story validate?", "Is the story testable independently (including setup and teardown conditions)?", "What external systems or services does this story need to interact with?", "What requests, responses, or contracts are involved in those system interactions?", "Are there system integration points that require validation or simulation?", "How do we handle failures, timeouts, or retries for those system calls?", "What data variations (e.g., boundary conditions, common examples) are required for test coverage?", "What are the input values needed to test each scenario?", "What are the expected output values for each input?", "Are there formulas or calculations that need multiple data points to validate?", "Are there domain entities with named values that should be tested?", "What are the boundary conditions (min, max, edge cases) for each data point?", "Who is responsible for writing or validating these examples (e.g., BA, Dev, QC)?", "Do scenarios need to be converted to Scenario Outlines with Examples tables?"], "evidence": ["Acceptance criteria from Exploration stage (Domain AC at feature level, Behavioral AC at story level)", "Low fidelity UX flows", "Domain models or ubiquitous language", "Cross-functional walkthrough outputs", "Integration contracts or API mocks", "Behavior diagrams (state, sequence)"]}}}}, "78": {"action_state": "story_bot.6_scenarios.gather_context", "status": "started", "timestamp": "2025-12-10T01:12:42.767291"}, "79": {"action_state": "story_bot.6_scenarios.gather_context", "status": "completed", "timestamp": "2025-12-10T01:12:42.785812", "outputs": {"instructions": {"action": "gather_context", "behavior": "6_scenarios", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["What system and user actions initiate this story's flow?", "What is the intended system response after each user action?", "What preconditions or data states are required before this story can begin?", "What are the success criteria for the story (from a domain and user perspective)?", "What are the expected alternate flows, error paths, and edge cases?", "Are there any mandatory sequencing constraints within or across stories?", "What domain rules, calculations, or business policies does this story validate?", "Is the story testable independently (including setup and teardown conditions)?", "What external systems or services does this story need to interact with?", "What requests, responses, or contracts are involved in those system interactions?", "Are there system integration points that require validation or simulation?", "How do we handle failures, timeouts, or retries for those system calls?", "What data variations (e.g., boundary conditions, common examples) are required for test coverage?", "What are the input values needed to test each scenario?", "What are the expected output values for each input?", "Are there formulas or calculations that need multiple data points to validate?", "Are there domain entities with named values that should be tested?", "What are the boundary conditions (min, max, edge cases) for each data point?", "Who is responsible for writing or validating these examples (e.g., BA, Dev, QC)?", "Do scenarios need to be converted to Scenario Outlines with Examples tables?"], "evidence": ["Acceptance criteria from Exploration stage (Domain AC at feature level, Behavioral AC at story level)", "Low fidelity UX flows", "Domain models or ubiquitous language", "Cross-functional walkthrough outputs", "Integration contracts or API mocks", "Behavior diagrams (state, sequence)"]}}}}, "80": {"action_state": "story_bot.6_scenarios.gather_context", "status": "started", "timestamp": "2025-12-10T01:13:47.494945"}, "81": {"action_state": "story_bot.6_scenarios.gather_context", "status": "completed", "timestamp": "2025-12-10T01:13:47.513521", "outputs": {"instructions": {"action": "gather_context", "behavior": "6_scenarios", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["What system and user actions initiate this story's flow?", "What is the intended system response after each user action?", "What preconditions or data states are required before this story can begin?", "What are the success criteria for the story (from a domain and user perspective)?", "What are the expected alternate flows, error paths, and edge cases?", "Are there any mandatory sequencing constraints within or across stories?", "What domain rules, calculations, or business policies does this story validate?", "Is the story testable independently (including setup and teardown conditions)?", "What external systems or services does this story need to interact with?", "What requests, responses, or contracts are involved in those system interactions?", "Are there system integration points that require validation or simulation?", "How do we handle failures, timeouts, or retries for those system calls?", "What data variations (e.g., boundary conditions, common examples) are required for test coverage?", "What are the input values needed to test each scenario?", "What are the expected output values for each input?", "Are there formulas or calculations that need multiple data points to validate?", "Are there domain entities with named values that should be tested?", "What are the boundary conditions (min, max, edge cases) for each data point?", "Who is responsible for writing or validating these examples (e.g., BA, Dev, QC)?", "Do scenarios need to be converted to Scenario Outlines with Examples tables?"], "evidence": ["Acceptance criteria from Exploration stage (Domain AC at feature level, Behavioral AC at story level)", "Low fidelity UX flows", "Domain models or ubiquitous language", "Cross-functional walkthrough outputs", "Integration contracts or API mocks", "Behavior diagrams (state, sequence)"]}}}}, "82": {"action_state": "story_bot.6_scenarios.gather_context", "status": "started", "timestamp": "2025-12-10T01:20:40.655871"}, "83": {"action_state": "story_bot.6_scenarios.gather_context", "status": "completed", "timestamp": "2025-12-10T01:20:40.696496", "outputs": {"instructions": {"action": "gather_context", "behavior": "6_scenarios", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["What system and user actions initiate this story's flow?", "What is the intended system response after each user action?", "What preconditions or data states are required before this story can begin?", "What are the success criteria for the story (from a domain and user perspective)?", "What are the expected alternate flows, error paths, and edge cases?", "Are there any mandatory sequencing constraints within or across stories?", "What domain rules, calculations, or business policies does this story validate?", "Is the story testable independently (including setup and teardown conditions)?", "What external systems or services does this story need to interact with?", "What requests, responses, or contracts are involved in those system interactions?", "Are there system integration points that require validation or simulation?", "How do we handle failures, timeouts, or retries for those system calls?", "What data variations (e.g., boundary conditions, common examples) are required for test coverage?", "What are the input values needed to test each scenario?", "What are the expected output values for each input?", "Are there formulas or calculations that need multiple data points to validate?", "Are there domain entities with named values that should be tested?", "What are the boundary conditions (min, max, edge cases) for each data point?", "Who is responsible for writing or validating these examples (e.g., BA, Dev, QC)?", "Do scenarios need to be converted to Scenario Outlines with Examples tables?"], "evidence": ["Acceptance criteria from Exploration stage (Domain AC at feature level, Behavioral AC at story level)", "Low fidelity UX flows", "Domain models or ubiquitous language", "Cross-functional walkthrough outputs", "Integration contracts or API mocks", "Behavior diagrams (state, sequence)"]}}}}, "84": {"action_state": "story_bot.6_scenarios.decide_planning_criteria", "status": "started", "timestamp": "2025-12-10T01:20:44.122307"}, "85": {"action_state": "story_bot.6_scenarios.decide_planning_criteria", "status": "completed", "timestamp": "2025-12-10T01:20:44.148908", "outputs": {"instructions": {"assumptions": ["One story is specified at a time", "Acceptance criteria must be testable, unambiguous, and executable", "Gherkin syntax or structured language (Given/When/Then) is preferred", "Scenarios are written in plain English without variables or test data", "Specification drives both design and test \u2014 not written after implementation", "Scenarios must cover both behavior and domain policy", "Examples tables when used must include ALL variables used in scenario steps", "Examples tables when used must have exact values for both input AND output variables", "Every variable when usedin scenario steps must have a corresponding column in Examples table", "Examples tables when usedmust have actual test data, not placeholders", "Output/expected result variables must be included in Examples tables when used", "Examples drive both design and test \u2014 not written after implementation"], "decision_criteria": {"scenario_detail_level": {"description": "Scenario detail level", "question": "What approach are we using to define the right level of detail and coverage for this story's scenarios?", "outcome": "Determines whether the scenarios are granular, domain-focused, or integration-heavy", "options": ["User-System Behavioral Flow \u2014 ensures full traceability from trigger to response", "Domain Rules-Centric \u2014 validates business correctness through rule clarity", "System-Centric \u2014 defines system-to-system interactions with clear request/response templates", "Minimal Path Plus Alternates \u2014 covers happy path plus targeted exceptions only", "Full Spec Coverage \u2014 includes all realistic variations and negative cases", "Very Trustable Story \u2014 maximizes testability by scoping tight atomic flows with few steps and precise acceptance criteria", "Exhaustive Behavior Split \u2014 repeats each unique behavior even when similar, discourages reuse to maximize coverage visibility"]}, "scenario_outline": {"description": "Scenario Outline", "question": "Should scenarios be converted to Scenario Outline with Examples?", "outcome": "Determines Scenario Outline creation", "options": ["Yes - formulas/calculations need multiple data points OR domain has named entities from source OR parameter variations exist", "No - behavior is simple/obvious and doesn't need data variations"]}, "scenario_structure": {"description": "Scenario structure", "question": "Should scenarios use Background for repeated Given steps?", "outcome": "Determines Background section creation", "options": ["Yes - 3+ scenarios share Given steps", "No - Given steps are unique per scenario"]}}}}}, "86": {"action_state": "story_bot.6_scenarios.validate_rules", "status": "started", "timestamp": "2025-12-10T01:20:46.676210"}, "87": {"action_state": "story_bot.6_scenarios.validate_rules", "status": "completed", "timestamp": "2025-12-10T01:20:46.719704", "outputs": {"instructions": {"action": "validate_rules", "behavior": "6_scenarios", "base_instructions": ["Load and review clarification.json and planning.json", "Check Content Data against all rules listed above", "Generate a validation report", "Save the validation report to validation-report.md in docs/stories/", "", "**NEXT BEHAVIOR REMINDER:**", "After completing this behavior, the next behavior in sequence is `7_tests`. When the user is ready to continue, remind them: 'The next behavior in sequence is `7_tests`. Would you like to continue with `7_tests` or work on a different behavior?'"], "validation_rules": [{"rule_file": "given_describes_preconditions_not_functionality.json", "rule_content": {"description": "CRITICAL: Given statements describe PRECONDITIONS (what exists before the test), NOT the functionality being tested. If you're describing WHAT the system does or HOW it behaves, that belongs in Then statements, not Given.", "examples": [{"do": {"description": "Given describes preconditions only", "content": ["CORRECT:", "Given activity log is initialized at project_area/activity log", "Given user is logged in", "Given character sheet exists", "Given workflow state is persisted", "", "These describe STATE/EXISTENCE, not functionality."]}, "dont": {"description": "Don't describe functionality in Given - that's what you're testing", "content": ["WRONG:", "Given activity log tracks: timestamp, action_state, inputs, outputs, duration", "(This describes WHAT the activity log DOES - that's the functionality being tested!)", "", "Given system validates user input", "(This describes WHAT the system DOES - that's functionality, not a precondition!)", "", "Given bot routes to correct action based on workflow state", "(This describes HOW the bot BEHAVES - that's what you're testing!)", "", "Ask yourself: Am I describing WHAT EXISTS or WHAT THE SYSTEM DOES?", "- If describing WHAT EXISTS \u2192 Given (precondition)", "- If describing WHAT THE SYSTEM DOES \u2192 Then (expected behavior being tested)", "", "Common mistakes:", "- Describing data structure/format in Given (that's functionality to test in Then)", "- Describing system behavior in Given (that's what you're testing in Then)", "- Describing validation rules in Given (that's functionality to test in Then)", "", "CORRECT approach:", "Given activity log is initialized (precondition - it exists)", "When action completes", "Then activity log captures: timestamp, action_state, inputs, outputs, duration (functionality being tested)"]}}]}}, {"rule_file": "given_describes_state_not_actions.json", "rule_content": {"description": "CRITICAL: Given statements describe STATE/CONFIGURATION, never actions or events. The first action in a scenario is ALWAYS a When, never a Given. Given sets up preconditions, When triggers the behavior being tested.", "examples": [{"do": {"description": "Given describes state, When triggers action", "content": ["CORRECT:", "Given a bot with name 'test_bot'", "And bot has a behavior configured as 'shape'", "And behavior has action 'gather_context'", "When Tool invokes test_bot.Shape.GatherContext() method", "", "Given = STATE (bot exists, is configured)", "When = ACTION (tool invokes method)"]}, "dont": {"description": "Don't use Given for actions - first action is ALWAYS When", "content": ["WRONG:", "Given Tool has invoked test_bot.Shape.GatherContext() method", "", "This is WRONG because 'invoked' is an ACTION, not a state.", "The scenario's first action must be When, not Given.", "", "Other common mistakes:", "- Given user clicks button (WRONG - clicking is action, use When)", "- Given system sends message (WRONG - sending is action, use When)", "- Given API is called (WRONG - calling is action, use When)", "- Given tool executes (WRONG - executing is action, use When)"]}}, {"do": {"description": "Given = preconditions (state), When = trigger (action), Then = outcomes", "content": ["Structure of every scenario:", "", "Given <state/config> - What exists, is configured, is true BEFORE the action", "And <more state> - Additional preconditions", "When <action> - The ONE thing that triggers the behavior (external stimulus)", "Then <outcome> - What should happen as a result", "And <more outcomes> - Additional expected results", "", "Example:", "Given a bot with name 'test_bot' (STATE - bot exists)", "And bot has behavior configured as 'shape' (STATE - configured)", "When Tool invokes test_bot.Shape.GatherContext() (ACTION - trigger)", "Then Action loads instructions (OUTCOME - result)", "And Action merges instructions (OUTCOME - more results)"]}, "dont": {"description": "Don't confuse state with actions", "content": ["Ask yourself: Is this describing WHAT EXISTS or WHAT HAPPENS?", "", "If it describes WHAT EXISTS \u2192 Given", "If it describes WHAT HAPPENS \u2192 When (if first action) or Then (if result)", "", "WRONG patterns to avoid:", "- Given <something> happened (past tense action \u2192 use When)", "- Given <actor> does <action> (present tense action \u2192 use When)", "- Given <system> executes <process> (action \u2192 use When)"]}}]}}, {"rule_file": "given_uses_state_language.json", "rule_content": {"description": "Given statements must use state-oriented language (not action-oriented). Given describes STATE, not actions.", "examples": [{"do": {"description": "Given uses state language", "content": ["Given user is logged in (state)", "Given character sheet exists (state)"]}, "dont": {"description": "Given doesn't use action language", "content": ["Given user logs in (action - WRONG)", "Given system creates character (action - WRONG)"]}}]}}, {"rule_file": "scenarios_cover_all_cases.json", "rule_content": {"description": "Scenarios must cover happy path, edge cases, and error cases based on acceptance criteria.", "examples": [{"do": {"description": "Complete scenario coverage", "content": ["Happy path: User enters valid data \u2192 System saves.", "Edge case: User enters boundary value \u2192 System validates.", "Error case: User enters invalid data \u2192 System shows error."]}, "dont": {"description": "Don't skip scenario types", "content": ["Only happy path scenarios (missing edge cases and error cases)"]}}]}}, {"rule_file": "scenarios_on_story_docs.json", "rule_content": {"description": "CRITICAL SCOPE: Scenarios work on STORY documents (\ud83d\udcdd *.md files), NOT feature documents. NEVER creates feature specification documents.", "examples": [{"do": {"description": "Add scenarios to story documents", "content": ["docs/stories/Epic/Feature/\ud83d\udcdd Story Name.md - Scenarios section added"]}, "dont": {"description": "Don't create feature specification documents", "content": ["docs/stories/Epic/Feature/Feature Specification.md (WRONG - scenarios go in story docs)"]}}]}}, {"rule_file": "scenario_steps_start_with_scenario_specific_given.json", "rule_content": {"description": "CRITICAL: Each scenario's Steps section starts with Given steps for scenario-specific setup. Background steps are automatically applied before scenario Steps. Scenario Steps should contain setup specific to THIS scenario only, not common setup that belongs in Background.", "examples": [{"do": {"description": "What goes in scenario Steps Given section - Scenario-specific setup only", "content": ["**What goes in scenario Steps Given section:**", "- Setup specific to THIS scenario only", "- Variable-dependent setup (even if similar across scenarios)", "- Test data setup (paths, file names, etc.)", "- Scenario-specific preconditions", "- Any setup that is NOT true for ALL scenarios", "", "**GOOD Example structure:**", "- Background has: \"Given Agent is initialized with agent_name='story_bot'\" (common to ALL scenarios)", "- Background has: \"Given Project is finished initializing\" (common to ALL scenarios)", "- Scenario Steps start with: \"Given test project area is set up at test_data/projects/valid-project\" (scenario-specific)", "- Scenario Steps continue with: \"And valid base agent.json exists at test_data/agents/base/agent.json\" (scenario-specific)", "", "**Example scenario Steps:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And valid base agent.json exists at test_data/agents/base/agent.json", "When Project initializes with project_path='test_data/projects/valid-project'", "Then Project loads agent configuration from agent.json", "```"]}, "dont": {"description": "Don't put common setup in scenario Steps or scenario-specific setup in Background", "content": ["**BAD Example (what NOT to do):**", "- Background has: \"Given test project area is set up at test_data/projects/valid-project\" (WRONG - this is scenario-specific)", "- Scenario Steps start with: \"Given Agent is initialized\" (WRONG - this belongs in Background if true for all scenarios)", "", "**Common mistakes:**", "- Including common setup in scenario Steps that should be in Background", "- Including scenario-specific setup in Background that should be in scenario Steps", "- Repeating Background steps in scenario Steps (Background is automatically applied)", "", "**WRONG Example:**", "```gherkin", "Given Agent is initialized with agent_name='story_bot'", "And Project is finished initializing", "And test project area is set up at test_data/projects/valid-project", "When Project initializes", "```", "(WRONG - first two Given steps belong in Background, only last Given is scenario-specific)"]}}]}}, {"rule_file": "story_filename_matches_story_name.json", "rule_content": {"description": "CRITICAL: Story filenames must match the story name exactly (no actor prefix). Actor information belongs in story description or acceptance criteria, NOT in the filename.", "examples": [{"do": {"description": "Filename matches story name without actor", "content": ["CORRECT:", "Story name: 'Route To MCP Behavior Tool'", "Filename: \ud83d\udcdd Route To MCP Behavior Tool.md", "", "Story name: 'Saves Behavior State'", "Filename: \ud83d\udcdd Saves Behavior State.md", "", "Story name: 'Track Activity for Gather Context Action'", "Filename: \ud83d\udcdd Track Activity for Gather Context Action.md"]}, "dont": {"description": "Don't include actor name in filename", "content": ["WRONG:", "Story name: 'Route To MCP Behavior Tool'", "Filename: \ud83d\udcdd AI Chat Route To MCP Behavior Tool.md", "(Actor 'AI Chat' should NOT be in filename)", "", "Story name: 'Saves Behavior State'", "Filename: \ud83d\udcdd Bot Behavior Saves Behavior State.md", "(Actor 'Bot Behavior' should NOT be in filename)", "", "Story name: 'Track Activity for Gather Context Action'", "Filename: \ud83d\udcdd GatherContextAction Track Activity.md", "(Actor 'GatherContextAction' should NOT be in filename)", "", "Common mistakes:", "- Including actor/user name from story description in filename", "- Prefixing filename with 'AI Chat', 'Router', 'Bot Behavior', etc.", "- Adding class/component names to filename", "", "Actor information belongs in:", "- Story description", "- Acceptance criteria (WHEN actor does X...)", "- NOT in the filename"]}}]}}, {"rule_file": "use_background_for_common_setup.json", "rule_content": {"description": "CRITICAL: Background section is ONLY for common setup steps shared across 3+ scenarios. DO NOT include scenario-specific setup here. Background contains only Given/And steps (no When/Then). Scenario-specific setup goes in scenario Steps as Given steps, not in Background.", "examples": [{"do": {"description": "What belongs in Background - Setup steps that are TRUE for ALL scenarios (100% of scenarios)", "content": ["**What belongs in Background:**", "- Setup steps that are TRUE for ALL scenarios in this story (100% of scenarios)", "- Common preconditions that every single scenario needs", "- Shared system state that applies to all scenarios without exception", "- Steps that never vary between scenarios", "", "**Examples of valid Background steps:**", "- Given Agent is initialized with agent_name='story_bot' (true for ALL scenarios)", "- Given Cursor/VS Code chat window is open (true for ALL scenarios)", "- Given Project is finished initializing (true for ALL scenarios)", "", "**GOOD Example:**", "```gherkin", "Given Agent is initialized with agent_name='story_bot'", "And Project is finished initializing", "```", "These are true for ALL scenarios in that story."]}, "dont": {"description": "What does NOT belong in Background - Scenario-specific or variable-dependent setup", "content": ["**What does NOT belong in Background:**", "- Scenario-specific setup (goes in scenario Steps as Given)", "- Variable-dependent setup (goes in scenario Steps)", "- Setup that only applies to some scenarios (goes in scenario Steps)", "- Test data paths or file names (goes in scenario Steps)", "- Conditional setup (goes in scenario Steps)", "", "**Examples of invalid Background steps:**", "- Given test project area is set up at test_data/projects/valid-project (WRONG - scenario-specific, goes in Steps)", "- Given user has attached documents to chat window (WRONG if not true for ALL scenarios - check if all scenarios need this)", "", "**BAD Example:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And test agent base area is set up at test_data/agents/base", "```", "These are scenario-specific and belong in scenario Steps, not Background."]}}, {"do": {"description": "Background for shared context, scenario-specific Given in Steps", "content": ["## Background", "", "**Common setup steps shared across all scenarios:**", "", "```gherkin", "Given Agent is initialized with agent_name='story_bot'", "And Project is finished initializing", "```", "", "## Scenarios", "", "### Scenario: Agent loads configurations", "", "**Steps:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And valid base agent.json exists at test_data/agents/base/agent.json", "When Project initializes with project_path='test_data/projects/valid-project'", "Then Project loads agent configuration from agent.json", "```", "", "**Key points:**", "- Background has common setup (true for ALL scenarios)", "- Scenario Steps start with scenario-specific Given steps", "- Background steps are automatically applied before scenario Steps"]}, "dont": {"description": "Don't put scenario-specific setup in Background or repeat Background in each scenario", "content": ["**BAD Example (what NOT to do):**", "", "## Background", "", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "```", "", "### Scenario: Agent loads configurations", "", "**Background:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And Project is finished initializing", "```", "", "(WRONG - Background repeated in scenario, scenario-specific setup in Background)", "", "**Common mistakes:**", "- Background has scenario-specific setup (WRONG - this is scenario-specific)", "- Scenario Steps start with common setup (WRONG - this belongs in Background if true for all scenarios)", "- Background repeated in each scenario (WRONG - Background is at story level only)"]}}]}}, {"rule_file": "write_plain_english_scenarios.json", "rule_content": {"description": "Write scenarios in plain English. NO variables, NO placeholders, NO Scenario Outlines, NO Examples tables at this stage.", "examples": [{"do": {"description": "Plain English scenarios", "content": ["Given user has attached documents to chat window", "And user has typed request message 'start shaping'", "When AI Chat processes request", "Then AI Chat identifies story shaping keywords"]}, "dont": {"description": "Don't use variables or placeholders", "content": ["Given user has typed request message \"<request_message>\" (WRONG - has variable)", "Scenario Outline: AI Chat detects keywords (WRONG - Outline at this stage)", "Examples: | request_message | (WRONG - Examples at this stage)"]}}]}}], "content_to_validate": {"project_location": "C:\\dev\\augmented-teams\\demo\\mob_minion", "rendered_outputs": ["C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-description.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-diagram.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json"], "clarification_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\clarification.json", "planning_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\planning.json", "report_path": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\validation-report.md"}}}}, "88": {"action_state": "story_bot.6_scenarios.validate_rules", "status": "started", "timestamp": "2025-12-10T01:21:13.854599"}, "89": {"action_state": "story_bot.6_scenarios.validate_rules", "status": "completed", "timestamp": "2025-12-10T01:21:13.894912", "outputs": {"instructions": {"action": "validate_rules", "behavior": "6_scenarios", "base_instructions": ["Load and review clarification.json and planning.json", "Check Content Data against all rules listed above", "Generate a validation report", "Save the validation report to validation-report.md in docs/stories/", "", "**NEXT BEHAVIOR REMINDER:**", "After completing this behavior, the next behavior in sequence is `7_tests`. When the user is ready to continue, remind them: 'The next behavior in sequence is `7_tests`. Would you like to continue with `7_tests` or work on a different behavior?'"], "validation_rules": [{"rule_file": "given_describes_preconditions_not_functionality.json", "rule_content": {"description": "CRITICAL: Given statements describe PRECONDITIONS (what exists before the test), NOT the functionality being tested. If you're describing WHAT the system does or HOW it behaves, that belongs in Then statements, not Given.", "examples": [{"do": {"description": "Given describes preconditions only", "content": ["CORRECT:", "Given activity log is initialized at project_area/activity log", "Given user is logged in", "Given character sheet exists", "Given workflow state is persisted", "", "These describe STATE/EXISTENCE, not functionality."]}, "dont": {"description": "Don't describe functionality in Given - that's what you're testing", "content": ["WRONG:", "Given activity log tracks: timestamp, action_state, inputs, outputs, duration", "(This describes WHAT the activity log DOES - that's the functionality being tested!)", "", "Given system validates user input", "(This describes WHAT the system DOES - that's functionality, not a precondition!)", "", "Given bot routes to correct action based on workflow state", "(This describes HOW the bot BEHAVES - that's what you're testing!)", "", "Ask yourself: Am I describing WHAT EXISTS or WHAT THE SYSTEM DOES?", "- If describing WHAT EXISTS \u2192 Given (precondition)", "- If describing WHAT THE SYSTEM DOES \u2192 Then (expected behavior being tested)", "", "Common mistakes:", "- Describing data structure/format in Given (that's functionality to test in Then)", "- Describing system behavior in Given (that's what you're testing in Then)", "- Describing validation rules in Given (that's functionality to test in Then)", "", "CORRECT approach:", "Given activity log is initialized (precondition - it exists)", "When action completes", "Then activity log captures: timestamp, action_state, inputs, outputs, duration (functionality being tested)"]}}]}}, {"rule_file": "given_describes_state_not_actions.json", "rule_content": {"description": "CRITICAL: Given statements describe STATE/CONFIGURATION, never actions or events. The first action in a scenario is ALWAYS a When, never a Given. Given sets up preconditions, When triggers the behavior being tested.", "examples": [{"do": {"description": "Given describes state, When triggers action", "content": ["CORRECT:", "Given a bot with name 'test_bot'", "And bot has a behavior configured as 'shape'", "And behavior has action 'gather_context'", "When Tool invokes test_bot.Shape.GatherContext() method", "", "Given = STATE (bot exists, is configured)", "When = ACTION (tool invokes method)"]}, "dont": {"description": "Don't use Given for actions - first action is ALWAYS When", "content": ["WRONG:", "Given Tool has invoked test_bot.Shape.GatherContext() method", "", "This is WRONG because 'invoked' is an ACTION, not a state.", "The scenario's first action must be When, not Given.", "", "Other common mistakes:", "- Given user clicks button (WRONG - clicking is action, use When)", "- Given system sends message (WRONG - sending is action, use When)", "- Given API is called (WRONG - calling is action, use When)", "- Given tool executes (WRONG - executing is action, use When)"]}}, {"do": {"description": "Given = preconditions (state), When = trigger (action), Then = outcomes", "content": ["Structure of every scenario:", "", "Given <state/config> - What exists, is configured, is true BEFORE the action", "And <more state> - Additional preconditions", "When <action> - The ONE thing that triggers the behavior (external stimulus)", "Then <outcome> - What should happen as a result", "And <more outcomes> - Additional expected results", "", "Example:", "Given a bot with name 'test_bot' (STATE - bot exists)", "And bot has behavior configured as 'shape' (STATE - configured)", "When Tool invokes test_bot.Shape.GatherContext() (ACTION - trigger)", "Then Action loads instructions (OUTCOME - result)", "And Action merges instructions (OUTCOME - more results)"]}, "dont": {"description": "Don't confuse state with actions", "content": ["Ask yourself: Is this describing WHAT EXISTS or WHAT HAPPENS?", "", "If it describes WHAT EXISTS \u2192 Given", "If it describes WHAT HAPPENS \u2192 When (if first action) or Then (if result)", "", "WRONG patterns to avoid:", "- Given <something> happened (past tense action \u2192 use When)", "- Given <actor> does <action> (present tense action \u2192 use When)", "- Given <system> executes <process> (action \u2192 use When)"]}}]}}, {"rule_file": "given_uses_state_language.json", "rule_content": {"description": "Given statements must use state-oriented language (not action-oriented). Given describes STATE, not actions.", "examples": [{"do": {"description": "Given uses state language", "content": ["Given user is logged in (state)", "Given character sheet exists (state)"]}, "dont": {"description": "Given doesn't use action language", "content": ["Given user logs in (action - WRONG)", "Given system creates character (action - WRONG)"]}}]}}, {"rule_file": "scenarios_cover_all_cases.json", "rule_content": {"description": "Scenarios must cover happy path, edge cases, and error cases based on acceptance criteria.", "examples": [{"do": {"description": "Complete scenario coverage", "content": ["Happy path: User enters valid data \u2192 System saves.", "Edge case: User enters boundary value \u2192 System validates.", "Error case: User enters invalid data \u2192 System shows error."]}, "dont": {"description": "Don't skip scenario types", "content": ["Only happy path scenarios (missing edge cases and error cases)"]}}]}}, {"rule_file": "scenarios_on_story_docs.json", "rule_content": {"description": "CRITICAL SCOPE: Scenarios work on STORY documents (\ud83d\udcdd *.md files), NOT feature documents. NEVER creates feature specification documents.", "examples": [{"do": {"description": "Add scenarios to story documents", "content": ["docs/stories/Epic/Feature/\ud83d\udcdd Story Name.md - Scenarios section added"]}, "dont": {"description": "Don't create feature specification documents", "content": ["docs/stories/Epic/Feature/Feature Specification.md (WRONG - scenarios go in story docs)"]}}]}}, {"rule_file": "scenario_steps_start_with_scenario_specific_given.json", "rule_content": {"description": "CRITICAL: Each scenario's Steps section starts with Given steps for scenario-specific setup. Background steps are automatically applied before scenario Steps. Scenario Steps should contain setup specific to THIS scenario only, not common setup that belongs in Background.", "examples": [{"do": {"description": "What goes in scenario Steps Given section - Scenario-specific setup only", "content": ["**What goes in scenario Steps Given section:**", "- Setup specific to THIS scenario only", "- Variable-dependent setup (even if similar across scenarios)", "- Test data setup (paths, file names, etc.)", "- Scenario-specific preconditions", "- Any setup that is NOT true for ALL scenarios", "", "**GOOD Example structure:**", "- Background has: \"Given Agent is initialized with agent_name='story_bot'\" (common to ALL scenarios)", "- Background has: \"Given Project is finished initializing\" (common to ALL scenarios)", "- Scenario Steps start with: \"Given test project area is set up at test_data/projects/valid-project\" (scenario-specific)", "- Scenario Steps continue with: \"And valid base agent.json exists at test_data/agents/base/agent.json\" (scenario-specific)", "", "**Example scenario Steps:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And valid base agent.json exists at test_data/agents/base/agent.json", "When Project initializes with project_path='test_data/projects/valid-project'", "Then Project loads agent configuration from agent.json", "```"]}, "dont": {"description": "Don't put common setup in scenario Steps or scenario-specific setup in Background", "content": ["**BAD Example (what NOT to do):**", "- Background has: \"Given test project area is set up at test_data/projects/valid-project\" (WRONG - this is scenario-specific)", "- Scenario Steps start with: \"Given Agent is initialized\" (WRONG - this belongs in Background if true for all scenarios)", "", "**Common mistakes:**", "- Including common setup in scenario Steps that should be in Background", "- Including scenario-specific setup in Background that should be in scenario Steps", "- Repeating Background steps in scenario Steps (Background is automatically applied)", "", "**WRONG Example:**", "```gherkin", "Given Agent is initialized with agent_name='story_bot'", "And Project is finished initializing", "And test project area is set up at test_data/projects/valid-project", "When Project initializes", "```", "(WRONG - first two Given steps belong in Background, only last Given is scenario-specific)"]}}]}}, {"rule_file": "story_filename_matches_story_name.json", "rule_content": {"description": "CRITICAL: Story filenames must match the story name exactly (no actor prefix). Actor information belongs in story description or acceptance criteria, NOT in the filename.", "examples": [{"do": {"description": "Filename matches story name without actor", "content": ["CORRECT:", "Story name: 'Route To MCP Behavior Tool'", "Filename: \ud83d\udcdd Route To MCP Behavior Tool.md", "", "Story name: 'Saves Behavior State'", "Filename: \ud83d\udcdd Saves Behavior State.md", "", "Story name: 'Track Activity for Gather Context Action'", "Filename: \ud83d\udcdd Track Activity for Gather Context Action.md"]}, "dont": {"description": "Don't include actor name in filename", "content": ["WRONG:", "Story name: 'Route To MCP Behavior Tool'", "Filename: \ud83d\udcdd AI Chat Route To MCP Behavior Tool.md", "(Actor 'AI Chat' should NOT be in filename)", "", "Story name: 'Saves Behavior State'", "Filename: \ud83d\udcdd Bot Behavior Saves Behavior State.md", "(Actor 'Bot Behavior' should NOT be in filename)", "", "Story name: 'Track Activity for Gather Context Action'", "Filename: \ud83d\udcdd GatherContextAction Track Activity.md", "(Actor 'GatherContextAction' should NOT be in filename)", "", "Common mistakes:", "- Including actor/user name from story description in filename", "- Prefixing filename with 'AI Chat', 'Router', 'Bot Behavior', etc.", "- Adding class/component names to filename", "", "Actor information belongs in:", "- Story description", "- Acceptance criteria (WHEN actor does X...)", "- NOT in the filename"]}}]}}, {"rule_file": "use_background_for_common_setup.json", "rule_content": {"description": "CRITICAL: Background section is ONLY for common setup steps shared across 3+ scenarios. DO NOT include scenario-specific setup here. Background contains only Given/And steps (no When/Then). Scenario-specific setup goes in scenario Steps as Given steps, not in Background.", "examples": [{"do": {"description": "What belongs in Background - Setup steps that are TRUE for ALL scenarios (100% of scenarios)", "content": ["**What belongs in Background:**", "- Setup steps that are TRUE for ALL scenarios in this story (100% of scenarios)", "- Common preconditions that every single scenario needs", "- Shared system state that applies to all scenarios without exception", "- Steps that never vary between scenarios", "", "**Examples of valid Background steps:**", "- Given Agent is initialized with agent_name='story_bot' (true for ALL scenarios)", "- Given Cursor/VS Code chat window is open (true for ALL scenarios)", "- Given Project is finished initializing (true for ALL scenarios)", "", "**GOOD Example:**", "```gherkin", "Given Agent is initialized with agent_name='story_bot'", "And Project is finished initializing", "```", "These are true for ALL scenarios in that story."]}, "dont": {"description": "What does NOT belong in Background - Scenario-specific or variable-dependent setup", "content": ["**What does NOT belong in Background:**", "- Scenario-specific setup (goes in scenario Steps as Given)", "- Variable-dependent setup (goes in scenario Steps)", "- Setup that only applies to some scenarios (goes in scenario Steps)", "- Test data paths or file names (goes in scenario Steps)", "- Conditional setup (goes in scenario Steps)", "", "**Examples of invalid Background steps:**", "- Given test project area is set up at test_data/projects/valid-project (WRONG - scenario-specific, goes in Steps)", "- Given user has attached documents to chat window (WRONG if not true for ALL scenarios - check if all scenarios need this)", "", "**BAD Example:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And test agent base area is set up at test_data/agents/base", "```", "These are scenario-specific and belong in scenario Steps, not Background."]}}, {"do": {"description": "Background for shared context, scenario-specific Given in Steps", "content": ["## Background", "", "**Common setup steps shared across all scenarios:**", "", "```gherkin", "Given Agent is initialized with agent_name='story_bot'", "And Project is finished initializing", "```", "", "## Scenarios", "", "### Scenario: Agent loads configurations", "", "**Steps:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And valid base agent.json exists at test_data/agents/base/agent.json", "When Project initializes with project_path='test_data/projects/valid-project'", "Then Project loads agent configuration from agent.json", "```", "", "**Key points:**", "- Background has common setup (true for ALL scenarios)", "- Scenario Steps start with scenario-specific Given steps", "- Background steps are automatically applied before scenario Steps"]}, "dont": {"description": "Don't put scenario-specific setup in Background or repeat Background in each scenario", "content": ["**BAD Example (what NOT to do):**", "", "## Background", "", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "```", "", "### Scenario: Agent loads configurations", "", "**Background:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And Project is finished initializing", "```", "", "(WRONG - Background repeated in scenario, scenario-specific setup in Background)", "", "**Common mistakes:**", "- Background has scenario-specific setup (WRONG - this is scenario-specific)", "- Scenario Steps start with common setup (WRONG - this belongs in Background if true for all scenarios)", "- Background repeated in each scenario (WRONG - Background is at story level only)"]}}]}}, {"rule_file": "write_plain_english_scenarios.json", "rule_content": {"description": "Write scenarios in plain English. NO variables, NO placeholders, NO Scenario Outlines, NO Examples tables at this stage.", "examples": [{"do": {"description": "Plain English scenarios", "content": ["Given user has attached documents to chat window", "And user has typed request message 'start shaping'", "When AI Chat processes request", "Then AI Chat identifies story shaping keywords"]}, "dont": {"description": "Don't use variables or placeholders", "content": ["Given user has typed request message \"<request_message>\" (WRONG - has variable)", "Scenario Outline: AI Chat detects keywords (WRONG - Outline at this stage)", "Examples: | request_message | (WRONG - Examples at this stage)"]}}]}}], "content_to_validate": {"project_location": "C:\\dev\\augmented-teams\\demo\\mob_minion", "rendered_outputs": ["C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-description.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-diagram.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json"], "clarification_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\clarification.json", "planning_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\planning.json", "report_path": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\validation-report.md"}}}}, "90": {"action_state": "story_bot.6_scenarios.render_output", "status": "started", "timestamp": "2025-12-10T01:21:17.954424"}, "91": {"action_state": "story_bot.6_scenarios.render_output", "status": "completed", "timestamp": "2025-12-10T01:21:18.001527", "outputs": {"instructions": {"action": "render_output", "behavior": "6_scenarios", "base_instructions": ["\n**PROJECT PATH: C:\\dev\\augmented-teams\\demo\\mob_minion**\nAll render outputs must be written to paths relative to this project path, NOT to the bot's own directories.", "Instruction for render_output", "Instantiate synchronizer class synchronizers.story_scenarios.StoryScenariosSynchronizer and call render method with renderer_command='render', input_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json, and output_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\docs\\stories"], "render_instructions": {"behaviorName": "specification_scenarios", "step": "2_render", "instructions": ["**RENDER STORY DOCUMENTS WITH SCENARIOS**", "", "**Input:** Updated story-graph.json with scenarios (and scenario outlines if decision criteria chosen) from knowledge graph step", "", "**Output:** Individual story documents with scenarios section added (and scenario outlines with examples if decision criteria chosen)", "", "**Process:**", "", "1. **Load story graph** from project area: docs/stories/story-graph.json", "", "2. **Check decision criteria:**", "   - Review planning decision criteria: agile_bot/bots/story_bot/behaviors/6_scenarios/1_guardrails/planning/decision_criteria/scenario_outline.json", "   - **IF decision criteria answer is 'Yes':** Render Scenario Outlines with Examples tables (see step 4b)", "   - **IF decision criteria answer is 'No':** Render regular scenarios only (see step 4a)", "", "3. **For each story in the graph:**", "   - Create folder structure: docs/stories/map/{epic_name}/{feature_name}/", "   - Use emoji monikers: \ud83c\udfaf for Epic folders, \u2699\ufe0f for Feature folders", "   - Only create folders where stories actually exist", "   - Create story document: docs/stories/map/{epic_name}/{feature_name}/{story_name}.md", "   - Keep existing sections: Story Description, Acceptance Criteria", "   - Add new sections: Background (if applicable), Scenarios (with Scenario Outlines and Examples if decision criteria = 'Yes')", "", "4a. **Render Background section** (if story has background steps):", "   ```markdown", "   ## Background", "   ", "   **Common setup steps shared across all scenarios:**", "   ", "   ```gherkin", "   Given <step>", "   And <step>", "   ```", "   ```", "", "4b. **Render Scenarios section:**", "   ```markdown", "   ## Scenarios", "   ", "   ### Scenario: {scenario_name} ({scenario_type})", "   ", "   **Steps:**", "   ```gherkin", "   Given <step>", "   When <step>", "   Then <step>", "   ```", "   ", "   ### Scenario Outline: {scenario_outline_name} ({type})", "   ", "   **Note:** Scenario Outlines with Examples tables are included ONLY when decision criteria chooses Scenario Outline", "   ", "   **Steps:**", "   ```gherkin", "   Given <step with \\\"<variable>\\\">", "   When <step with \\\"<variable>\\\">", "   Then <step with \\\"<expected>\\\"", "   ```", "   ", "   **Examples:**", "   | variable | expected |", "   |----------|----------|", "   | value1   | result1  |", "   | value2   | result2  |", "   ```", "   ```", "", "5. **Save updated story documents** to project area", "", "**Template:** templates/story-doc-scenarios.md (scenarios include examples when decision criteria chooses Scenario Outline)", "", "**Validation:**", "- All existing story content is preserved", "- Background section only included if story has background steps", "- All scenarios are rendered with proper Gherkin formatting", "- Scenario types are indicated (happy_path, edge_case, error_case)", "- **IF Scenario Outlines are used (decision criteria = 'Yes'):**", "  * Scenario Outlines are rendered within the Scenarios section", "  * Scenario Outlines are rendered with proper Gherkin formatting", "  * Examples tables have all required columns matching variables in Steps", "  * Examples tables contain concrete test data (no placeholders)", "  * At least 2 rows of test data per Scenario Outline"]}, "render_configs": [{"file": "behaviors\\6_scenarios\\2_content\\2_render\\render_story_scenarios.json", "config": {"name": "render_story_scenarios", "type": "synchronizer", "path": "docs/stories", "input": "story-graph.json", "synchronizer": "synchronizers.story_scenarios.StoryScenariosSynchronizer", "output": "docs/stories", "instructions": "Render story-graph.json to story markdown files with scenarios. The synchronizer reads the story graph and generates markdown files for all Bot/system stories (excluding Human/AI Chat stories). Each story file includes acceptance criteria and scenarios sections. Files are placed in the appropriate epic/feature folder structure based on the graph hierarchy."}}], "project_path": "C:\\dev\\augmented-teams\\demo\\mob_minion"}}}, "92": {"action_state": "story_bot.6_scenarios.render_output", "status": "started", "timestamp": "2025-12-10T01:24:05.000364"}, "93": {"action_state": "story_bot.6_scenarios.render_output", "status": "completed", "timestamp": "2025-12-10T01:24:05.021374", "outputs": {"instructions": {"action": "render_output", "behavior": "6_scenarios", "base_instructions": ["\n**PROJECT PATH: C:\\dev\\augmented-teams\\demo\\mob_minion**\nAll render outputs must be written to paths relative to this project path, NOT to the bot's own directories.", "Instruction for render_output", "Instantiate synchronizer class synchronizers.story_scenarios.StoryScenariosSynchronizer and call render method with renderer_command='render', input_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json, and output_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\docs\\stories"], "render_instructions": {"behaviorName": "specification_scenarios", "step": "2_render", "instructions": ["**RENDER STORY DOCUMENTS WITH SCENARIOS**", "", "**Input:** Updated story-graph.json with scenarios (and scenario outlines if decision criteria chosen) from knowledge graph step", "", "**Output:** Individual story documents with scenarios section added (and scenario outlines with examples if decision criteria chosen)", "", "**Process:**", "", "1. **Load story graph** from project area: docs/stories/story-graph.json", "", "2. **Check decision criteria:**", "   - Review planning decision criteria: agile_bot/bots/story_bot/behaviors/6_scenarios/1_guardrails/planning/decision_criteria/scenario_outline.json", "   - **IF decision criteria answer is 'Yes':** Render Scenario Outlines with Examples tables (see step 4b)", "   - **IF decision criteria answer is 'No':** Render regular scenarios only (see step 4a)", "", "3. **For each story in the graph:**", "   - Create folder structure: docs/stories/map/{epic_name}/{feature_name}/", "   - Use emoji monikers: \ud83c\udfaf for Epic folders, \u2699\ufe0f for Feature folders", "   - Only create folders where stories actually exist", "   - Create story document: docs/stories/map/{epic_name}/{feature_name}/{story_name}.md", "   - Keep existing sections: Story Description, Acceptance Criteria", "   - Add new sections: Background (if applicable), Scenarios (with Scenario Outlines and Examples if decision criteria = 'Yes')", "", "4a. **Render Background section** (if story has background steps):", "   ```markdown", "   ## Background", "   ", "   **Common setup steps shared across all scenarios:**", "   ", "   ```gherkin", "   Given <step>", "   And <step>", "   ```", "   ```", "", "4b. **Render Scenarios section:**", "   ```markdown", "   ## Scenarios", "   ", "   ### Scenario: {scenario_name} ({scenario_type})", "   ", "   **Steps:**", "   ```gherkin", "   Given <step>", "   When <step>", "   Then <step>", "   ```", "   ", "   ### Scenario Outline: {scenario_outline_name} ({type})", "   ", "   **Note:** Scenario Outlines with Examples tables are included ONLY when decision criteria chooses Scenario Outline", "   ", "   **Steps:**", "   ```gherkin", "   Given <step with \\\"<variable>\\\">", "   When <step with \\\"<variable>\\\">", "   Then <step with \\\"<expected>\\\"", "   ```", "   ", "   **Examples:**", "   | variable | expected |", "   |----------|----------|", "   | value1   | result1  |", "   | value2   | result2  |", "   ```", "   ```", "", "5. **Save updated story documents** to project area", "", "**Template:** templates/story-doc-scenarios.md (scenarios include examples when decision criteria chooses Scenario Outline)", "", "**Validation:**", "- All existing story content is preserved", "- Background section only included if story has background steps", "- All scenarios are rendered with proper Gherkin formatting", "- Scenario types are indicated (happy_path, edge_case, error_case)", "- **IF Scenario Outlines are used (decision criteria = 'Yes'):**", "  * Scenario Outlines are rendered within the Scenarios section", "  * Scenario Outlines are rendered with proper Gherkin formatting", "  * Examples tables have all required columns matching variables in Steps", "  * Examples tables contain concrete test data (no placeholders)", "  * At least 2 rows of test data per Scenario Outline"]}, "render_configs": [{"file": "behaviors\\6_scenarios\\2_content\\2_render\\render_story_scenarios.json", "config": {"name": "render_story_scenarios", "type": "synchronizer", "path": "docs/stories", "input": "story-graph.json", "synchronizer": "synchronizers.story_scenarios.StoryScenariosSynchronizer", "output": "docs/stories", "instructions": "Render story-graph.json to story markdown files with scenarios. The synchronizer reads the story graph and generates markdown files for all Bot/system stories (excluding Human/AI Chat stories). Each story file includes acceptance criteria and scenarios sections. Files are placed in the appropriate epic/feature folder structure based on the graph hierarchy."}}], "project_path": "C:\\dev\\augmented-teams\\demo\\mob_minion"}}}, "94": {"action_state": "story_bot.6_scenarios.render_output", "status": "started", "timestamp": "2025-12-10T01:24:55.498303"}, "95": {"action_state": "story_bot.6_scenarios.render_output", "status": "completed", "timestamp": "2025-12-10T01:24:55.517994", "outputs": {"instructions": {"action": "render_output", "behavior": "6_scenarios", "base_instructions": ["\n**PROJECT PATH: C:\\dev\\augmented-teams\\demo\\mob_minion**\nAll render outputs must be written to paths relative to this project path, NOT to the bot's own directories.", "Instruction for render_output", "Instantiate synchronizer class synchronizers.story_scenarios.StoryScenariosSynchronizer and call render method with renderer_command='render', input_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json, and output_path=C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\docs\\stories"], "render_instructions": {"behaviorName": "specification_scenarios", "step": "2_render", "instructions": ["**RENDER STORY DOCUMENTS WITH SCENARIOS**", "", "**Input:** Updated story-graph.json with scenarios (and scenario outlines if decision criteria chosen) from knowledge graph step", "", "**Output:** Individual story documents with scenarios section added (and scenario outlines with examples if decision criteria chosen)", "", "**Process:**", "", "1. **Load story graph** from project area: docs/stories/story-graph.json", "", "2. **Check decision criteria:**", "   - Review planning decision criteria: agile_bot/bots/story_bot/behaviors/6_scenarios/1_guardrails/planning/decision_criteria/scenario_outline.json", "   - **IF decision criteria answer is 'Yes':** Render Scenario Outlines with Examples tables (see step 4b)", "   - **IF decision criteria answer is 'No':** Render regular scenarios only (see step 4a)", "", "3. **For each story in the graph:**", "   - Create folder structure: docs/stories/map/{epic_name}/{feature_name}/", "   - Use emoji monikers: \ud83c\udfaf for Epic folders, \u2699\ufe0f for Feature folders", "   - Only create folders where stories actually exist", "   - Create story document: docs/stories/map/{epic_name}/{feature_name}/{story_name}.md", "   - Keep existing sections: Story Description, Acceptance Criteria", "   - Add new sections: Background (if applicable), Scenarios (with Scenario Outlines and Examples if decision criteria = 'Yes')", "", "4a. **Render Background section** (if story has background steps):", "   ```markdown", "   ## Background", "   ", "   **Common setup steps shared across all scenarios:**", "   ", "   ```gherkin", "   Given <step>", "   And <step>", "   ```", "   ```", "", "4b. **Render Scenarios section:**", "   ```markdown", "   ## Scenarios", "   ", "   ### Scenario: {scenario_name} ({scenario_type})", "   ", "   **Steps:**", "   ```gherkin", "   Given <step>", "   When <step>", "   Then <step>", "   ```", "   ", "   ### Scenario Outline: {scenario_outline_name} ({type})", "   ", "   **Note:** Scenario Outlines with Examples tables are included ONLY when decision criteria chooses Scenario Outline", "   ", "   **Steps:**", "   ```gherkin", "   Given <step with \\\"<variable>\\\">", "   When <step with \\\"<variable>\\\">", "   Then <step with \\\"<expected>\\\"", "   ```", "   ", "   **Examples:**", "   | variable | expected |", "   |----------|----------|", "   | value1   | result1  |", "   | value2   | result2  |", "   ```", "   ```", "", "5. **Save updated story documents** to project area", "", "**Template:** templates/story-doc-scenarios.md (scenarios include examples when decision criteria chooses Scenario Outline)", "", "**Validation:**", "- All existing story content is preserved", "- Background section only included if story has background steps", "- All scenarios are rendered with proper Gherkin formatting", "- Scenario types are indicated (happy_path, edge_case, error_case)", "- **IF Scenario Outlines are used (decision criteria = 'Yes'):**", "  * Scenario Outlines are rendered within the Scenarios section", "  * Scenario Outlines are rendered with proper Gherkin formatting", "  * Examples tables have all required columns matching variables in Steps", "  * Examples tables contain concrete test data (no placeholders)", "  * At least 2 rows of test data per Scenario Outline"]}, "render_configs": [{"file": "behaviors\\6_scenarios\\2_content\\2_render\\render_story_scenarios.json", "config": {"name": "render_story_scenarios", "type": "synchronizer", "path": "docs/stories", "input": "story-graph.json", "synchronizer": "synchronizers.story_scenarios.StoryScenariosSynchronizer", "output": "docs/stories", "instructions": "Render story-graph.json to story markdown files with scenarios. The synchronizer reads the story graph and generates markdown files for all Bot/system stories (excluding Human/AI Chat stories). Each story file includes acceptance criteria and scenarios sections. Files are placed in the appropriate epic/feature folder structure based on the graph hierarchy."}}], "project_path": "C:\\dev\\augmented-teams\\demo\\mob_minion"}}}, "96": {"action_state": "story_bot.6_scenarios.validate_rules", "status": "started", "timestamp": "2025-12-10T01:24:56.144304"}, "97": {"action_state": "story_bot.6_scenarios.validate_rules", "status": "completed", "timestamp": "2025-12-10T01:24:56.166268", "outputs": {"instructions": {"action": "validate_rules", "behavior": "6_scenarios", "base_instructions": ["Load and review clarification.json and planning.json", "Check Content Data against all rules listed above", "Generate a validation report", "Save the validation report to validation-report.md in docs/stories/", "", "**NEXT BEHAVIOR REMINDER:**", "After completing this behavior, the next behavior in sequence is `7_tests`. When the user is ready to continue, remind them: 'The next behavior in sequence is `7_tests`. Would you like to continue with `7_tests` or work on a different behavior?'"], "validation_rules": [{"rule_file": "given_describes_preconditions_not_functionality.json", "rule_content": {"description": "CRITICAL: Given statements describe PRECONDITIONS (what exists before the test), NOT the functionality being tested. If you're describing WHAT the system does or HOW it behaves, that belongs in Then statements, not Given.", "examples": [{"do": {"description": "Given describes preconditions only", "content": ["CORRECT:", "Given activity log is initialized at project_area/activity log", "Given user is logged in", "Given character sheet exists", "Given workflow state is persisted", "", "These describe STATE/EXISTENCE, not functionality."]}, "dont": {"description": "Don't describe functionality in Given - that's what you're testing", "content": ["WRONG:", "Given activity log tracks: timestamp, action_state, inputs, outputs, duration", "(This describes WHAT the activity log DOES - that's the functionality being tested!)", "", "Given system validates user input", "(This describes WHAT the system DOES - that's functionality, not a precondition!)", "", "Given bot routes to correct action based on workflow state", "(This describes HOW the bot BEHAVES - that's what you're testing!)", "", "Ask yourself: Am I describing WHAT EXISTS or WHAT THE SYSTEM DOES?", "- If describing WHAT EXISTS \u2192 Given (precondition)", "- If describing WHAT THE SYSTEM DOES \u2192 Then (expected behavior being tested)", "", "Common mistakes:", "- Describing data structure/format in Given (that's functionality to test in Then)", "- Describing system behavior in Given (that's what you're testing in Then)", "- Describing validation rules in Given (that's functionality to test in Then)", "", "CORRECT approach:", "Given activity log is initialized (precondition - it exists)", "When action completes", "Then activity log captures: timestamp, action_state, inputs, outputs, duration (functionality being tested)"]}}]}}, {"rule_file": "given_describes_state_not_actions.json", "rule_content": {"description": "CRITICAL: Given statements describe STATE/CONFIGURATION, never actions or events. The first action in a scenario is ALWAYS a When, never a Given. Given sets up preconditions, When triggers the behavior being tested.", "examples": [{"do": {"description": "Given describes state, When triggers action", "content": ["CORRECT:", "Given a bot with name 'test_bot'", "And bot has a behavior configured as 'shape'", "And behavior has action 'gather_context'", "When Tool invokes test_bot.Shape.GatherContext() method", "", "Given = STATE (bot exists, is configured)", "When = ACTION (tool invokes method)"]}, "dont": {"description": "Don't use Given for actions - first action is ALWAYS When", "content": ["WRONG:", "Given Tool has invoked test_bot.Shape.GatherContext() method", "", "This is WRONG because 'invoked' is an ACTION, not a state.", "The scenario's first action must be When, not Given.", "", "Other common mistakes:", "- Given user clicks button (WRONG - clicking is action, use When)", "- Given system sends message (WRONG - sending is action, use When)", "- Given API is called (WRONG - calling is action, use When)", "- Given tool executes (WRONG - executing is action, use When)"]}}, {"do": {"description": "Given = preconditions (state), When = trigger (action), Then = outcomes", "content": ["Structure of every scenario:", "", "Given <state/config> - What exists, is configured, is true BEFORE the action", "And <more state> - Additional preconditions", "When <action> - The ONE thing that triggers the behavior (external stimulus)", "Then <outcome> - What should happen as a result", "And <more outcomes> - Additional expected results", "", "Example:", "Given a bot with name 'test_bot' (STATE - bot exists)", "And bot has behavior configured as 'shape' (STATE - configured)", "When Tool invokes test_bot.Shape.GatherContext() (ACTION - trigger)", "Then Action loads instructions (OUTCOME - result)", "And Action merges instructions (OUTCOME - more results)"]}, "dont": {"description": "Don't confuse state with actions", "content": ["Ask yourself: Is this describing WHAT EXISTS or WHAT HAPPENS?", "", "If it describes WHAT EXISTS \u2192 Given", "If it describes WHAT HAPPENS \u2192 When (if first action) or Then (if result)", "", "WRONG patterns to avoid:", "- Given <something> happened (past tense action \u2192 use When)", "- Given <actor> does <action> (present tense action \u2192 use When)", "- Given <system> executes <process> (action \u2192 use When)"]}}]}}, {"rule_file": "given_uses_state_language.json", "rule_content": {"description": "Given statements must use state-oriented language (not action-oriented). Given describes STATE, not actions.", "examples": [{"do": {"description": "Given uses state language", "content": ["Given user is logged in (state)", "Given character sheet exists (state)"]}, "dont": {"description": "Given doesn't use action language", "content": ["Given user logs in (action - WRONG)", "Given system creates character (action - WRONG)"]}}]}}, {"rule_file": "scenarios_cover_all_cases.json", "rule_content": {"description": "Scenarios must cover happy path, edge cases, and error cases based on acceptance criteria.", "examples": [{"do": {"description": "Complete scenario coverage", "content": ["Happy path: User enters valid data \u2192 System saves.", "Edge case: User enters boundary value \u2192 System validates.", "Error case: User enters invalid data \u2192 System shows error."]}, "dont": {"description": "Don't skip scenario types", "content": ["Only happy path scenarios (missing edge cases and error cases)"]}}]}}, {"rule_file": "scenarios_on_story_docs.json", "rule_content": {"description": "CRITICAL SCOPE: Scenarios work on STORY documents (\ud83d\udcdd *.md files), NOT feature documents. NEVER creates feature specification documents.", "examples": [{"do": {"description": "Add scenarios to story documents", "content": ["docs/stories/Epic/Feature/\ud83d\udcdd Story Name.md - Scenarios section added"]}, "dont": {"description": "Don't create feature specification documents", "content": ["docs/stories/Epic/Feature/Feature Specification.md (WRONG - scenarios go in story docs)"]}}]}}, {"rule_file": "scenario_steps_start_with_scenario_specific_given.json", "rule_content": {"description": "CRITICAL: Each scenario's Steps section starts with Given steps for scenario-specific setup. Background steps are automatically applied before scenario Steps. Scenario Steps should contain setup specific to THIS scenario only, not common setup that belongs in Background.", "examples": [{"do": {"description": "What goes in scenario Steps Given section - Scenario-specific setup only", "content": ["**What goes in scenario Steps Given section:**", "- Setup specific to THIS scenario only", "- Variable-dependent setup (even if similar across scenarios)", "- Test data setup (paths, file names, etc.)", "- Scenario-specific preconditions", "- Any setup that is NOT true for ALL scenarios", "", "**GOOD Example structure:**", "- Background has: \"Given Agent is initialized with agent_name='story_bot'\" (common to ALL scenarios)", "- Background has: \"Given Project is finished initializing\" (common to ALL scenarios)", "- Scenario Steps start with: \"Given test project area is set up at test_data/projects/valid-project\" (scenario-specific)", "- Scenario Steps continue with: \"And valid base agent.json exists at test_data/agents/base/agent.json\" (scenario-specific)", "", "**Example scenario Steps:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And valid base agent.json exists at test_data/agents/base/agent.json", "When Project initializes with project_path='test_data/projects/valid-project'", "Then Project loads agent configuration from agent.json", "```"]}, "dont": {"description": "Don't put common setup in scenario Steps or scenario-specific setup in Background", "content": ["**BAD Example (what NOT to do):**", "- Background has: \"Given test project area is set up at test_data/projects/valid-project\" (WRONG - this is scenario-specific)", "- Scenario Steps start with: \"Given Agent is initialized\" (WRONG - this belongs in Background if true for all scenarios)", "", "**Common mistakes:**", "- Including common setup in scenario Steps that should be in Background", "- Including scenario-specific setup in Background that should be in scenario Steps", "- Repeating Background steps in scenario Steps (Background is automatically applied)", "", "**WRONG Example:**", "```gherkin", "Given Agent is initialized with agent_name='story_bot'", "And Project is finished initializing", "And test project area is set up at test_data/projects/valid-project", "When Project initializes", "```", "(WRONG - first two Given steps belong in Background, only last Given is scenario-specific)"]}}]}}, {"rule_file": "story_filename_matches_story_name.json", "rule_content": {"description": "CRITICAL: Story filenames must match the story name exactly (no actor prefix). Actor information belongs in story description or acceptance criteria, NOT in the filename.", "examples": [{"do": {"description": "Filename matches story name without actor", "content": ["CORRECT:", "Story name: 'Route To MCP Behavior Tool'", "Filename: \ud83d\udcdd Route To MCP Behavior Tool.md", "", "Story name: 'Saves Behavior State'", "Filename: \ud83d\udcdd Saves Behavior State.md", "", "Story name: 'Track Activity for Gather Context Action'", "Filename: \ud83d\udcdd Track Activity for Gather Context Action.md"]}, "dont": {"description": "Don't include actor name in filename", "content": ["WRONG:", "Story name: 'Route To MCP Behavior Tool'", "Filename: \ud83d\udcdd AI Chat Route To MCP Behavior Tool.md", "(Actor 'AI Chat' should NOT be in filename)", "", "Story name: 'Saves Behavior State'", "Filename: \ud83d\udcdd Bot Behavior Saves Behavior State.md", "(Actor 'Bot Behavior' should NOT be in filename)", "", "Story name: 'Track Activity for Gather Context Action'", "Filename: \ud83d\udcdd GatherContextAction Track Activity.md", "(Actor 'GatherContextAction' should NOT be in filename)", "", "Common mistakes:", "- Including actor/user name from story description in filename", "- Prefixing filename with 'AI Chat', 'Router', 'Bot Behavior', etc.", "- Adding class/component names to filename", "", "Actor information belongs in:", "- Story description", "- Acceptance criteria (WHEN actor does X...)", "- NOT in the filename"]}}]}}, {"rule_file": "use_background_for_common_setup.json", "rule_content": {"description": "CRITICAL: Background section is ONLY for common setup steps shared across 3+ scenarios. DO NOT include scenario-specific setup here. Background contains only Given/And steps (no When/Then). Scenario-specific setup goes in scenario Steps as Given steps, not in Background.", "examples": [{"do": {"description": "What belongs in Background - Setup steps that are TRUE for ALL scenarios (100% of scenarios)", "content": ["**What belongs in Background:**", "- Setup steps that are TRUE for ALL scenarios in this story (100% of scenarios)", "- Common preconditions that every single scenario needs", "- Shared system state that applies to all scenarios without exception", "- Steps that never vary between scenarios", "", "**Examples of valid Background steps:**", "- Given Agent is initialized with agent_name='story_bot' (true for ALL scenarios)", "- Given Cursor/VS Code chat window is open (true for ALL scenarios)", "- Given Project is finished initializing (true for ALL scenarios)", "", "**GOOD Example:**", "```gherkin", "Given Agent is initialized with agent_name='story_bot'", "And Project is finished initializing", "```", "These are true for ALL scenarios in that story."]}, "dont": {"description": "What does NOT belong in Background - Scenario-specific or variable-dependent setup", "content": ["**What does NOT belong in Background:**", "- Scenario-specific setup (goes in scenario Steps as Given)", "- Variable-dependent setup (goes in scenario Steps)", "- Setup that only applies to some scenarios (goes in scenario Steps)", "- Test data paths or file names (goes in scenario Steps)", "- Conditional setup (goes in scenario Steps)", "", "**Examples of invalid Background steps:**", "- Given test project area is set up at test_data/projects/valid-project (WRONG - scenario-specific, goes in Steps)", "- Given user has attached documents to chat window (WRONG if not true for ALL scenarios - check if all scenarios need this)", "", "**BAD Example:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And test agent base area is set up at test_data/agents/base", "```", "These are scenario-specific and belong in scenario Steps, not Background."]}}, {"do": {"description": "Background for shared context, scenario-specific Given in Steps", "content": ["## Background", "", "**Common setup steps shared across all scenarios:**", "", "```gherkin", "Given Agent is initialized with agent_name='story_bot'", "And Project is finished initializing", "```", "", "## Scenarios", "", "### Scenario: Agent loads configurations", "", "**Steps:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And valid base agent.json exists at test_data/agents/base/agent.json", "When Project initializes with project_path='test_data/projects/valid-project'", "Then Project loads agent configuration from agent.json", "```", "", "**Key points:**", "- Background has common setup (true for ALL scenarios)", "- Scenario Steps start with scenario-specific Given steps", "- Background steps are automatically applied before scenario Steps"]}, "dont": {"description": "Don't put scenario-specific setup in Background or repeat Background in each scenario", "content": ["**BAD Example (what NOT to do):**", "", "## Background", "", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "```", "", "### Scenario: Agent loads configurations", "", "**Background:**", "```gherkin", "Given test project area is set up at test_data/projects/valid-project", "And Project is finished initializing", "```", "", "(WRONG - Background repeated in scenario, scenario-specific setup in Background)", "", "**Common mistakes:**", "- Background has scenario-specific setup (WRONG - this is scenario-specific)", "- Scenario Steps start with common setup (WRONG - this belongs in Background if true for all scenarios)", "- Background repeated in each scenario (WRONG - Background is at story level only)"]}}]}}, {"rule_file": "write_plain_english_scenarios.json", "rule_content": {"description": "Write scenarios in plain English. NO variables, NO placeholders, NO Scenario Outlines, NO Examples tables at this stage.", "examples": [{"do": {"description": "Plain English scenarios", "content": ["Given user has attached documents to chat window", "And user has typed request message 'start shaping'", "When AI Chat processes request", "Then AI Chat identifies story shaping keywords"]}, "dont": {"description": "Don't use variables or placeholders", "content": ["Given user has typed request message \"<request_message>\" (WRONG - has variable)", "Scenario Outline: AI Chat detects keywords (WRONG - Outline at this stage)", "Examples: | request_message | (WRONG - Examples at this stage)"]}}]}}], "content_to_validate": {"project_location": "C:\\dev\\augmented-teams\\demo\\mob_minion", "rendered_outputs": ["C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-description.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-diagram.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json"], "clarification_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\clarification.json", "planning_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\planning.json", "report_path": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\validation-report.md"}}}}, "98": {"action_state": "story_bot.7_tests.gather_context", "status": "started", "timestamp": "2025-12-10T01:26:16.292596"}, "99": {"action_state": "story_bot.7_tests.gather_context", "status": "completed", "timestamp": "2025-12-10T01:26:16.314217", "outputs": {"instructions": {"action": "gather_context", "behavior": "7_tests", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["What test framework should be used (pytest-bdd, pytest, etc.)?", "Should tests use real implementations or mocks (e2e vs unit tests)?", "What fixtures or helpers are needed for test setup?", "Are there any specific test data requirements beyond what's in Examples tables?", "What is the expected test file structure and location?", "Are there any existing test patterns or conventions to follow?"], "evidence": ["Feature files (.feature) from specification_examples stage", "Examples tables with test data", "Structured.json with scenarios and examples", "Existing test code or test patterns", "Test framework documentation"]}}}}, "100": {"action_state": "story_bot.7_tests.gather_context", "status": "started", "timestamp": "2025-12-10T01:26:16.648424"}, "101": {"action_state": "story_bot.7_tests.gather_context", "status": "completed", "timestamp": "2025-12-10T01:26:16.665429", "outputs": {"instructions": {"action": "gather_context", "behavior": "7_tests", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["What test framework should be used (pytest-bdd, pytest, etc.)?", "Should tests use real implementations or mocks (e2e vs unit tests)?", "What fixtures or helpers are needed for test setup?", "Are there any specific test data requirements beyond what's in Examples tables?", "What is the expected test file structure and location?", "Are there any existing test patterns or conventions to follow?"], "evidence": ["Feature files (.feature) from specification_examples stage", "Examples tables with test data", "Structured.json with scenarios and examples", "Existing test code or test patterns", "Test framework documentation"]}}}}, "102": {"action_state": "story_bot.7_tests.decide_planning_criteria", "status": "started", "timestamp": "2025-12-10T01:26:48.323200"}, "103": {"action_state": "story_bot.7_tests.decide_planning_criteria", "status": "completed", "timestamp": "2025-12-10T01:26:48.346204", "outputs": {"instructions": {"assumptions": ["Tests must match feature files exactly - no new steps, no modified step text", "Step definitions must use exact text from feature files", "Assertions must verify what the steps say they verify", "Tests should use real implementations by default", "Only mock when explicitly asked for e2e tests or for uncontrollable external dependencies", "All test code must use ASCII-only characters (no Unicode)", "Tests should call production code directly - let tests fail naturally if code doesn't exist"], "decision_criteria": {"mocking_strategy": {"description": "Mocking strategy", "question": "Should tests use mocks or real implementations?", "outcome": "Determines whether to mock external dependencies", "options": ["Real implementations - use actual code with temporary test data (default)", "Mock framwork and tools - file I/O, databases, network, on top of external APIs (for system level)", "Mock external dependencies - mock external APIs, integrations, external systems", "No mocking - use real implementations for everything (for whole solution)"]}, "test_scope_level": {"description": "Test scope level", "question": "What scope level should acceptance tests cover?", "outcome": "Determines test implementation approach", "options": ["Component/Service level - test individual components/services in isolation (minimum)", "System level - test full system with external systems mocked out", "Whole solution - test entire solution including external systems"]}}}}}, "104": {"action_state": "story_bot.7_tests.build_knowledge", "status": "started", "timestamp": "2025-12-10T01:27:03.098245"}, "105": {"action_state": "story_bot.7_tests.render_output", "status": "started", "timestamp": "2025-12-10T01:29:05.227431"}, "106": {"action_state": "story_bot.7_tests.render_output", "status": "completed", "timestamp": "2025-12-10T01:29:05.249490", "outputs": {"instructions": {"action": "render_output", "behavior": "7_tests", "base_instructions": ["\n**PROJECT PATH: C:\\dev\\augmented-teams\\demo\\mob_minion**\nAll render outputs must be written to paths relative to this project path, NOT to the bot's own directories.", "Instruction for render_output"], "project_path": "C:\\dev\\augmented-teams\\demo\\mob_minion"}}}, "107": {"action_state": "story_bot.7_tests.validate_rules", "status": "started", "timestamp": "2025-12-10T01:29:38.754485"}, "108": {"action_state": "story_bot.7_tests.validate_rules", "status": "completed", "timestamp": "2025-12-10T01:29:38.780937", "outputs": {"instructions": {"action": "validate_rules", "behavior": "7_tests", "base_instructions": ["Load and review clarification.json and planning.json", "Check Content Data against all rules listed above", "Generate a validation report", "Save the validation report to validation-report.md in docs/stories/", "", "**NEXT BEHAVIOR REMINDER:**", "After completing this behavior, the next behavior in sequence is `8_code`. When the user is ready to continue, remind them: 'The next behavior in sequence is `8_code`. Would you like to continue with `8_code` or work on a different behavior?'"], "validation_rules": [{"rule_file": "bug_fix_test_first.json", "rule_content": {"description": "When production code breaks, ALWAYS follow the test-first workflow: write/modify failing test, verify failure, fix code, verify success, then test in production. Never fix bugs directly without a failing test first.", "rationale": ["Writing a failing test before fixing a bug ensures: (1) we can reproduce the bug, (2) we know when it's truly fixed, (3) we prevent regression, (4) we document the bug for future reference.", "Skipping the failing test step means we might fix the wrong thing or not really fix it at all.", "A failing test proves we understand the bug and can reproduce it. Without this, we're guessing at the fix.", "If the test doesn't fail, either: (a) we're testing the wrong thing, (b) the bug doesn't exist in test environment, (c) the test is wrong. We must know the test fails before proceeding.", "Minimal fixes reduce risk of introducing new bugs. If more changes are needed, they should be separate commits with their own tests.", "A fix in one area might break something else. Running the full test suite catches regressions immediately.", "Production testing is expensive (time, risk). Never waste time testing in production until automated tests confirm the fix works.", "Tests that pass but don't prevent production failures are worse than no tests - they give false confidence. The test must be improved to catch what production caught.", "Tests serve as documentation. Future developers should understand what bug was fixed by reading the test."], "examples": [{"do": {"description": "Follow RED-GREEN-PRODUCTION workflow", "content": ["# Bug: MCP tool returns 'Bot not initialized' error", "", "# Step 1: RED - Write/modify test to reproduce bug", "def test_mcp_tool_initializes_bot_before_invocation(self, workspace_root):", "    \"\"\"", "    SCENARIO: MCP tool initializes bot before invocation", "    GIVEN: MCP server is started", "    WHEN: Tool is invoked", "    THEN: Bot is initialized and tool executes successfully", "    \"\"\"", "    # Given: MCP server setup", "    from agile_bot.bots.base_bot.src.mcp.server import MCPServer", "    server = MCPServer(workspace_root=workspace_root)", "    ", "    # When: Invoke tool", "    result = server.invoke_tool('test_bot_shape_gather_context', {})", "    ", "    # Then: Bot initialized and tool executed", "    assert result.status == 'completed'", "    assert server.bot is not None", "", "# Step 2: Run test - VERIFY it fails with 'Bot not initialized'", "# pytest output: AttributeError: 'NoneType' object has no attribute 'invoke'", "", "# Step 3: GREEN - Make minimal fix", "# In mcp_server_generator.py:", "#   self.bot = Bot(bot_name=bot_name, workspace_root=workspace_root)", "", "# Step 4: Run test - VERIFY it passes", "", "# Step 5: Run full test suite - verify no regressions", "", "# Step 6: PRODUCTION - Test in real MCP server environment"]}, "dont": {"description": "Fix first, test later", "content": ["# DON'T: Fix bug directly without test", "# Bug: MCP tool returns 'Bot not initialized' error", "", "# WRONG: Directly edit mcp_server_generator.py", "#   self.bot = Bot(...)  # Hope this fixes it", "", "# WRONG: Restart server and test in production", "#   - Restart MCP server", "#   - Test tool invocation", "#   - Still fails? Edit again", "#   - Repeat 3-5 times", "", "# Problems:", "# - Can't prove the fix actually solves the problem", "# - Might fix wrong thing", "# - No way to verify it stays fixed", "# - No automated test to prevent regression"]}}, {"do": {"description": "Verify test fails before fixing", "content": ["# Step 1: Write test", "def test_bot_initializes_correctly(self, workspace_root):", "    bot = Bot(bot_name='test_bot', workspace_root=workspace_root)", "    assert bot.is_initialized", "", "# Step 2: Run test - MUST FAIL", "# pytest output: AssertionError: assert False == True", "# GOOD: Test fails as expected", "", "# Step 3: Now fix the code", "# In bot.py:", "#   def __init__(self, ...):", "#       self._initialized = True  # Fix", "", "# Step 4: Run test - should pass now"]}, "dont": {"description": "Skip verifying test fails", "content": ["# DON'T: Write test and immediately fix", "def test_bot_initializes(self, workspace_root):", "    bot = Bot(bot_name='test_bot', workspace_root=workspace_root)", "    assert bot.is_initialized", "", "# WRONG: Immediately add fix without running test first", "# In bot.py:", "#   self._initialized = True", "", "# WRONG: Run test - passes", "# Deploy to production - still fails!", "# Why? Test was testing wrong thing or bug doesn't exist in test environment", "", "# Problem: Can't tell if fix worked or test was wrong"]}}, {"do": {"description": "Make minimal fix, run full test suite", "content": ["# Bug: Bot not initialized", "", "# Step 1: Test fails (verified)", "", "# Step 2: Make MINIMAL fix", "# In mcp_server_generator.py:", "#   def __init__(self, ...):", "#       # MINIMAL: Only add bot initialization", "#       self.bot = Bot(bot_name=bot_name, workspace_root=workspace_root)", "", "# Step 3: Run the failing test - passes", "", "# Step 4: Run ALL related tests", "#   pytest test_mcp_server.py", "#   pytest test_bot_initialization.py", "#   pytest test_tool_invocation.py", "#   All 30 tests pass - good!", "", "# Step 5: Test in production"]}, "dont": {"description": "Make large changes while fixing bug", "content": ["# DON'T: Mix bug fix with refactoring", "# Bug: Bot not initialized", "", "# WRONG: While fixing, also refactor entire class", "# In mcp_server_generator.py:", "#   def __init__(self, ...):", "#       self.bot = Bot(...)  # Bug fix", "#       # But also:", "#       self._refactor_entire_class()  # WRONG!", "#       self._rename_all_variables()  # WRONG!", "#       self._add_new_features()  # WRONG!", "", "# Problems:", "# - Can't tell which change fixed the bug", "# - Might have introduced new bugs", "# - Mixing concerns makes debugging harder"]}}, {"do": {"description": "Improve test if production still fails", "content": ["# Bug: UTF-8 encoding error in production", "", "# Step 1: Write test", "def test_json_writes_with_utf8_encoding(self, tmp_path):", "    file_path = tmp_path / 'data.json'", "    data = {'text': 'Hello \u4e16\u754c'}", "    write_json(file_path, data)", "    ", "    content = file_path.read_text(encoding='utf-8')", "    assert '\u4e16\u754c' in content", "", "# Step 2: Test passes (but production still fails)", "", "# Step 3: Improve test to catch real issue", "def test_json_writes_with_utf8_encoding(self, tmp_path):", "    file_path = tmp_path / 'data.json'", "    data = {'text': 'Hello \u4e16\u754c'}", "    ", "    # Test actual write operation", "    write_json(file_path, data)", "    ", "    # Verify encoding is correct", "    content = file_path.read_bytes()", "    assert content.decode('utf-8') == json.dumps(data)", "", "# Step 4: Test now fails - good!", "", "# Step 5: Fix encoding in write_json()", "#   file_path.write_text(json.dumps(data), encoding='utf-8')", "", "# Step 6: Test passes, production works"]}, "dont": {"description": "Fix code without improving test", "content": ["# DON'T: Fix code when test passes but production fails", "# Bug: UTF-8 encoding error in production", "", "# WRONG: Test passes but doesn't catch encoding issue", "def test_json_writes(self, tmp_path):", "    file_path = tmp_path / 'data.json'", "    write_json(file_path, {'text': 'Hello'})", "    assert file_path.exists()  # Too simple!", "", "# WRONG: Fix encoding in code", "#   file_path.write_text(json.dumps(data), encoding='utf-8')", "", "# WRONG: Test still passes (wasn't checking encoding)", "# Deploy - production still fails!", "", "# Problem: Test doesn't catch what production caught"]}}, {"do": {"description": "Document bug in test name and scenario", "content": ["# GOOD: Test name documents the bug", "def test_server_initializes_bot_instance_to_prevent_not_initialized_error(self, workspace_root):", "    \"\"\"", "    SCENARIO: Server initializes bot instance to prevent 'not initialized' error", "    GIVEN: MCP server is created", "    WHEN: Server starts", "    THEN: Bot instance is initialized", "    AND: Tool invocations don't fail with 'Bot not initialized' error", "    \"\"\"", "    # Test implementation...", "", "# GOOD: Future developers understand:", "# - What bug was fixed (not initialized error)", "# - How it was fixed (bot initialization)", "# - Why it matters (prevents tool invocation failures)"]}, "dont": {"description": "Use generic test names", "content": ["# DON'T: Generic test name", "def test_server_works(self, workspace_root):", "    \"\"\"", "    SCENARIO: Server works", "    \"\"\"", "    # Test implementation...", "", "# BAD: Future developers can't tell:", "# - What bug was this fixing?", "# - What does 'works' mean?", "# - Why does this test exist?"]}}], "key_principles": ["WHEN production code breaks, ALWAYS write or modify a test to reproduce the bug FIRST", "ALWAYS run the test BEFORE fixing to confirm it fails for the RIGHT reason", "Make the MINIMAL change to fix the bug - just enough to make the test pass", "Run ALL related tests after the fix to ensure no regression", "ONLY AFTER tests pass, test the fix in production/real environment", "If fix works in tests but fails in production, the test is INCOMPLETE - return to step 1", "Document the bug and fix in the test name and test scenario", "RED: Write/modify test to reproduce bug (test fails)", "GREEN: Make minimal fix to pass the test", "PRODUCTION: Test in real environment only after automated tests pass"], "antipatterns": ["Fix first, test later - Can't prove the fix actually solves the problem. Might fix wrong thing. No way to verify it stays fixed.", "Skip verifying test fails before fixing - Test might be wrong or testing the wrong thing. You'll make unnecessary changes or miss the real bug.", "Test only in production - Wastes time (restart servers, wait for changes). Risky (might break production). No automation (will break again).", "Make large changes while fixing bug - Can't tell if the bug fix worked or if new code introduced new bugs. Mixing refactoring with bug fixes leads to confusion.", "Fix code without improving test when production still fails - Tests that pass but don't prevent production failures are worse than no tests - they give false confidence.", "Use generic test names - Future developers can't understand what bug was fixed by reading the test"], "workflow": ["1. RED: Write/modify test to reproduce bug (test fails)", "2. Verify test fails for the right reason", "3. GREEN: Make minimal fix to pass the test", "4. Verify test now passes", "5. Run full test suite (verify no regression)", "6. PRODUCTION: Test in real environment (MCP server, actual usage)", "7. If production still fails: repeat from step 1 with better test"], "checklist": ["[ ] Written or modified test to reproduce the bug", "[ ] Run test - VERIFIED it fails", "[ ] Confirmed test fails for the RIGHT REASON (not a test bug)", "[ ] Made MINIMAL fix to address the bug", "[ ] Run test - VERIFIED it now passes", "[ ] Run FULL test suite - VERIFIED no regressions", "[ ] Test in production/real environment", "[ ] If production still fails, repeat from step 1 with better test"], "real_world_example": {"bug": "MCP tool returns 'Bot not initialized' error in production", "workflow_followed": ["1. RED: Saw existing test test_bot_tool_invocation.py exists but uses mocks", "2. RED: Modified test to use real MCPServerGenerator", "3. RED: Ran test - FAILED with 'Bot not initialized' (good!)", "4. GREEN: Added self.bot = Bot(...) to mcp_server_generator.py", "5. GREEN: Ran test - PASSED", "6. Run all 30 tests - ALL PASSED", "7. PRODUCTION: Restarted MCP server, tested - SUCCESS", "8. Found UTF-8 encoding bug in production", "9. RED: Test helper writes JSON without encoding", "10. GREEN: Added encoding='utf-8' to all JSON writes", "11. Run all tests - PASSED", "12. PRODUCTION: Restarted MCP server, tested - SUCCESS"], "outcome": "Bug fixed correctly, with automated tests preventing regression, and caught additional bug (UTF-8) through the process"}}}, {"rule_file": "business_readable_test_names.json", "rule_content": {"description": "Test names must read like plain English business language. Use domain language stakeholders understand, not technical jargon. Test names should read naturally when spoken aloud. Describe WHAT happens (behavior), not HOW it works (implementation). Combines BDD Rule 1 (Business Readable Language) with pytest orchestrator pattern.", "examples": [{"do": {"description": "Business-readable test names with domain language", "content": ["def test_agent_loads_configuration_when_file_exists(self, workspace_root):", "    \"\"\"", "    Agent loads configuration when file exists.", "    ", "    Business stakeholders can understand:", "    - 'agent' is domain concept", "    - 'loads configuration' is business behavior", "    - 'when file exists' is business condition", "    \"\"\"", "    # Given: Configuration file exists", "    config_file = create_config_file(workspace_root, 'story_bot')", "    ", "    # When: Agent loads configuration", "    agent = Agent('story_bot', workspace_root)", "    agent.load_config(config_file)", "    ", "    # Then: Configuration is loaded", "    assert agent.is_configured", "", "def test_character_has_initial_stats_when_created(self):", "    \"\"\"Character has initial stats when created.\"\"\"", "    # Reads naturally: 'character has initial stats when created'", "", "def test_validation_rejects_config_when_required_fields_missing(self):", "    \"\"\"Validation rejects configuration when required fields missing.\"\"\"", "    # Business-readable: what happens when condition occurs"]}, "dont": {"description": "Technical jargon or implementation-focused names", "content": ["# DON'T: Technical jargon", "def test_agent_constructor_calls_load_method(self):", "    # WRONG: 'constructor calls method' is implementation detail", "", "def test_char_init_sets_vars(self):", "    # WRONG: Abbreviated, technical ('init', 'vars')", "", "def test_validates_json_schema(self):", "    # WRONG: Too technical ('JSON schema')", "    # Better: test_validation_accepts_valid_configuration", "", "def test_config_loader_execute(self):", "    # WRONG: Technical class/method names", "    # Better: test_agent_loads_configuration_from_file", "", "def test_parse_and_store(self):", "    # WRONG: Implementation verbs ('parse', 'store')", "    # Better: test_agent_saves_configuration_data", "", "def test_setup(self):", "    # WRONG: Vague, no context", "    # Better: test_agent_initializes_with_default_settings"]}}, {"do": {"description": "Use 'when' for conditions in test names", "content": ["def test_agent_raises_error_when_config_missing(self):", "    \"\"\"Agent raises error when configuration file missing.\"\"\"", "    # 'when' makes condition clear", "", "def test_character_applies_bonus_when_strength_above_threshold(self):", "    \"\"\"Character applies bonus when strength above threshold.\"\"\"", "    # Business condition is explicit", "", "def test_validation_succeeds_when_all_fields_present(self):", "    \"\"\"Validation succeeds when all required fields present.\"\"\"", "    # Clear condition and outcome"]}, "dont": {"description": "Vague or missing conditions", "content": ["def test_agent_error(self):", "    # WRONG: When does error occur? What kind?", "    # Better: test_agent_raises_error_when_config_missing", "", "def test_character_bonus(self):", "    # WRONG: When is bonus applied? What condition?", "    # Better: test_character_applies_bonus_when_strength_high", "", "def test_validation(self):", "    # WRONG: Validates what? Under what condition?", "    # Better: test_validation_succeeds_when_all_fields_present"]}}]}}, {"rule_file": "call_production_code_directly.json", "rule_content": {"description": "Call production code directly - tests drive production code creation through RED-GREEN-REFACTOR. Let tests fail naturally if code doesn't exist. Don't comment out calls, mock business logic, or fake state. Only mock external boundaries (file I/O, network, APIs) when necessary. Separate business logic from side effects.", "examples": [{"do": {"description": "Call production code directly, let it fail naturally", "content": ["def test_agent_initializes_with_config(self, workspace_root):", "    # Given", "    config = {'name': 'story_bot'}", "    ", "    # When - Call production code directly", "    agent = Agent(agent_name='story_bot', workspace_root=workspace_root)", "    agent.initialize(config)", "    ", "    # Then", "    assert agent.is_initialized", "    # If initialize() doesn't exist, test fails with clear AttributeError"]}, "dont": {"description": "Comment out, mock business logic, or fake state", "content": ["def test_agent_initializes(self):", "    # DON'T: Comment out production code", "    # agent.initialize()  # WRONG - test should fail!", "    ", "    # DON'T: Mock the class you're testing", "    agent = Mock(spec=Agent)  # WRONG - defeats purpose of test", "    ", "    # DON'T: Fake internal state", "    agent._initialized = True  # WRONG - bypasses logic", "    ", "    # DON'T: Mock business logic", "    with patch('agent.validate_config'):  # WRONG - test the logic!", "        pass"]}}, {"do": {"description": "Only mock external boundaries when necessary", "content": ["def test_agent_loads_config_from_file(self, tmp_path):", "    # Use real file I/O with temp directory", "    config_file = tmp_path / 'config.json'", "    config_file.write_text('{\"name\": \"story_bot\"}')", "    ", "    agent = Agent.from_config_file(config_file)", "    assert agent.name == 'story_bot'", "", "# Only mock when external boundary unavailable:", "def test_agent_fetches_remote_config(self):", "    with patch('requests.get') as mock_get:", "        mock_get.return_value.json.return_value = {'name': 'bot'}", "        agent = Agent.from_remote_config('http://api.com/config')", "        assert agent.name == 'bot'"]}, "dont": {"description": "Mock file I/O when you can use real temp files", "content": ["# DON'T: Mock file operations when temp files work", "def test_agent_loads_config(self):", "    with patch('pathlib.Path.read_text') as mock_read:", "        mock_read.return_value = '{\"name\": \"bot\"}'", "        # WRONG - use real temp file instead!"]}}]}}, {"rule_file": "consistent_vocabulary.json", "rule_content": {"description": "Use ONE word per concept across entire test suite. Pick consistent vocabulary for common operations: create (not build/make/construct), verify (not check/assert/validate), load (not fetch/get/retrieve). Inconsistent vocabulary confuses readers and makes codebase harder to navigate. From Clean Code Rule 2.2 and BDD Rule 1.", "examples": [{"do": {"description": "Consistent vocabulary across all helpers", "content": ["# Choose 'create_*' and use EVERYWHERE", "def create_agent(name: str, workspace: Path) -> Agent:", "    \"\"\"Helper: Create agent instance.\"\"\"", "    return Agent(name=name, workspace_root=workspace)", "", "def create_config_file(workspace: Path, agent_name: str) -> Path:", "    \"\"\"Helper: Create configuration file.\"\"\"", "    config_path = workspace / 'config.json'", "    config_path.write_text(f'{{\"name\": \"{agent_name}\"}}')", "    return config_path", "", "def create_workspace_with_structure(tmp_path: Path) -> Path:", "    \"\"\"Helper: Create workspace with directory structure.\"\"\"", "    workspace = tmp_path / 'workspace'", "    workspace.mkdir()", "    (workspace / 'agents').mkdir()", "    return workspace", "", "# Choose 'verify_*' and use EVERYWHERE", "def verify_agent_initialized(agent: Agent):", "    \"\"\"Helper: Verify agent is initialized.\"\"\"", "    assert agent.is_initialized", "    assert agent.config_path is not None", "", "def verify_config_valid(config: dict):", "    \"\"\"Helper: Verify configuration is valid.\"\"\"", "    assert 'name' in config", "    assert 'workspace_root' in config", "", "def verify_file_exists(path: Path):", "    \"\"\"Helper: Verify file exists at path.\"\"\"", "    assert path.exists()", "    assert path.is_file()"]}, "dont": {"description": "Mixed vocabulary for same concept", "content": ["# DON'T: Mix create/build/make/construct", "def create_agent(...): ...", "def build_config(...):  # WRONG - use create_config", "def make_workspace(...):  # WRONG - use create_workspace", "def construct_domain_graph(...):  # WRONG - use create_domain_graph", "", "# DON'T: Mix verify/check/assert/validate randomly", "def verify_agent_initialized(...): ...", "def check_config_valid(...):  # WRONG - use verify_config_valid", "def assert_file_exists(...):  # WRONG - use verify_file_exists", "def validate_workspace(...):  # WRONG - use verify_workspace_valid", "", "# DON'T: Mix load/fetch/get/retrieve", "def load_config_from_file(...): ...", "def fetch_domain_graph(...):  # WRONG - use load_domain_graph", "def get_workspace_data(...):  # WRONG - use load_workspace_data", "def retrieve_agent_state(...):  # WRONG - use load_agent_state"]}}, {"do": {"description": "Document vocabulary choices in test file docstring", "content": ["\"\"\"", "Agent Configuration Tests", "", "Vocabulary conventions:", "- create_* : Create test objects/files", "- verify_* : Assert expected conditions", "- load_*   : Load data from files", "- setup_*  : Arrange test preconditions", "", "Example:", "    workspace = create_workspace(tmp_path)", "    config = load_config(workspace)", "    agent = setup_agent_with_config(config)", "    verify_agent_initialized(agent)", "\"\"\"", "import pytest", "from pathlib import Path", "", "# All helpers follow documented vocabulary", "def create_workspace(tmp_path): ...", "def load_config(workspace): ...", "def setup_agent_with_config(config): ...", "def verify_agent_initialized(agent): ..."]}, "dont": {"description": "No vocabulary documentation or consistency", "content": ["# DON'T: No vocabulary conventions documented", "\"\"\"Agent Configuration Tests\"\"\"", "", "# Functions use random different verbs", "def build_workspace(tmp_path): ...", "def fetch_config(workspace): ...", "def initialize_agent(config): ...", "def check_agent(agent): ...", "# Reader must guess which verb to use!"]}}, {"do": {"description": "Standard vocabulary recommendations", "content": ["# Recommended vocabulary choices:", "", "# CREATION: create_*", "create_agent(), create_config(), create_workspace()", "", "# VERIFICATION: verify_*", "verify_initialized(), verify_valid(), verify_exists()", "", "# LOADING: load_*", "load_config(), load_graph(), load_data()", "", "# SETUP: setup_* (for complex arrangements)", "setup_test_environment(), setup_agent_with_dependencies()", "", "# CLEANUP: cleanup_* (when needed)", "cleanup_temp_files(), cleanup_test_data()", "", "# These choices are clear, unambiguous, and parallel"]}, "dont": {"description": "Avoid these vocabulary anti-patterns", "content": ["# DON'T: Mix synonyms", "create_agent(), build_config(), make_workspace(), construct_graph()", "# Pick ONE: create_* for all", "", "# DON'T: Use vague generic verbs", "do_agent(), handle_config(), process_data()", "# Use specific verbs: create_agent(), load_config(), parse_data()", "", "# DON'T: Use technical acronyms inconsistently", "init_agent(), initialize_config(), setup_workspace()", "# Pick ONE: setup_* for all OR initialize_* for all"]}}]}}, {"rule_file": "cover_all_behavior_paths.json", "rule_content": {"description": "Cover all behavior paths: normal (happy path), edge cases, and failure scenarios. Each distinct behavior needs its own focused test. Tests must be independent and can run in any order. From BDD Rule 3 (Comprehensive and Brief Coverage).", "examples": [{"do": {"description": "Test normal, edge, and failure paths", "content": ["class TestAgentConfigurationLoading:", "    \"\"\"Agent configuration loading behavior.\"\"\"", "    ", "    # NORMAL PATH: Happy path scenario", "    def test_loads_valid_configuration_from_file(self, tmp_path):", "        \"\"\"Agent loads valid configuration from file.\"\"\"", "        # Given: Valid config file exists", "        config_file = tmp_path / 'config.json'", "        config_file.write_text('{\"name\": \"story_bot\", \"version\": \"1.0\"}')", "        ", "        # When: Agent loads config", "        agent = Agent()", "        config = agent.load_config(config_file)", "        ", "        # Then: Config loaded successfully", "        assert config['name'] == 'story_bot'", "        assert config['version'] == '1.0'", "    ", "    # EDGE CASE: Empty but valid configuration", "    def test_loads_empty_configuration_file(self, tmp_path):", "        \"\"\"Agent loads empty configuration file.\"\"\"", "        # Given: Empty but valid JSON", "        config_file = tmp_path / 'config.json'", "        config_file.write_text('{}')", "        ", "        # When: Agent loads empty config", "        agent = Agent()", "        config = agent.load_config(config_file)", "        ", "        # Then: Returns empty dict", "        assert config == {}", "    ", "    # EDGE CASE: Very large configuration", "    def test_loads_large_configuration_file(self, tmp_path):", "        \"\"\"Agent loads large configuration with many fields.\"\"\"", "        # Given: Config with 100+ fields", "        large_config = {f'field_{i}': f'value_{i}' for i in range(100)}", "        config_file = tmp_path / 'config.json'", "        config_file.write_text(json.dumps(large_config))", "        ", "        # When: Agent loads large config", "        agent = Agent()", "        config = agent.load_config(config_file)", "        ", "        # Then: All fields loaded", "        assert len(config) == 100", "        assert config['field_0'] == 'value_0'", "    ", "    # FAILURE PATH: File doesn't exist", "    def test_raises_error_when_config_file_missing(self):", "        \"\"\"Agent raises FileNotFoundError when config file missing.\"\"\"", "        # Given: Config file doesn't exist", "        missing_file = Path('nonexistent/config.json')", "        ", "        # When/Then: Loading raises FileNotFoundError", "        agent = Agent()", "        with pytest.raises(FileNotFoundError, match='config.json'):", "            agent.load_config(missing_file)", "    ", "    # FAILURE PATH: Invalid JSON", "    def test_raises_error_when_config_file_invalid_json(self, tmp_path):", "        \"\"\"Agent raises ValueError when config contains invalid JSON.\"\"\"", "        # Given: File with invalid JSON", "        config_file = tmp_path / 'config.json'", "        config_file.write_text('not valid json {')", "        ", "        # When/Then: Loading raises ValueError", "        agent = Agent()", "        with pytest.raises(ValueError, match='Invalid JSON'):", "            agent.load_config(config_file)", "    ", "    # FAILURE PATH: File exists but empty", "    def test_raises_error_when_config_file_empty(self, tmp_path):", "        \"\"\"Agent raises ValueError when config file is empty.\"\"\"", "        # Given: Empty file (not even empty JSON)", "        config_file = tmp_path / 'config.json'", "        config_file.write_text('')", "        ", "        # When/Then: Loading raises ValueError", "        agent = Agent()", "        with pytest.raises(ValueError, match='Empty configuration'):", "            agent.load_config(config_file)"]}, "dont": {"description": "Only test happy path or mix multiple paths in one test", "content": ["# DON'T: Only test happy path", "def test_loads_config(self, tmp_path):", "    config_file = tmp_path / 'config.json'", "    config_file.write_text('{\"name\": \"bot\"}')", "    agent = Agent()", "    config = agent.load_config(config_file)", "    assert config['name'] == 'bot'", "    # WRONG: What about missing file? Invalid JSON? Empty file?", "", "# DON'T: Mix multiple paths in one test", "def test_config_loading_all_scenarios(self, tmp_path):", "    # Test 1: Valid config", "    config_file = tmp_path / 'config.json'", "    config_file.write_text('{\"name\": \"bot\"}')", "    config = agent.load_config(config_file)", "    assert config['name'] == 'bot'", "    ", "    # Test 2: Missing file", "    with pytest.raises(FileNotFoundError):", "        agent.load_config(Path('missing.json'))", "    ", "    # Test 3: Invalid JSON", "    bad_file = tmp_path / 'bad.json'", "    bad_file.write_text('bad json')", "    with pytest.raises(ValueError):", "        agent.load_config(bad_file)", "    # WRONG: Multiple scenarios in one test!", "    # If first fails, others don't run!", "    # Hard to understand which scenario failed!"]}}, {"do": {"description": "Independent tests that can run in any order", "content": ["class TestCharacterCreation:", "    \"\"\"Each test is completely independent.\"\"\"", "    ", "    def test_character_has_default_stats_when_created(self):", "        \"\"\"Character has default stats when created.\"\"\"", "        # Own setup", "        character = Character(name='Hero')", "        ", "        # Own assertions", "        assert character.strength == 10", "        assert character.health == 100", "    ", "    def test_character_accepts_custom_stats_when_provided(self):", "        \"\"\"Character accepts custom stats when provided.\"\"\"", "        # Own setup (doesn't depend on previous test)", "        character = Character(name='Hero', strength=15, health=120)", "        ", "        # Own assertions", "        assert character.strength == 15", "        assert character.health == 120", "    ", "    def test_character_validates_stat_ranges_when_created(self):", "        \"\"\"Character validates stat ranges when created.\"\"\"", "        # Own setup (independent)", "        with pytest.raises(ValueError, match='Strength must be 1-20'):", "            Character(name='Hero', strength=25)", "    ", "    # These tests can run in ANY ORDER", "    # Each test creates its own Character", "    # No shared state between tests"]}, "dont": {"description": "Tests that depend on execution order", "content": ["class TestCharacterCreation:", "    # DON'T: Tests depend on order", "    ", "    def test_1_create_character(self):", "        self.character = Character('Hero')  # \u274c Shared state", "        assert self.character.name == 'Hero'", "    ", "    def test_2_set_stats(self):", "        # \u274c WRONG: Depends on test_1 running first!", "        self.character.strength = 15", "        assert self.character.strength == 15", "    ", "    def test_3_validate_stats(self):", "        # \u274c WRONG: Depends on test_2 running first!", "        assert self.character.strength == 15", "    ", "    # PROBLEMS:", "    # - Tests must run in specific order (1, 2, 3)", "    # - If test_1 fails, test_2 and test_3 can't run", "    # - Can't run single test in isolation", "    # - Shared state (self.character) causes coupling"]}}]}}, {"rule_file": "define_fixtures_in_test_file.json", "rule_content": {"description": "Define fixtures in the test file, not in separate conftest.py. Use pytest fixtures for shared setup. Truly reusable fixtures (file operations, location helpers) belong in agents/base/src/conftest.py.", "examples": [{"do": {"description": "Fixtures in test file", "content": ["# In test_agent_configuration.py", "import pytest", "", "@pytest.fixture", "def workspace_root(tmp_path):", "    \"\"\"Fixture: Temporary workspace directory.\"\"\"", "    workspace = tmp_path / \"workspace\"", "    workspace.mkdir()", "    return workspace", "", "@pytest.fixture", "def config_file(workspace_root):", "    \"\"\"Fixture: Agent configuration file.\"\"\"", "    config_path = workspace_root / \"agents\" / \"base\" / \"agent.json\"", "    config_path.parent.mkdir(parents=True, exist_ok=True)", "    config_path.write_text('{\"name\": \"story_bot\"}')", "    return config_path", "", "class TestAgentConfiguration:", "    def test_agent_loads_config(self, workspace_root, config_file):", "        \"\"\"Test uses fixtures defined in same file.\"\"\"", "        agent = Agent('story_bot', workspace_root)", "        agent.load_config(config_file)", "        assert agent.is_initialized"]}, "dont": {"description": "Separate conftest.py for agent-specific fixtures", "content": ["# DON'T: Create src/conftest.py for agent-specific fixtures", "# Use test file instead, or agents/base/src/conftest.py for reusable ones"]}}]}}, {"rule_file": "design_api_through_failing_tests.json", "rule_content": {"description": "Write tests against the REAL expected API (not dummy variables or placeholders) BEFORE implementing code. Tests MUST fail initially because the API doesn't exist yet. This failure reveals the complete API design including parameter objects, config setup, dependencies, and return values. Set up real test data (files, directories, objects) and call the real API. Only mock I/O boundaries (file access, network, database) and only when explicitly necessary. The failing test serves as executable API documentation.", "examples": [{"do": {"description": "Write test against real expected API that fails", "content": ["def test_project_initializes_with_agent_config(self, tmp_path):", "    \"\"\"Project initializes by loading agent configuration from file.\"\"\"", "    # Given: Real test workspace with config file", "    project_path = tmp_path / 'projects' / 'test-project'", "    project_path.mkdir(parents=True, exist_ok=True)", "    ", "    agent_config_path = tmp_path / 'agents' / 'base' / 'agent.json'", "    agent_config_path.parent.mkdir(parents=True, exist_ok=True)", "    agent_config_path.write_text(json.dumps({", "        'name': 'story_bot',", "        'behaviors': ['shape', 'discovery']", "    }))", "    ", "    # When: Call REAL expected API (doesn't exist yet!)", "    project = Project(", "        project_path=project_path,", "        agent_config_path=agent_config_path,", "        workspace_root=tmp_path", "    )", "    project.initialize()", "    ", "    # Then: Verify real behavior", "    assert project.agent.name == 'story_bot'", "    assert project.agent.behaviors == ['shape', 'discovery']", "    assert project.is_initialized is True", "    ", "    # TEST FAILS: AttributeError - Project doesn't have 'initialize' method", "    # GOOD! Now we know:", "    # - Project needs __init__ with project_path, agent_config_path, workspace_root", "    # - Project needs initialize() method", "    # - Project needs agent property", "    # - Project needs is_initialized property", "    # - Agent needs name and behaviors attributes"]}, "dont": {"description": "Use dummy variables or placeholders to make test pass", "content": ["def test_project_initializes():", "    # DON'T: Use dummy/placeholder values", "    project = None  # Placeholder - hides real API!", "    agent = None    # Placeholder - hides real API!", "    ", "    # Test passes but reveals NOTHING about real API", "    assert project is None  # USELESS!", "    assert agent is None    # USELESS!", "    ", "    # WRONG: This doesn't show:", "    # - What parameters Project needs", "    # - What methods Project should have", "    # - What the Agent structure looks like", "    # - How initialization works"]}}, {"do": {"description": "Set up real test data, call real API, let it fail", "content": ["def test_workflow_executes_behavior_sequence(self, tmp_path):", "    \"\"\"Workflow executes behaviors in configured sequence.\"\"\"", "    # Given: Real agent with real config", "    agent_path = tmp_path / 'agents' / 'story_bot'", "    agent_path.mkdir(parents=True, exist_ok=True)", "    ", "    config = {", "        'name': 'story_bot',", "        'behaviors': [", "            {'name': 'shape', 'order': 1},", "            {'name': 'discovery', 'order': 2}", "        ]", "    }", "    (agent_path / 'agent.json').write_text(json.dumps(config))", "    ", "    # When: Create real objects and call real API", "    agent = Agent.load_from_path(agent_path)", "    workflow = Workflow(agent=agent, workspace=tmp_path)", "    result = workflow.execute_next_behavior()", "    ", "    # Then: Verify real behavior", "    assert result.behavior_name == 'shape'", "    assert result.status == 'completed'", "    assert workflow.current_behavior_index == 1", "    ", "    # TEST FAILS: AttributeError - Agent.load_from_path doesn't exist", "    # GOOD! Failure shows exact API needed:", "    # - Agent.load_from_path(path) class method", "    # - Workflow.__init__(agent, workspace) constructor", "    # - Workflow.execute_next_behavior() method returns result object", "    # - Result object with behavior_name, status properties", "    # - Workflow.current_behavior_index property"]}, "dont": {"description": "Mock everything or use fake objects", "content": ["def test_workflow_executes():", "    # DON'T: Mock internal objects that should be real", "    mock_agent = Mock()", "    mock_agent.name = 'story_bot'", "    ", "    mock_workflow = Mock()", "    mock_workflow.execute_next_behavior.return_value = Mock(status='completed')", "    ", "    # Test passes but reveals NOTHING", "    result = mock_workflow.execute_next_behavior()", "    assert result.status == 'completed'", "    ", "    # WRONG: Doesn't show:", "    # - How Agent is constructed", "    # - How Workflow is constructed", "    # - What parameters they need", "    # - What the real implementation does"]}}, {"do": {"description": "Mock only I/O boundaries when explicitly necessary", "content": ["def test_agent_fetches_remote_template(self, tmp_path):", "    \"\"\"Agent fetches template from remote URL.\"\"\"", "    # Given: Real agent setup", "    agent_path = tmp_path / 'agents' / 'story_bot'", "    agent_path.mkdir(parents=True, exist_ok=True)", "    ", "    # Mock ONLY the network I/O boundary (can't control external API)", "    with patch('requests.get') as mock_get:", "        mock_get.return_value.text = '# Template content'", "        mock_get.return_value.status_code = 200", "        ", "        # When: Call REAL Agent API", "        agent = Agent(name='story_bot', workspace=agent_path)", "        template = agent.fetch_remote_template(", "            url='https://example.com/template.md',", "            cache_path=agent_path / 'templates'", "        )", "        ", "        # Then: Verify real behavior", "        assert template.content == '# Template content'", "        assert (agent_path / 'templates' / 'template.md').exists()", "        mock_get.assert_called_once_with('https://example.com/template.md')", "    ", "    # TEST FAILS: Agent.fetch_remote_template doesn't exist", "    # GOOD! Shows API needs:", "    # - Agent.__init__(name, workspace)", "    # - Agent.fetch_remote_template(url, cache_path) method", "    # - Returns template object with content property", "    # - Caches to local file", "    # Only network call is mocked - everything else is real!"]}, "dont": {"description": "Mock file operations that can use real temp files", "content": ["def test_agent_caches_template():", "    # DON'T: Mock file operations", "    with patch('pathlib.Path.exists') as mock_exists:", "        with patch('pathlib.Path.mkdir') as mock_mkdir:", "            with patch('pathlib.Path.write_text') as mock_write:", "                mock_exists.return_value = False", "                ", "                agent = Agent('story_bot', Path('/fake'))", "                agent.cache_template('content', 'template.md')", "                ", "                mock_mkdir.assert_called_once()", "                mock_write.assert_called_once()", "    ", "    # WRONG: Use real tmp_path and real file operations!", "    # File I/O is controllable and testable without mocking"]}}, {"do": {"description": "Design complex APIs through failing tests with real objects", "content": ["def test_behavior_runner_executes_multi_step_workflow(self, tmp_path):", "    \"\"\"BehaviorRunner executes multi-step workflow with state tracking.\"\"\"", "    # Given: Real test workspace with config", "    workspace = tmp_path / 'test-workspace'", "    workspace.mkdir()", "    ", "    config = WorkflowConfig(", "        steps=[", "            StepConfig(name='gather_context', timeout=30),", "            StepConfig(name='build_knowledge', timeout=60),", "            StepConfig(name='render_output', timeout=45)", "        ],", "        workspace_path=workspace", "    )", "    ", "    state = WorkflowState(", "        current_step=0,", "        completed_steps=[],", "        workspace=workspace", "    )", "    ", "    # When: Execute real workflow", "    runner = BehaviorRunner(config=config, initial_state=state)", "    result = runner.execute_all_steps()", "    ", "    # Then: Verify state tracking", "    assert result.total_steps == 3", "    assert result.completed_steps == ['gather_context', 'build_knowledge', 'render_output']", "    assert result.final_state.current_step == 3", "    assert (workspace / 'workflow_state.json').exists()", "    ", "    # TEST FAILS: Multiple failures reveal complete API:", "    # - WorkflowConfig class with steps list and workspace_path", "    # - StepConfig class with name and timeout", "    # - WorkflowState class with current_step, completed_steps, workspace", "    # - BehaviorRunner.__init__(config, initial_state)", "    # - BehaviorRunner.execute_all_steps() returns result", "    # - Result object with total_steps, completed_steps, final_state", "    # - State persisted to workflow_state.json", "    # Complete API design visible through test!"]}, "dont": {"description": "Build up API incrementally with dummy values", "content": ["def test_behavior_runner():", "    # DON'T: Start with dummies and build up slowly", "    runner = None  # Placeholder", "    assert runner is None", "    ", "    # Later...", "    runner = BehaviorRunner()  # Empty constructor", "    assert runner is not None", "    ", "    # Later...", "    result = runner.execute()  # Simplified, not real API", "    assert result == 'done'", "    ", "    # WRONG: Should design complete API upfront through test:", "    # - What parameters does runner need?", "    # - What configuration?", "    # - What state tracking?", "    # - What does result look like?", "    # Write test with COMPLETE expected API!"]}}], "rationale": ["Failing tests against real API reveal complete design including parameters, config, dependencies, and return types", "Test serves as executable documentation of expected API before implementation exists", "Real test data (files, objects) shows how production code will actually be used", "Avoiding mocks for internal objects ensures API is testable and well-designed", "Seeing the test fail validates that test is testing something real, not dummy values", "Forces thinking about API usability and design before writing implementation", "Real setup code shows what dependencies and configuration production code needs", "Parameter objects and config structures become visible through test construction"], "key_principles": ["Write tests against REAL expected API (not dummy/placeholder values)", "Tests MUST fail initially - this validates the test and reveals the API", "Set up real test data using tmp_path (files, directories, config)", "Call real constructors and methods with real parameters", "Only mock I/O boundaries (network, external APIs) when explicitly necessary", "Never mock file operations - use real temp files", "Never mock internal objects - use real implementations", "Test should show complete API: parameters, config, dependencies, return types", "Failing test is executable API documentation", "Design is revealed through test structure, not implementation"], "antipatterns": ["Using None or placeholder values instead of real API calls", "Making tests pass with dummy assertions like 'assert x is None'", "Mocking file operations when tmp_path provides real files", "Mocking internal objects that should be real implementations", "Building up API incrementally with partial/incomplete tests", "Writing tests that pass without real implementation (false positives)", "Hiding API design by not showing real parameters and config", "Using simplified APIs in tests that don't match real usage"]}}, {"rule_file": "helpers_inline_not_shared.json", "rule_content": {"rule_id": "helpers_inline_not_shared", "description": "Helper functions must be inline in test file, not in separate shared helper file", "rationale": "Helpers should be as local as possible to the tests using them. Keep helpers in the same test file unless they are truly reusable across multiple sub-epics (in which case they go in conftest.py).", "examples": [{"correct": "# test_gather_context.py\n\n# HELPER FUNCTIONS\ndef create_activity_log_file(workspace: Path) -> Path:\n    \"\"\"Helper: Create activity log file.\"\"\"\n    ...\n\nclass TestTrackActivityForGatherContextAction:\n    def test_track_activity_when_action_starts(self, workspace_root):\n        log_file = create_activity_log_file(workspace_root)\n        ...", "wrong": "# test_helpers.py (separate file)\ndef create_activity_log_file(workspace: Path) -> Path:\n    ...\n\n# test_gather_context.py\nfrom test_helpers import create_activity_log_file\n\nclass TestTrackActivity:\n    def test_something(self):\n        log_file = create_activity_log_file(...)"}], "validation": {"check": "No imports from test_helpers.py or separate helper modules", "error_message": "Helpers must be inline in test file, not imported from separate test_helpers.py"}}}, {"rule_file": "helper_extraction_and_reuse.json", "rule_content": {"description": "Extract duplicate test setup to reusable helper functions and factory functions. Keep test bodies focused on specific behavior being tested. Balance shared context with test-specific setup. Avoid duplication through helper extraction. From BDD Rules 8.3 (Helper Extraction) and 4 (Balance Context Sharing with Localization).", "examples": [{"do": {"description": "Extract duplicate setup to reusable helpers", "content": ["# ============================================================================", "# HELPER FUNCTIONS - Reusable across multiple tests", "# ============================================================================", "", "def create_agent_with_config(name: str, workspace: Path, config: dict) -> Agent:", "    \"\"\"Helper: Create agent with configuration.\"\"\"", "    agent = Agent(agent_name=name, workspace_root=workspace)", "    agent.set_config(config)", "    agent.initialize()", "    return agent", "", "def create_config_file(workspace: Path, agent_name: str) -> Path:", "    \"\"\"Helper: Create configuration file with agent name.\"\"\"", "    config_dir = workspace / 'agents' / 'base'", "    config_dir.mkdir(parents=True, exist_ok=True)", "    config_file = config_dir / 'agent.json'", "    config_file.write_text(json.dumps({'name': agent_name}))", "    return config_file", "", "def create_workspace_with_structure(tmp_path: Path) -> Path:", "    \"\"\"Helper: Create workspace with standard directory structure.\"\"\"", "    workspace = tmp_path / 'workspace'", "    workspace.mkdir()", "    (workspace / 'agents').mkdir()", "    (workspace / 'agents' / 'base').mkdir()", "    (workspace / 'data').mkdir()", "    return workspace", "", "def verify_agent_initialized(agent: Agent, expected_name: str):", "    \"\"\"Helper: Verify agent is fully initialized.\"\"\"", "    assert agent.is_initialized", "    assert agent.name == expected_name", "    assert agent.config_path is not None", "", "# ============================================================================", "# TESTS - Reuse helpers, stay focused on behavior", "# ============================================================================", "", "class TestAgentInitialization:", "    def test_agent_initializes_with_base_config(self, tmp_path):", "        \"\"\"Agent initializes with base configuration.\"\"\"", "        # Given - Use helper for setup", "        workspace = create_workspace_with_structure(tmp_path)", "        config_file = create_config_file(workspace, 'story_bot')", "        ", "        # When - Focus on behavior being tested", "        agent = create_agent_with_config('story_bot', workspace, {'name': 'story_bot'})", "        ", "        # Then - Use helper for verification", "        verify_agent_initialized(agent, 'story_bot')", "    ", "    def test_agent_loads_custom_config(self, tmp_path):", "        \"\"\"Agent loads custom configuration values.\"\"\"", "        # Given - Reuse same helpers", "        workspace = create_workspace_with_structure(tmp_path)", "        custom_config = {'name': 'custom_bot', 'version': '2.0'}", "        ", "        # When - Focus on custom config behavior", "        agent = create_agent_with_config('custom_bot', workspace, custom_config)", "        ", "        # Then - Reuse verification helper", "        verify_agent_initialized(agent, 'custom_bot')", "        assert agent.config['version'] == '2.0'", "    ", "    # Both tests reuse helpers - no duplication!", "    # Test bodies stay focused on specific behavior"]}, "dont": {"description": "Duplicate setup code across tests", "content": ["# DON'T: Duplicate setup in every test", "class TestAgentInitialization:", "    def test_agent_initializes_with_base_config(self, tmp_path):", "        # WRONG: Inline setup - duplicated in every test", "        workspace = tmp_path / 'workspace'", "        workspace.mkdir()", "        agents_dir = workspace / 'agents'", "        agents_dir.mkdir()", "        base_dir = agents_dir / 'base'", "        base_dir.mkdir()", "        config_file = base_dir / 'agent.json'", "        config_file.write_text('{\"name\": \"story_bot\"}')", "        ", "        agent = Agent('story_bot', workspace)", "        agent.initialize()", "        ", "        assert agent.is_initialized", "        assert agent.name == 'story_bot'", "        assert agent.config_path is not None", "    ", "    def test_agent_loads_custom_config(self, tmp_path):", "        # WRONG: Same setup duplicated again!", "        workspace = tmp_path / 'workspace'", "        workspace.mkdir()", "        agents_dir = workspace / 'agents'", "        agents_dir.mkdir()", "        base_dir = agents_dir / 'base'", "        base_dir.mkdir()", "        config_file = base_dir / 'agent.json'", "        config_file.write_text('{\"name\": \"custom_bot\", \"version\": \"2.0\"}')", "        ", "        agent = Agent('custom_bot', workspace)", "        agent.initialize()", "        ", "        assert agent.is_initialized", "        # Tons of duplication! Hard to maintain!", "        # If setup changes, must update all tests!"]}}, {"do": {"description": "Factory functions for test data creation", "content": ["# Factory functions create complex test data", "def build_test_character(name: str = 'Hero', **kwargs) -> Character:", "    \"\"\"Factory: Build character with default or custom attributes.\"\"\"", "    defaults = {", "        'strength': 10,", "        'health': 100,", "        'level': 1", "    }", "    defaults.update(kwargs)", "    return Character(name=name, **defaults)", "", "def build_test_config(overrides: dict = None) -> dict:", "    \"\"\"Factory: Build config with defaults and optional overrides.\"\"\"", "    config = {", "        'name': 'story_bot',", "        'workspace_root': '/tmp/workspace',", "        'version': '1.0'", "    }", "    if overrides:", "        config.update(overrides)", "    return config", "", "# Tests use factories for flexible test data", "def test_character_default_stats(self):", "    character = build_test_character()  # Uses defaults", "    assert character.strength == 10", "", "def test_character_custom_stats(self):", "    character = build_test_character(strength=15, health=120)  # Custom", "    assert character.strength == 15", "", "def test_agent_with_custom_config(self):", "    config = build_test_config({'version': '2.0'})  # Override one field", "    agent = Agent.from_config(config)", "    assert agent.version == '2.0'"]}, "dont": {"description": "Duplicate test data creation", "content": ["# DON'T: Duplicate test data creation", "def test_character_default_stats(self):", "    # WRONG: Manual construction duplicated", "    character = Character(", "        name='Hero',", "        strength=10,", "        health=100,", "        level=1", "    )", "    assert character.strength == 10", "", "def test_character_custom_stats(self):", "    # WRONG: Same manual construction with slight changes", "    character = Character(", "        name='Hero',", "        strength=15,  # Only difference", "        health=120,   # Only difference", "        level=1", "    )", "    # Use factory function instead!"]}}, {"do": {"description": "Use fixtures for shared setup", "content": ["# Fixtures provide shared setup across tests", "@pytest.fixture", "def workspace_root(tmp_path):", "    \"\"\"Fixture: Workspace with standard structure.\"\"\"", "    workspace = tmp_path / 'workspace'", "    workspace.mkdir()", "    (workspace / 'agents').mkdir()", "    (workspace / 'data').mkdir()", "    return workspace", "", "@pytest.fixture", "def base_config(workspace_root):", "    \"\"\"Fixture: Base configuration file.\"\"\"", "    config_path = workspace_root / 'agents' / 'base' / 'agent.json'", "    config_path.parent.mkdir(parents=True, exist_ok=True)", "    config_path.write_text('{\"name\": \"story_bot\"}')", "    return config_path", "", "@pytest.fixture", "def configured_agent(workspace_root, base_config):", "    \"\"\"Fixture: Agent with configuration loaded.\"\"\"", "    agent = Agent('story_bot', workspace_root)", "    agent.load_config(base_config)", "    return agent", "", "# Tests use fixtures - no setup duplication", "class TestAgentOperations:", "    def test_agent_saves_state(self, configured_agent):", "        \"\"\"Agent saves state to disk.\"\"\"", "        configured_agent.save()  # Uses fixture", "        assert configured_agent.state_file.exists()", "    ", "    def test_agent_loads_domain_graph(self, configured_agent, workspace_root):", "        \"\"\"Agent loads domain graph.\"\"\"", "        graph_file = workspace_root / 'domain_graph.json'", "        graph_file.write_text('{\"nodes\": []}')", "        configured_agent.load_graph(graph_file)  # Uses fixture", "        assert configured_agent.has_graph"]}, "dont": {"description": "Repeat fixture setup in every test", "content": ["# DON'T: Repeat setup that could be fixture", "class TestAgentOperations:", "    def test_agent_saves_state(self, tmp_path):", "        # WRONG: Duplicating setup in every test", "        workspace = tmp_path / 'workspace'", "        workspace.mkdir()", "        config_path = workspace / 'config.json'", "        config_path.write_text('{\"name\": \"bot\"}')", "        agent = Agent('bot', workspace)", "        agent.load_config(config_path)", "        # Use fixture instead!", "        ", "        agent.save()", "        assert agent.state_file.exists()", "    ", "    def test_agent_loads_graph(self, tmp_path):", "        # WRONG: Same setup repeated again!", "        workspace = tmp_path / 'workspace'", "        workspace.mkdir()", "        config_path = workspace / 'config.json'", "        config_path.write_text('{\"name\": \"bot\"}')", "        agent = Agent('bot', workspace)", "        agent.load_config(config_path)", "        # Create fixture for this common setup!"]}}, {"do": {"description": "Balance shared context with test-specific setup", "content": ["# Shared context via fixture", "@pytest.fixture", "def base_agent(workspace_root):", "    \"\"\"Fixture: Basic agent for all tests.\"\"\"", "    return Agent('story_bot', workspace_root)", "", "# Tests add test-specific setup", "class TestAgentConfiguration:", "    def test_agent_loads_json_config(self, base_agent, tmp_path):", "        \"\"\"Agent loads JSON configuration.\"\"\"", "        # Shared: base_agent fixture", "        # Test-specific: JSON config file", "        config_file = tmp_path / 'config.json'", "        config_file.write_text('{\"format\": \"json\"}')", "        ", "        base_agent.load_config(config_file)", "        assert base_agent.config['format'] == 'json'", "    ", "    def test_agent_loads_yaml_config(self, base_agent, tmp_path):", "        \"\"\"Agent loads YAML configuration.\"\"\"", "        # Shared: base_agent fixture", "        # Test-specific: YAML config file", "        config_file = tmp_path / 'config.yaml'", "        config_file.write_text('format: yaml')", "        ", "        base_agent.load_config(config_file)", "        assert base_agent.config['format'] == 'yaml'", "    ", "    # Balanced: Shared agent, test-specific config"]}, "dont": {"description": "Force all setup into fixture or repeat everything", "content": ["# DON'T: Force everything into shared fixture", "@pytest.fixture", "def agent_with_json_config(workspace_root, tmp_path):", "    # WRONG: Too specific for shared fixture", "    agent = Agent('story_bot', workspace_root)", "    config_file = tmp_path / 'config.json'", "    config_file.write_text('{\"format\": \"json\"}')", "    agent.load_config(config_file)", "    return agent", "", "# This fixture is too specific - can't reuse for YAML test!", "# Need separate fixture for each config type - wrong!", "", "# DON'T: Repeat shared setup in each test", "def test_loads_json_config(self, tmp_path):", "    # WRONG: Repeating agent creation", "    workspace = create_workspace(tmp_path)", "    agent = Agent('story_bot', workspace)  # Repeated", "    agent.initialize()  # Repeated", "    ", "    config_file = tmp_path / 'config.json'", "    config_file.write_text('{\"format\": \"json\"}')", "    # Agent creation should be in fixture!"]}}, {"do": {"description": "Group related helpers by purpose", "content": ["# ============================================================================", "# CREATION HELPERS - Build test objects", "# ============================================================================", "", "def create_agent(...): ...", "def create_config_file(...): ...", "def create_workspace(...): ...", "", "# ============================================================================", "# VERIFICATION HELPERS - Assert expected state", "# ============================================================================", "", "def verify_agent_initialized(...): ...", "def verify_config_valid(...): ...", "def verify_file_exists(...): ...", "", "# ============================================================================", "# DATA FACTORIES - Build test data", "# ============================================================================", "", "def build_test_character(...): ...", "def build_test_config(...): ...", "def build_test_domain_graph(...): ...", "", "# Clear organization makes helpers easy to find and reuse"]}, "dont": {"description": "Scatter helpers randomly throughout file", "content": ["# DON'T: Random helper placement", "def create_agent(...): ...", "def verify_config(...): ...", "def create_config(...): ...", "def some_test():", "def verify_agent(...): ...", "def another_test():", "def create_workspace(...): ...", "# WRONG: Helpers scattered randomly", "# Hard to find, hard to reuse", "# Group by purpose instead!"]}}]}}, {"rule_file": "match_specification_scenarios.json", "rule_content": {"description": "CRITICAL: Test docstrings and assertions must match specification scenarios exactly. Test names and docstrings describe the behavior from specification. Assertions verify exactly what the scenario states - no more, no less. Use exact variable names and terminology from specification.", "examples": [{"do": {"description": "Test matches specification scenario exactly", "content": ["# Specification scenario:", "# GIVEN: Base agent configuration exists", "# WHEN: Agent is initialized with agent_name='story_bot'", "# THEN: Agent sets up base agent configuration path at agents/base/agent.json", "", "def test_agent_initializes_with_base_config(self, workspace_root):", "    \"\"\"", "    SCENARIO: Agent initializes with base configuration", "    GIVEN: Base agent configuration exists", "    WHEN: Agent is initialized with agent_name='story_bot'", "    THEN: Agent sets up configuration path at agents/base/agent.json", "    \"\"\"", "    # Given", "    create_base_config(workspace_root)", "    ", "    # When", "    agent = Agent(agent_name='story_bot', workspace_root=workspace_root)", "    ", "    # Then - verify EXACTLY what scenario states", "    expected_path = workspace_root / \"agents\" / \"base\" / \"agent.json\"", "    assert agent.config_path == expected_path"]}, "dont": {"description": "Test doesn't match specification", "content": ["# DON'T: Different terminology or missing context", "def test_agent_init(self):", "    \"\"\"Test agent.\"\"\"  # WRONG - vague, doesn't match spec", "    agent = Agent('story_bot')", "    assert agent.initialized  # WRONG - not in specification", "", "# DON'T: Assert things not in specification", "def test_agent_initializes(self):", "    # ...", "    assert agent._internal_flag == True  # WRONG - internal detail", "    assert agent.validate.called  # WRONG - implementation detail"]}}, {"do": {"description": "Use exact variable names from specification", "content": ["# Specification: agent_name='story_bot', workspace_root='/test/workspace'", "", "def test_with_exact_names(self):", "    agent_name = 'story_bot'  # Exact name from spec", "    workspace_root = Path('/test/workspace')  # Exact name from spec", "    agent = Agent(agent_name=agent_name, workspace_root=workspace_root)"]}, "dont": {"description": "Different variable names than specification", "content": ["# DON'T: Use different names", "def test_with_wrong_names(self):", "    name = 'story_bot'  # WRONG - spec says 'agent_name'", "    root = Path('/test')  # WRONG - spec says 'workspace_root'"]}}]}}, {"rule_file": "mock_only_boundaries.json", "rule_content": {"description": "Mock ONLY at architectural boundaries: external APIs, network calls, uncontrollable services. DON'T mock internal business logic, classes under test, or file operations (use temp files). Mocking internal code defeats the purpose of tests. From BDD Rule 8.2 (Proper Mocking).", "examples": [{"do": {"description": "Mock only external dependencies", "content": ["# \u2705 DO: Mock external API (can't control)", "def test_agent_fetches_remote_configuration(self):", "    \"\"\"Agent fetches configuration from remote API.\"\"\"", "    # Given: Mock EXTERNAL HTTP request", "    with patch('requests.get') as mock_get:", "        mock_get.return_value.json.return_value = {", "            'name': 'story_bot',", "            'version': '1.0'", "        }", "        ", "        # When: Agent fetches from remote API", "        agent = Agent.from_remote_config('http://api.example.com/config')", "        ", "        # Then: Config loaded from API", "        assert agent.name == 'story_bot'", "        mock_get.assert_called_once_with('http://api.example.com/config')", "", "# \u2705 DO: Mock external monitoring service", "def test_agent_sends_metrics_on_initialization(self):", "    \"\"\"Agent sends metrics to monitoring service.\"\"\"", "    # Given: Mock EXTERNAL metrics service", "    with patch('monitoring.send_metric') as mock_send:", "        agent = Agent('bot', Path('/tmp'))", "        ", "        # When: Agent initializes (sends metrics)", "        agent.initialize()", "        ", "        # Then: Metrics sent to external service", "        mock_send.assert_called_with('agent_initialized', {'name': 'bot'})", "", "# \u2705 DO: Use real temp files instead of mocking file I/O", "def test_agent_loads_config_from_file(self, tmp_path):", "    \"\"\"Agent loads configuration from file.\"\"\"", "    # Given: REAL file in temp directory", "    config_file = tmp_path / 'config.json'", "    config_file.write_text('{\"name\": \"story_bot\"}')", "    ", "    # When: Agent loads from REAL file", "    agent = Agent()", "    config = agent.load_config(config_file)", "    ", "    # Then: Config loaded (real file I/O, no mocking!)", "    assert config['name'] == 'story_bot'"]}, "dont": {"description": "Mock internal business logic or file operations", "content": ["# DON'T: Mock the class under test", "def test_agent_initializes(self):", "    # WRONG: Mocking the class we're testing!", "    agent = Mock(spec=Agent)", "    agent.initialize.return_value = True", "    ", "    result = agent.initialize()", "    # This test is USELESS - we're testing the mock!", "", "# DON'T: Mock internal business logic", "def test_agent_validates_configuration(self):", "    # WRONG: Mocking internal validation method", "    with patch.object(Agent, 'validate_config') as mock_validate:", "        mock_validate.return_value = True", "        ", "        agent = Agent('bot', Path('/tmp'))", "        agent.initialize()", "        ", "        # This defeats the purpose - we WANT to test validation!", "        mock_validate.assert_called_once()", "", "# DON'T: Mock file operations (use real temp files)", "def test_agent_loads_config(self):", "    # WRONG: Mocking file I/O instead of using temp files", "    with patch('pathlib.Path.exists', return_value=True):", "        with patch('pathlib.Path.read_text') as mock_read:", "            mock_read.return_value = '{\"name\": \"bot\"}'", "            ", "            agent = Agent()", "            config = agent.load_config(Path('config.json'))", "            ", "            # WRONG: Use real temp files with tmp_path fixture!", "", "# DON'T: Mock json.loads (just use it!)", "def test_parses_json_config(self):", "    # WRONG: Mocking standard library that works fine", "    with patch('json.loads') as mock_json:", "        mock_json.return_value = {'name': 'bot'}", "        # Just use real json.loads! It's fast and reliable!", "", "# DON'T: Mock helper functions you own", "def test_creates_workspace(self):", "    # WRONG: Mocking your own helper", "    with patch('test_helpers.create_config_file'):", "        # Just call the real helper function!"]}}, {"do": {"description": "When to mock: external services only", "content": ["# Mock these EXTERNAL dependencies:", "", "# 1. Network/HTTP requests", "with patch('requests.get'): ...", "with patch('urllib.request.urlopen'): ...", "", "# 2. External APIs you don't control", "with patch('stripe.Customer.create'): ...", "with patch('boto3.client'): ...", "", "# 3. External services (email, SMS, monitoring)", "with patch('sendgrid.SendGridAPIClient.send'): ...", "with patch('twilio.rest.Client.messages.create'): ...", "with patch('monitoring.send_metric'): ...", "", "# 4. Time/date when you need deterministic values", "with patch('datetime.datetime.now') as mock_now:", "    mock_now.return_value = datetime(2025, 1, 1)", "", "# 5. Random values when you need deterministic tests", "with patch('random.randint') as mock_random:", "    mock_random.return_value = 42"]}, "dont": {"description": "Don't mock these - use real implementations", "content": ["# DON'T mock these - use REAL implementations:", "", "# 1. File I/O - use tmp_path fixture", "# \u274c DON'T: with patch('pathlib.Path.read_text')", "# \u2705 DO: Use tmp_path fixture and real files", "", "# 2. Standard library functions (json, os, pathlib)", "# \u274c DON'T: with patch('json.loads')", "# \u2705 DO: Use real json.loads - it's fast!", "", "# 3. Your own classes and business logic", "# \u274c DON'T: with patch.object(Agent, 'validate')", "# \u2705 DO: Test real validation logic", "", "# 4. Database operations - use test database", "# \u274c DON'T: with patch('database.query')", "# \u2705 DO: Use in-memory SQLite or test database", "", "# 5. Helper functions you wrote", "# \u274c DON'T: with patch('helpers.create_agent')", "# \u2705 DO: Call real helper function", "", "# 6. Configuration objects", "# \u274c DON'T: Mock(spec=Config)", "# \u2705 DO: Create real Config with test data"]}}, {"do": {"description": "Extract mock setup to helpers when repeated", "content": ["# Helper for common mock setup", "@pytest.fixture", "def mock_remote_api():", "    \"\"\"Fixture: Mock remote API responses.\"\"\"", "    with patch('requests.get') as mock_get:", "        mock_get.return_value.json.return_value = {", "            'name': 'story_bot',", "            'version': '1.0'", "        }", "        yield mock_get", "", "# Tests use fixture", "def test_fetches_remote_config(self, mock_remote_api):", "    agent = Agent.from_remote_config('http://api.com/config')", "    assert agent.name == 'story_bot'", "    mock_remote_api.assert_called_once()", "", "def test_retries_on_failure(self, mock_remote_api):", "    mock_remote_api.side_effect = [", "        ConnectionError(),", "        Mock(json=lambda: {'name': 'bot'})", "    ]", "    agent = Agent.from_remote_config('http://api.com/config')", "    assert mock_remote_api.call_count == 2"]}, "dont": {"description": "Duplicate mock setup across tests", "content": ["# DON'T: Duplicate mock setup", "def test_fetches_config(self):", "    with patch('requests.get') as mock_get:", "        mock_get.return_value.json.return_value = {'name': 'bot'}", "        agent = Agent.from_remote_config('http://api.com/config')", "        assert agent.name == 'bot'", "", "def test_retries_on_failure(self):", "    # WRONG: Duplicating same mock setup", "    with patch('requests.get') as mock_get:", "        mock_get.return_value.json.return_value = {'name': 'bot'}", "        # Use fixture instead!"]}}]}}, {"rule_file": "production_code_api_design.json", "rule_content": {"description": "PRODUCTION CODE RULE: Object-oriented API design principles from BDD. Objects initialize automatically, manage their own state (ask don't tell), use properties over methods when appropriate, and provide simple direct verb names. From BDD Rules 11.1-11.4.", "examples": [{"do": {"description": "Automatic initialization in constructor", "content": ["# Production Code - Automatic initialization", "class Agent:", "    def __init__(self, agent_name: str, workspace_root: Path):", "        \"\"\"Initialize agent with all dependencies automatically.\"\"\"", "        self.name = agent_name", "        self.workspace_root = workspace_root", "        # Automatic initialization - no manual steps required", "        self._config = self._load_config()  # Automatic", "        self._dependencies = self._initialize_dependencies()  # Automatic", "        self._initialized = True  # Ready immediately", "    ", "    def _load_config(self) -> dict:", "        \"\"\"Load configuration automatically.\"\"\"", "        config_path = self.workspace_root / 'agents' / self.name / 'config.json'", "        return json.loads(config_path.read_text())", "", "# Test is simple - object ready immediately", "def test_agent_ready_immediately_after_construction(self, workspace_root):", "    # When: Agent created", "    agent = Agent('story_bot', workspace_root)", "    ", "    # Then: Fully initialized and ready to use", "    assert agent.is_initialized", "    assert agent.config is not None", "    # No manual initialization steps required!"]}, "dont": {"description": "Manual initialization required after construction", "content": ["# DON'T: Require manual initialization", "class Agent:", "    def __init__(self, agent_name: str):", "        self.name = agent_name", "        self._config = None  # \u274c Not initialized", "        self._initialized = False  # \u274c Not ready", "    ", "    def load_config(self):  # \u274c Manual step", "        \"\"\"User must remember to call this!\"\"\"", "        self._config = ...", "    ", "    def initialize(self):  # \u274c Another manual step", "        \"\"\"User must remember to call this too!\"\"\"", "        self._initialized = True", "", "# Test must remember manual steps", "def test_agent(self, workspace_root):", "    agent = Agent('story_bot')", "    agent.load_config()  # \u274c Manual step", "    agent.initialize()  # \u274c Another manual step", "    # User must remember sequence - error-prone!"]}}, {"do": {"description": "Ask don't tell - objects manage their own state", "content": ["# Production Code - Object manages state", "class StoryGenerator:", "    def __init__(self, agent_name: str, workspace: Path):", "        self.agent_name = agent_name", "        self.workspace = workspace", "        self._phase = None", "        self._assumptions = None", "    ", "    # Set internal state", "    def start(self, phase: str):", "        \"\"\"Start generation in specified phase.\"\"\"", "        self._phase = phase", "    ", "    def set_assumptions(self, assumptions: dict):", "        \"\"\"Set assumptions for generation.\"\"\"", "        self._assumptions = assumptions", "    ", "    # Use internal state (no parameters needed)", "    def build_instructions(self) -> str:", "        \"\"\"Build instructions using internal state.\"\"\"", "        return f\"Phase: {self._phase}, Assumptions: {self._assumptions}\"", "    ", "    @property", "    def is_ready(self) -> bool:", "        \"\"\"Check if ready to generate.\"\"\"", "        return self._phase is not None and self._assumptions is not None", "", "# Test - object orchestrates its own state", "def test_generator_uses_internal_state(self):", "    generator = StoryGenerator('bot', Path('/tmp'))", "    ", "    # Set state on object", "    generator.start('shape')", "    generator.set_assumptions({'key': 'value'})", "    ", "    # Methods use internal state", "    instructions = generator.build_instructions()", "    assert 'shape' in instructions", "    assert generator.is_ready"]}, "dont": {"description": "Tell don't ask - pass state as parameters", "content": ["# DON'T: Require state passed as parameters", "class StoryGenerator:", "    def __init__(self, agent_name: str, workspace: Path):", "        self.agent_name = agent_name", "        self.workspace = workspace", "    ", "    # \u274c WRONG: Requires external state management", "    def build_instructions(self, phase: str, assumptions: dict) -> str:", "        \"\"\"External caller must manage state!\"\"\"", "        return f\"Phase: {phase}, Assumptions: {assumptions}\"", "", "# Test must manage state externally", "def test_generator(self):", "    generator = StoryGenerator('bot', Path('/tmp'))", "    ", "    # \u274c Caller manages state, not object", "    phase = 'shape'", "    assumptions = {'key': 'value'}", "    instructions = generator.build_instructions(phase, assumptions)", "    # Object doesn't manage its own state!"]}}, {"do": {"description": "Properties for state access, methods for actions", "content": ["# Production Code - Properties vs Methods", "class Agent:", "    def __init__(self, name: str, workspace: Path):", "        self.name = name", "        self.workspace = workspace", "        self._initialized = False", "        self._config = None", "    ", "    # Properties for STATE ACCESS", "    @property", "    def is_initialized(self) -> bool:", "        \"\"\"Check if agent is initialized.\"\"\"", "        return self._initialized", "    ", "    @property", "    def config_path(self) -> Path:", "        \"\"\"Get configuration file path.\"\"\"", "        return self.workspace / 'config.json'", "    ", "    @property", "    def config(self) -> dict:", "        \"\"\"Get current configuration.\"\"\"", "        return self._config", "    ", "    # Methods for ACTIONS", "    def initialize(self):", "        \"\"\"Initialize agent (action).\"\"\"", "        self._config = self._load_config()", "        self._initialized = True", "    ", "    def save(self):", "        \"\"\"Save agent state (action).\"\"\"", "        self.config_path.write_text(json.dumps(self._config))", "", "# Test uses properties for state, methods for actions", "def test_agent_api(self):", "    agent = Agent('bot', Path('/tmp'))", "    ", "    # Properties for state (no parentheses)", "    assert not agent.is_initialized", "    assert agent.config_path.exists()", "    ", "    # Methods for actions (with parentheses)", "    agent.initialize()", "    agent.save()"]}, "dont": {"description": "Methods for simple state access", "content": ["# DON'T: Methods for state access", "class Agent:", "    # \u274c WRONG: Methods for simple state", "    def get_is_initialized(self) -> bool:", "        return self._initialized", "    ", "    def get_config_path(self) -> Path:", "        return self.workspace / 'config.json'", "    ", "    def get_config(self) -> dict:", "        return self._config", "", "# Test has verbose method calls", "def test_agent(self):", "    agent = Agent('bot', Path('/tmp'))", "    ", "    # \u274c Verbose method calls for state", "    assert not agent.get_is_initialized()", "    assert agent.get_config_path().exists()", "    # Use properties instead!"]}}, {"do": {"description": "Simple direct verb names for methods", "content": ["# Production Code - Simple verb names", "class Agent:", "    def build(self) -> str:", "        \"\"\"Build instructions.\"\"\"", "        return self._generate_instructions()", "    ", "    def save(self):", "        \"\"\"Save agent state.\"\"\"", "        self._write_to_disk()", "    ", "    def validate(self) -> bool:", "        \"\"\"Validate configuration.\"\"\"", "        return self._check_config()", "    ", "    def transform(self, data: dict) -> dict:", "        \"\"\"Transform data.\"\"\"", "        return self._apply_transformations(data)", "", "# Simple, clear verbs: build, save, validate, transform", "# Easy to remember and use", "", "# Test uses simple verb names", "def test_agent_operations(self):", "    agent = Agent('bot', Path('/tmp'))", "    ", "    instructions = agent.build()", "    agent.save()", "    is_valid = agent.validate()", "    data = agent.transform({'key': 'value'})"]}, "dont": {"description": "Verbose or overly descriptive method names", "content": ["# DON'T: Verbose method names", "class Agent:", "    # \u274c WRONG: Overly verbose", "    def buildCompleteInstructionsWithAllOptions(self) -> str:", "        return self._generate_instructions()", "    ", "    def saveAgentStateToFileSystem(self):", "        self._write_to_disk()", "    ", "    def validateConfigurationAgainstSchema(self) -> bool:", "        return self._check_config()", "    ", "    def transformInputDataToOutputFormat(self, data: dict) -> dict:", "        return self._apply_transformations(data)", "", "# Test has verbose method calls", "def test_agent(self):", "    agent = Agent('bot', Path('/tmp'))", "    ", "    # \u274c Too verbose and complex", "    instructions = agent.buildCompleteInstructionsWithAllOptions()", "    agent.saveAgentStateToFileSystem()", "    # Simple verbs (build, save) are better!"]}}]}}, {"rule_file": "production_code_explicit_dependencies.json", "rule_content": {"description": "PRODUCTION CODE RULE: Make dependencies explicit through constructor injection. Pass all external dependencies (file systems, APIs, services) as constructor parameters. No hidden global state or singleton access. Tests should easily inject test doubles when needed. Follow user's rule: 'Maximize use of constructor injection - objects should have external dependencies passed in at construction time'.", "examples": [{"do": {"description": "Explicit constructor injection", "content": ["# Production Code - Dependencies injected", "class Agent:", "    def __init__(", "        self,", "        agent_name: str,", "        workspace_root: Path,", "        config_loader: ConfigLoader,", "        domain_graph: DomainGraph", "    ):", "        \"\"\"All dependencies explicit and injected.\"\"\"", "        self.agent_name = agent_name", "        self.workspace_root = workspace_root", "        self._config_loader = config_loader", "        self._domain_graph = domain_graph", "    ", "    def initialize(self):", "        \"\"\"Use injected dependencies.\"\"\"", "        config = self._config_loader.load(self.agent_name)", "        self._domain_graph.build_from_config(config)", "", "# Test easily injects test doubles", "def test_agent_initializes_with_config(self):", "    # Given: Create test dependencies", "    config_loader = FakeConfigLoader({'name': 'story_bot'})", "    domain_graph = FakeDomainGraph()", "    ", "    # When: Inject dependencies", "    agent = Agent(", "        agent_name='story_bot',", "        workspace_root=Path('/test'),", "        config_loader=config_loader,", "        domain_graph=domain_graph", "    )", "    agent.initialize()", "    ", "    # Then: Verify behavior", "    assert domain_graph.was_built", "    # Easy to test - no mocking needed!"]}, "dont": {"description": "Hidden dependencies and global state", "content": ["# DON'T: Hidden dependencies created inside class", "class Agent:", "    def __init__(self, agent_name: str, workspace_root: Path):", "        self.agent_name = agent_name", "        self.workspace_root = workspace_root", "        # WRONG - creates dependencies internally", "        self._config_loader = ConfigLoader()  # Hidden!", "        self._domain_graph = DomainGraph.get_instance()  # Singleton!", "    ", "    def load_data(self):", "        # WRONG - accesses global state", "        db = DatabaseConnection.instance()  # Hidden dependency!", "        return db.query('SELECT * FROM agents')", "", "# Test is forced to mock globally", "def test_agent_loads_data(self):", "    # WRONG - must patch global state", "    with patch('module.ConfigLoader') as mock_loader:", "        with patch('module.DomainGraph.get_instance') as mock_graph:", "            with patch('module.DatabaseConnection.instance') as mock_db:", "                agent = Agent('bot', Path('/test'))", "                # Fragile test coupled to implementation!", "                # Can't easily test with real implementations!"]}}, {"do": {"description": "Use factories for complex construction", "content": ["# Production Code - Factory with explicit dependencies", "class AgentFactory:", "    def __init__(", "        self,", "        workspace_root: Path,", "        config_loader: ConfigLoader,", "        domain_graph: DomainGraph", "    ):", "        \"\"\"Factory has its own explicit dependencies.\"\"\"", "        self._workspace_root = workspace_root", "        self._config_loader = config_loader", "        self._domain_graph = domain_graph", "    ", "    def create_agent(self, agent_name: str) -> Agent:", "        \"\"\"Create agent with injected dependencies.\"\"\"", "        return Agent(", "            agent_name=agent_name,", "            workspace_root=self._workspace_root,", "            config_loader=self._config_loader,", "            domain_graph=self._domain_graph", "        )", "", "# Test with factory", "def test_factory_creates_agent_with_dependencies(self, tmp_path):", "    # Given: Create factory with test dependencies", "    config_loader = FakeConfigLoader()", "    domain_graph = FakeDomainGraph()", "    factory = AgentFactory(", "        workspace_root=tmp_path,", "        config_loader=config_loader,", "        domain_graph=domain_graph", "    )", "    ", "    # When: Factory creates agent", "    agent = factory.create_agent('story_bot')", "    ", "    # Then: Agent has correct dependencies", "    assert agent.agent_name == 'story_bot'", "    assert agent.workspace_root == tmp_path"]}, "dont": {"description": "Factory with hidden dependencies", "content": ["# DON'T: Factory creates dependencies", "class AgentFactory:", "    @staticmethod", "    def create_agent(agent_name: str, workspace_root: Path) -> Agent:", "        # WRONG - creates dependencies inside", "        config_loader = ConfigLoader()  # Hidden!", "        domain_graph = DomainGraph()  # Hidden!", "        return Agent(agent_name, workspace_root, config_loader, domain_graph)", "", "# Test can't control dependencies", "def test_factory(self, tmp_path):", "    # WRONG - can't inject test dependencies", "    with patch('module.ConfigLoader'):  # Forced to mock", "        with patch('module.DomainGraph'):  # Forced to mock", "            agent = AgentFactory.create_agent('bot', tmp_path)", "            # Fragile test!"]}}]}}, {"rule_file": "production_code_single_responsibility.json", "rule_content": {"description": "PRODUCTION CODE RULE: Each function/method should do ONE thing and do it well. No hidden side effects. Name reveals complete behavior. Keep functions under 20 lines. Extract multiple concerns into separate functions. Tests should verify single responsibility - if test needs multiple unrelated assertions, function probably does too much.", "examples": [{"do": {"description": "Single responsibility functions", "content": ["# Production Code - Each function does ONE thing", "class Agent:", "    def load_config(self, config_path: Path) -> dict:", "        \"\"\"Load configuration from file.\"\"\"", "        return json.loads(config_path.read_text())", "    ", "    def validate_config(self, config: dict) -> bool:", "        \"\"\"Validate configuration structure.\"\"\"", "        required = ['name', 'workspace_root']", "        return all(key in config for key in required)", "    ", "    def initialize_from_config(self, config_path: Path):", "        \"\"\"Initialize agent from configuration file.\"\"\"", "        config = self.load_config(config_path)", "        if not self.validate_config(config):", "            raise ValueError('Invalid config')", "        self._apply_config(config)", "", "# Test verifies single responsibility", "def test_load_config_reads_json_from_file(self, tmp_path):", "    config_file = tmp_path / 'config.json'", "    config_file.write_text('{\"name\": \"bot\"}')", "    ", "    agent = Agent()", "    config = agent.load_config(config_file)", "    ", "    assert config == {'name': 'bot'}"]}, "dont": {"description": "Functions doing multiple things", "content": ["# DON'T: Function does multiple unrelated things", "class Agent:", "    def setup(self, config_path: Path):", "        # WRONG - loads, validates, initializes, AND logs", "        config = json.loads(config_path.read_text())", "        if 'name' not in config:", "            raise ValueError('Invalid')", "        self.name = config['name']", "        self.workspace = Path(config['workspace'])", "        logger.info(f'Agent {self.name} initialized')  # Side effect!", "        self._send_metrics()  # Hidden side effect!", "        return config  # Mixed responsibility", "", "# Test reveals the problem - too many concerns", "def test_setup(self, tmp_path, mock_logger, mock_metrics):", "    # WRONG - test needs to verify too many unrelated things", "    config_file = tmp_path / 'config.json'", "    config_file.write_text('{\"name\": \"bot\", \"workspace\": \"/tmp\"}')", "    ", "    agent = Agent()", "    result = agent.setup(config_file)", "    ", "    assert agent.name == 'bot'  # Config loading", "    assert agent.workspace == Path('/tmp')  # Config parsing", "    mock_logger.info.assert_called()  # Logging", "    mock_metrics.assert_called()  # Metrics", "    assert result == {'name': 'bot', 'workspace': '/tmp'}  # Return value", "    # TOO MANY RESPONSIBILITIES!"]}}, {"do": {"description": "Separate business logic from side effects", "content": ["# Production Code - Pure business logic", "class ConfigValidator:", "    def validate(self, config: dict) -> ValidationResult:", "        \"\"\"Pure validation logic - no side effects.\"\"\"", "        errors = []", "        if 'name' not in config:", "            errors.append('Missing name')", "        if 'workspace_root' not in config:", "            errors.append('Missing workspace_root')", "        return ValidationResult(is_valid=len(errors) == 0, errors=errors)", "", "# Side effects in separate functions", "class Agent:", "    def initialize_with_logging(self, config: dict):", "        \"\"\"Initialize agent and log the action.\"\"\"", "        result = self._initialize(config)  # Pure logic", "        self._log_initialization(config)  # Side effect", "        return result", "", "# Tests are simple - test logic separately from side effects", "def test_validate_returns_errors_for_missing_fields(self):", "    validator = ConfigValidator()", "    result = validator.validate({'name': 'bot'})", "    ", "    assert not result.is_valid", "    assert 'Missing workspace_root' in result.errors"]}, "dont": {"description": "Mix business logic with side effects", "content": ["# DON'T: Mix logic and side effects", "class Agent:", "    def validate_and_log(self, config: dict) -> bool:", "        # WRONG - validation mixed with logging", "        logger.info('Validating config')  # Side effect", "        is_valid = 'name' in config", "        if is_valid:", "            logger.info('Config valid')  # Side effect", "            self._send_metrics('valid_config')  # Side effect", "        else:", "            logger.error('Config invalid')  # Side effect", "        return is_valid", "", "# Test is forced to mock side effects", "def test_validate(self, mock_logger, mock_metrics):", "    # WRONG - can't test logic without mocking side effects", "    agent = Agent()", "    result = agent.validate_and_log({'name': 'bot'})", "    # Test is fragile and coupled to logging implementation"]}}]}}, {"rule_file": "production_code_small_functions.json", "rule_content": {"description": "PRODUCTION CODE RULE: Keep functions under 20 lines. Each function should be one level of abstraction. Extract complex logic into named helper functions. Use guard clauses to reduce nesting. Keep nesting under 2-3 levels. Tests for small functions are easier to write and understand.", "examples": [{"do": {"description": "Small focused functions under 20 lines", "content": ["# Production Code - Small functions, one level of abstraction", "class Agent:", "    def initialize_from_config_file(self, config_path: Path):", "        \"\"\"Initialize agent from configuration file.\"\"\"", "        self._validate_config_file_exists(config_path)", "        config = self._load_config(config_path)", "        self._validate_config_structure(config)", "        self._apply_config(config)", "    ", "    def _validate_config_file_exists(self, config_path: Path):", "        \"\"\"Validate configuration file exists.\"\"\"", "        if not config_path.exists():", "            raise FileNotFoundError(f'Config not found: {config_path}')", "    ", "    def _load_config(self, config_path: Path) -> dict:", "        \"\"\"Load configuration from file.\"\"\"", "        try:", "            return json.loads(config_path.read_text())", "        except json.JSONDecodeError as e:", "            raise ValueError(f'Invalid JSON: {e}')", "    ", "    def _validate_config_structure(self, config: dict):", "        \"\"\"Validate configuration has required fields.\"\"\"", "        required = ['name', 'workspace_root']", "        missing = [f for f in required if f not in config]", "        if missing:", "            raise ValueError(f'Missing fields: {missing}')", "", "# Tests are simple - one function, one test", "def test_validate_config_file_raises_when_file_missing(self):", "    agent = Agent()", "    with pytest.raises(FileNotFoundError, match='Config not found'):", "        agent._validate_config_file_exists(Path('missing.json'))"]}, "dont": {"description": "Large monolithic functions over 20 lines", "content": ["# DON'T: Large function mixing abstraction levels", "class Agent:", "    def initialize_from_config_file(self, config_path: Path):", "        # WRONG - 40+ lines, multiple abstraction levels", "        if not config_path.exists():", "            logger.error(f'File not found: {config_path}')", "            raise FileNotFoundError('Config not found')", "        ", "        try:", "            content = config_path.read_text()", "        except IOError as e:", "            logger.error(f'Failed to read: {e}')", "            raise", "        ", "        try:", "            config = json.loads(content)", "        except json.JSONDecodeError as e:", "            logger.error(f'Invalid JSON: {e}')", "            raise ValueError('Invalid JSON')", "        ", "        if 'name' not in config:", "            logger.error('Missing name field')", "            raise ValueError('Missing name')", "        ", "        if 'workspace_root' not in config:", "            logger.error('Missing workspace_root')", "            raise ValueError('Missing workspace_root')", "        ", "        self.name = config['name']", "        self.workspace_root = Path(config['workspace_root'])", "        ", "        if not self.workspace_root.exists():", "            logger.warning('Creating workspace')", "            self.workspace_root.mkdir(parents=True)", "        ", "        # ... more code ...", "        # TOO LONG! Hard to test! Extract into smaller functions!", "", "# Test is complex and fragile", "def test_initialize_from_config_file(self, tmp_path, mock_logger):", "    # WRONG - test must handle all cases at once", "    # Multiple assertions, hard to maintain"]}}, {"do": {"description": "Use guard clauses to reduce nesting", "content": ["# Production Code - Guard clauses, early returns", "class ConfigValidator:", "    def validate_agent_config(self, config: dict) -> ValidationResult:", "        \"\"\"Validate agent configuration structure.\"\"\"", "        # Guard clauses - check and return early", "        if not config:", "            return ValidationResult.error('Config is empty')", "        ", "        if 'name' not in config:", "            return ValidationResult.error('Missing name')", "        ", "        if not isinstance(config['name'], str):", "            return ValidationResult.error('Name must be string')", "        ", "        if len(config['name']) == 0:", "            return ValidationResult.error('Name cannot be empty')", "        ", "        # Happy path at end, no nesting", "        return ValidationResult.success()", "", "# Tests are simple - one guard clause per test", "def test_validate_returns_error_when_config_empty(self):", "    validator = ConfigValidator()", "    result = validator.validate_agent_config({})", "    assert not result.is_valid", "    assert 'empty' in result.error.lower()"]}, "dont": {"description": "Deep nesting instead of guard clauses", "content": ["# DON'T: Deep nesting", "class ConfigValidator:", "    def validate_agent_config(self, config: dict) -> ValidationResult:", "        # WRONG - nested if statements", "        if config:", "            if 'name' in config:", "                if isinstance(config['name'], str):", "                    if len(config['name']) > 0:", "                        if 'workspace_root' in config:", "                            if isinstance(config['workspace_root'], str):", "                                return ValidationResult.success()", "                            else:", "                                return ValidationResult.error('workspace_root type')", "                        else:", "                            return ValidationResult.error('Missing workspace_root')", "                    else:", "                        return ValidationResult.error('Empty name')", "                else:", "                    return ValidationResult.error('Name type')", "            else:", "                return ValidationResult.error('Missing name')", "        else:", "            return ValidationResult.error('Empty config')", "        # WRONG - 6 levels deep! Unreadable! Use guard clauses!"]}}]}}, {"rule_file": "pytest_bdd_orchestrator_pattern.json", "rule_content": {"description": "MASTER RULE: Use pytest with orchestrator pattern for BDD-style tests. NO FEATURE FILES. Test classes contain orchestrator methods (under 20 lines) that show Given-When-Then flow by calling helper functions. Production code follows clean code principles: single responsibility, explicit dependencies, small functions. Tests drive production code through RED-GREEN-REFACTOR cycle.", "principles": ["1. Orchestrator Pattern: Test methods show flow, delegate to helpers", "2. Given-When-Then Structure: Clear sections with comments in each test", "3. Small Functions: Tests under 20 lines, helpers under 20 lines, classes under 300 lines", "4. Test Observable Behavior: Verify public API, not implementation details", "5. Real Implementations: Use real code with temp files, only mock external boundaries", "6. Explicit Dependencies: Constructor injection in production code", "7. Single Responsibility: Each function does one thing", "8. Test-Driven Development: RED-GREEN-REFACTOR cycle"], "examples": [{"description": "Complete example with all principles", "content": ["\"\"\"", "Agent Configuration Tests", "", "Tests follow orchestrator pattern:", "- Test methods show Given-When-Then flow (under 20 lines)", "- Helper functions provide reusable operations (under 20 lines)", "- Tests verify observable behavior through public API", "- Production code uses explicit dependencies and single responsibility", "\"\"\"", "import pytest", "from pathlib import Path", "import json", "", "# ============================================================================", "# HELPER FUNCTIONS - Reusable test operations", "# ============================================================================", "", "def create_config_file(workspace: Path, agent_name: str) -> Path:", "    \"\"\"Helper: Create configuration file with agent name.\"\"\"", "    config_dir = workspace / 'agents' / 'base'", "    config_dir.mkdir(parents=True, exist_ok=True)", "    config_file = config_dir / 'agent.json'", "    config_file.write_text(json.dumps({'name': agent_name}))", "    return config_file", "", "def create_domain_graph_file(workspace: Path, nodes: list) -> Path:", "    \"\"\"Helper: Create domain graph file with nodes.\"\"\"", "    graph_file = workspace / 'domain_graph.json'", "    graph_file.write_text(json.dumps({'nodes': nodes}))", "    return graph_file", "", "def verify_agent_configured(agent, expected_name: str, expected_workspace: Path):", "    \"\"\"Helper: Verify agent is correctly configured.\"\"\"", "    assert agent.name == expected_name", "    assert agent.workspace_root == expected_workspace", "    assert agent.is_initialized", "", "# ============================================================================", "# FIXTURES - Test setup", "# ============================================================================", "", "@pytest.fixture", "def workspace_root(tmp_path):", "    \"\"\"Fixture: Temporary workspace directory.\"\"\"", "    workspace = tmp_path / 'workspace'", "    workspace.mkdir()", "    return workspace", "", "@pytest.fixture", "def config_loader():", "    \"\"\"Fixture: Configuration loader for tests.\"\"\"", "    return ConfigLoader()", "", "@pytest.fixture", "def domain_graph():", "    \"\"\"Fixture: Domain graph for tests.\"\"\"", "    return DomainGraph()", "", "# ============================================================================", "# ORCHESTRATOR TESTS - Test flows with Given-When-Then", "# ============================================================================", "", "class TestAgentInitialization:", "    \"\"\"Agent initialization behavior tests.\"\"\"", "    ", "    def test_agent_initializes_with_base_config(self, workspace_root, config_loader, domain_graph):", "        \"\"\"", "        SCENARIO: Agent initializes with base configuration", "        GIVEN: Base configuration file exists", "        WHEN: Agent is initialized with agent_name='story_bot'", "        THEN: Agent loads configuration and is ready", "        \"\"\"", "        # Given: Configuration file exists", "        config_file = create_config_file(workspace_root, 'story_bot')", "        ", "        # When: Agent is initialized with dependencies", "        agent = Agent(", "            agent_name='story_bot',", "            workspace_root=workspace_root,", "            config_loader=config_loader,", "            domain_graph=domain_graph", "        )", "        agent.initialize()", "        ", "        # Then: Agent is correctly configured", "        verify_agent_configured(agent, 'story_bot', workspace_root)", "        assert agent.config_path == config_file", "    ", "    def test_agent_loads_domain_graph_when_initialized(self, workspace_root, config_loader, domain_graph):", "        \"\"\"", "        SCENARIO: Agent loads domain graph during initialization", "        GIVEN: Domain graph file exists with nodes", "        WHEN: Agent initializes", "        THEN: Agent has loaded domain graph with nodes", "        \"\"\"", "        # Given: Domain graph file exists", "        graph_file = create_domain_graph_file(workspace_root, ['node1', 'node2'])", "        config_file = create_config_file(workspace_root, 'story_bot')", "        ", "        # When: Agent initializes and loads graph", "        agent = Agent('story_bot', workspace_root, config_loader, domain_graph)", "        agent.initialize()", "        agent.load_domain_graph(graph_file)", "        ", "        # Then: Domain graph is loaded (test through public API)", "        assert agent.has_domain_graph", "        assert agent.get_domain_nodes() == ['node1', 'node2']", "", "class TestAgentConfigValidation:", "    \"\"\"Agent configuration validation behavior tests.\"\"\"", "    ", "    def test_agent_raises_error_when_config_missing(self, workspace_root, config_loader, domain_graph):", "        \"\"\"", "        SCENARIO: Agent raises error when configuration missing", "        GIVEN: No configuration file exists", "        WHEN: Agent attempts to initialize", "        THEN: Agent raises FileNotFoundError", "        \"\"\"", "        # Given: No config file (workspace is empty)", "        ", "        # When/Then: Initializing raises error", "        agent = Agent('story_bot', workspace_root, config_loader, domain_graph)", "        with pytest.raises(FileNotFoundError, match='Configuration not found'):", "            agent.initialize()", "", "# ============================================================================", "# PRODUCTION CODE - Following clean code principles", "# ============================================================================", "", "class Agent:", "    \"\"\"", "    Agent with configuration and domain graph support.", "    ", "    Follows clean code principles:", "    - Explicit dependencies through constructor injection", "    - Single responsibility per method", "    - Small methods under 20 lines", "    - Public API for testable behavior", "    \"\"\"", "    ", "    def __init__(", "        self,", "        agent_name: str,", "        workspace_root: Path,", "        config_loader: ConfigLoader,", "        domain_graph: DomainGraph", "    ):", "        \"\"\"Initialize agent with explicit dependencies.\"\"\"", "        self.name = agent_name", "        self.workspace_root = workspace_root", "        self._config_loader = config_loader", "        self._domain_graph = domain_graph", "        self._initialized = False", "        self._config_path = None", "    ", "    # Public API - Testable behavior", "    ", "    def initialize(self):", "        \"\"\"Initialize agent from configuration.\"\"\"", "        self._config_path = self._resolve_config_path()", "        config = self._config_loader.load(self._config_path)", "        self._validate_config(config)", "        self._initialized = True", "    ", "    def load_domain_graph(self, graph_path: Path):", "        \"\"\"Load domain graph from file.\"\"\"", "        self._domain_graph.load_from_file(graph_path)", "    ", "    @property", "    def is_initialized(self) -> bool:", "        \"\"\"Check if agent is initialized.\"\"\"", "        return self._initialized", "    ", "    @property", "    def config_path(self) -> Path:", "        \"\"\"Get agent configuration path.\"\"\"", "        return self._config_path", "    ", "    @property", "    def has_domain_graph(self) -> bool:", "        \"\"\"Check if domain graph is loaded.\"\"\"", "        return self._domain_graph.is_loaded", "    ", "    def get_domain_nodes(self) -> list:", "        \"\"\"Get list of domain nodes.\"\"\"", "        return self._domain_graph.get_nodes()", "    ", "    # Private helpers - Single responsibility", "    ", "    def _resolve_config_path(self) -> Path:", "        \"\"\"Resolve configuration file path.\"\"\"", "        config_path = self.workspace_root / 'agents' / 'base' / 'agent.json'", "        if not config_path.exists():", "            raise FileNotFoundError(f'Configuration not found: {config_path}')", "        return config_path", "    ", "    def _validate_config(self, config: dict):", "        \"\"\"Validate configuration structure.\"\"\"", "        if 'name' not in config:", "            raise ValueError('Configuration missing required field: name')", "", "# ============================================================================", "# KEY PRINCIPLES DEMONSTRATED:", "#", "# 1. Orchestrator Pattern:", "#    - test_agent_initializes_with_base_config shows flow (15 lines)", "#    - Delegates to create_config_file, verify_agent_configured helpers", "#", "# 2. Given-When-Then Structure:", "#    - Each test has clear Given/When/Then sections with comments", "#", "# 3. Small Functions:", "#    - All test methods under 20 lines", "#    - All helpers under 15 lines", "#    - Production methods under 10 lines each", "#", "# 4. Test Observable Behavior:", "#    - Tests use public API: is_initialized, config_path, get_domain_nodes()", "#    - No assertions on _initialized, _config_path (private)", "#", "# 5. Real Implementations:", "#    - Uses real files with tmp_path fixture", "#    - No mocking of business logic", "#", "# 6. Explicit Dependencies:", "#    - Agent constructor takes config_loader, domain_graph", "#    - Tests inject test doubles easily", "#", "# 7. Single Responsibility:", "#    - initialize() does initialization", "#    - load_domain_graph() loads graph", "#    - _resolve_config_path() resolves path", "#    - Each method does ONE thing", "#", "# 8. Test-Driven Development:", "#    - Write test first (RED)", "#    - Implement minimal code (GREEN)", "#    - Refactor while tests stay green (REFACTOR)", "# ============================================================================"]}]}}, {"rule_file": "self_documenting_tests.json", "rule_content": {"description": "Tests are self-documenting through code structure. Do NOT add verbose comments explaining that tests will fail or what API is needed. The imports, constructor calls, method calls, and assertions clearly show the expected API design. Let the code speak for itself.", "examples": [{"do": {"description": "Self-documenting test through code structure", "content": ["def test_generator_creates_server_for_test_bot(self, workspace_root):", "    \"\"\"", "    SCENARIO: Generator creates MCP server for test_bot", "    GIVEN: Bot config exists with behaviors configured", "    WHEN: Generator receives Bot Config", "    THEN: Generator creates MCP Server instance with unique server name", "    \"\"\"", "    # Given: Bot config and base templates exist", "    bot_name = 'test_bot'", "    behaviors = ['shape', 'discovery', 'exploration', 'specification']", "    config_file = create_bot_config(workspace_root, bot_name, behaviors)", "    create_base_server_template(workspace_root)", "    create_base_bot_class(workspace_root)", "    ", "    # When: Call REAL MCPServerGenerator API", "    from agile_bot.bots.base_bot.src.mcp_server_generator import MCPServerGenerator", "    generator = MCPServerGenerator(", "        bot_name=bot_name,", "        config_path=config_file,", "        workspace_root=workspace_root", "    )", "    server_file = generator.generate_server()", "    ", "    # Then: Server file created with unique name", "    assert server_file.exists()", "    assert server_file.name == f'{bot_name}_server.py'", "    assert server_file.parent.name == 'src'", "    ", "    # Verify server content includes bot config reference", "    server_content = server_file.read_text()", "    assert 'test_bot_server' in server_content", "    assert 'bot_config.json' in server_content", "    assert 'test_bot.py' in server_content", "", "# GOOD: Code is self-documenting:", "# - Import shows MCPServerGenerator class is needed", "# - Constructor shows bot_name, config_path, workspace_root parameters", "# - Method call shows generate_server() returns a Path", "# - Assertions show expected file properties and content", "# NO verbose comments needed!"]}, "dont": {"description": "Verbose comments explaining what will fail", "content": ["def test_generator_creates_server_for_test_bot(self, workspace_root):", "    # Given: Bot config exists", "    config_file = create_bot_config(workspace_root, 'test_bot', ['shape'])", "    ", "    # When: Call API", "    from agile_bot.bots.base_bot.src.mcp_server_generator import MCPServerGenerator", "    generator = MCPServerGenerator(", "        bot_name='test_bot',", "        config_path=config_file,", "        workspace_root=workspace_root", "    )", "    server_file = generator.generate_server()", "    ", "    # Then: Server created", "    assert server_file.exists()", "    ", "    # DON'T: Verbose comments explaining failures", "    # TEST WILL FAIL: ImportError or MCPServerGenerator doesn't exist yet", "    # Shows API needs: MCPServerGenerator(bot_name, config_path, workspace_root)", "    # Shows API needs: generator.generate_server() returns Path to server file", "    # Shows server file must reference bot config and bot instantiation", "    # WRONG: All of this is already obvious from the code above!"]}}, {"do": {"description": "Error handling test is self-documenting", "content": ["def test_generator_fails_when_config_missing(self, workspace_root):", "    \"\"\"", "    SCENARIO: Generator fails when Bot Config is missing", "    GIVEN: Bot config does not exist", "    WHEN: Generator attempts to receive Bot Config", "    THEN: Raises FileNotFoundError", "    \"\"\"", "    # Given: No bot config file exists", "    bot_name = 'test_bot'", "    config_path = workspace_root / 'agile_bot' / 'bots' / bot_name / 'config' / 'bot_config.json'", "    ", "    # When: Call REAL MCPServerGenerator API", "    from agile_bot.bots.base_bot.src.mcp_server_generator import MCPServerGenerator", "    generator = MCPServerGenerator(", "        bot_name=bot_name,", "        config_path=config_path,", "        workspace_root=workspace_root", "    )", "    ", "    # Then: Raises FileNotFoundError with clear message", "    with pytest.raises(FileNotFoundError) as exc_info:", "        generator.generate_server()", "    ", "    assert 'Bot Config not found' in str(exc_info.value)", "    assert 'bot_config.json' in str(exc_info.value)", "", "# GOOD: Code shows:", "# - FileNotFoundError should be raised", "# - Error message should mention 'Bot Config not found' and 'bot_config.json'", "# Self-documenting through pytest.raises and assertions!"]}, "dont": {"description": "Adding redundant failure explanations", "content": ["def test_generator_fails_when_config_missing(self, workspace_root):", "    # Given: No config", "    config_path = workspace_root / 'config.json'", "    ", "    # When: Call API", "    from agile_bot.bots.base_bot.src.mcp_server_generator import MCPServerGenerator", "    generator = MCPServerGenerator('test_bot', config_path, workspace_root)", "    ", "    # Then: Raises error", "    with pytest.raises(FileNotFoundError) as exc_info:", "        generator.generate_server()", "    assert 'Bot Config not found' in str(exc_info.value)", "    ", "    # DON'T: Redundant explanations", "    # TEST WILL FAIL: ImportError or MCPServerGenerator doesn't exist yet", "    # Shows API needs proper error handling for missing config", "    # WRONG: pytest.raises already shows this!"]}}, {"do": {"description": "Complex API revealed through code", "content": ["def test_generator_creates_tools_for_all_behaviors(self, workspace_root):", "    \"\"\"", "    SCENARIO: Generator creates tools for test_bot with 4 behaviors", "    GIVEN: Bot has 4 behaviors with 6 actions each", "    WHEN: Generator processes Bot Config", "    THEN: Creates 24 tool instances (4 x 6)", "    \"\"\"", "    # Given: Bot config with multiple behaviors", "    bot_name = 'test_bot'", "    behaviors = ['shape', 'discovery', 'exploration', 'specification']", "    config_file = create_bot_config(workspace_root, bot_name, behaviors)", "    ", "    # When: Call REAL ToolGenerator API", "    from agile_bot.bots.base_bot.src.tool_generator import ToolGenerator", "    generator = ToolGenerator(", "        bot_name=bot_name,", "        config_path=config_file,", "        workspace_root=workspace_root", "    )", "    tools = generator.generate_all_tools()", "    ", "    # Then: All behavior-action pairs generate tools", "    assert len(tools) == 24", "    assert all(hasattr(tool, 'name') for tool in tools)", "    assert all(hasattr(tool, 'behavior') for tool in tools)", "    assert all(hasattr(tool, 'action') for tool in tools)", "    ", "    # Verify tool naming format", "    tool_names = [tool.name for tool in tools]", "    assert 'test_bot_shape_gather_context' in tool_names", "", "# GOOD: Code reveals complete API:", "# - ToolGenerator class with constructor parameters", "# - generate_all_tools() returns list of tool objects", "# - Tool objects have name, behavior, action attributes", "# - Tool naming convention is clear from assertion", "# All self-documenting!"]}, "dont": {"description": "Explaining what code already shows", "content": ["    # Then: Tools generated", "    assert len(tools) == 24", "    assert all(hasattr(tool, 'name') for tool in tools)", "    ", "    # DON'T: Explaining the obvious", "    # TEST WILL FAIL: ImportError or ToolGenerator doesn't exist yet", "    # Shows API needs: ToolGenerator(bot_name, config_path, workspace_root)", "    # Shows API needs: generator.generate_all_tools() returns list of Tool objects", "    # Shows Tool needs: name, behavior, action properties", "    # WRONG: This is redundant - the code above already shows all of this!"]}}], "rationale": ["Tests that call real APIs are self-documenting - code reveals expected structure", "Import statements show what modules and classes are needed", "Constructor calls show what parameters are required (names and types)", "Method calls show what APIs must exist and what they return", "Assertions show expected properties, return types, and behavior", "pytest.raises shows expected exceptions and error messages", "Verbose comments add noise and duplicate information", "When tests fail, error messages clearly show what's missing", "Code is the documentation - comments should explain WHY not WHAT"], "key_principles": ["Tests are self-documenting through code structure", "Do NOT add comments explaining 'TEST WILL FAIL' or 'Shows API needs'", "Import statements document required modules/classes", "Constructor calls document required parameters", "Method calls document expected APIs and return types", "Assertions document expected properties and behavior", "Error tests use pytest.raises to document expected exceptions", "Let the failing test error messages explain what's missing", "Comments should explain complex logic or business rules, not API structure", "If code needs explanation, it's probably not clear enough"], "antipatterns": ["Adding 'TEST WILL FAIL' comments explaining obvious failures", "Documenting in comments what imports already show", "Explaining constructor parameters in comments when code is clear", "Listing what methods are needed when method calls show this", "Describing return types when assertions demonstrate them", "Verbose explanations that duplicate what pytest.raises shows", "Comments that explain WHAT the code does (code should be self-explanatory)", "Over-commenting to compensate for unclear code"], "what_to_comment": {"do_comment": ["Complex business rules that aren't obvious from code", "Why a specific test approach was chosen", "External dependencies or system requirements", "Non-obvious test data values and why they were chosen", "Workarounds for known issues or limitations"], "dont_comment": ["That test will fail (obvious when test is for unimplemented code)", "What classes or methods are needed (imports and calls show this)", "What parameters constructors take (constructor call shows this)", "What methods return (assertions show this)", "What exceptions are raised (pytest.raises shows this)"]}}}, {"rule_file": "tests_must_match_story_graph_exactly.json", "rule_content": {"rule_id": "tests_must_match_story_graph_exactly", "description": "Test structure must match story graph exactly: file names match sub-epics, class names match stories, method names match scenarios, and ordering follows story map sequence", "rationale": "Tests provide 1-to-1 traceability with story map. Exact naming and ordering makes it trivial to find tests for any story or scenario by following story map hierarchy.", "sub_rules": [{"rule_id": "test_file_matches_sub_epic", "description": "Test file name must match sub-epic name in snake_case format: test_<sub_epic_name>.py", "examples": [{"sub_epic": "Generate Bot Server And Tools", "correct": "test_generate_bot_server_and_tools.py", "wrong": ["test_increment_3_generate_bot_server_and_tools.py (includes increment number)", "test_bot_server_tools.py (abbreviated)", "test_generator.py (too generic)"]}, {"sub_epic": "Invoke Bot Tool", "correct": "test_invoke_bot_tool.py", "wrong": ["test_bot_tool_invocation.py (different words)", "test_tool_routing.py (generic)"]}, {"sub_epic": "Validate Knowledge & Content Against Rules", "correct": "test_validate_knowledge_and_content_against_rules.py", "wrong": ["test_validate_rules.py (too short)", "test_validation.py (generic)"]}]}, {"rule_id": "test_class_matches_story_exactly", "description": "Test class name must match story name EXACTLY in PascalCase: class Test<ExactStoryName>. NO abbreviations, NO generic terms.", "examples": [{"story": "Generate Bot Tools", "correct": "class TestGenerateBotTools:", "wrong": ["class TestGenBotTools: (abbreviated)", "class TestBotToolGeneration: (reworded)", "class TestToolGenerator: (different words)"]}, {"story": "Inject Guardrails as Part of Clarify Requirements", "correct": "class TestInjectGuardrailsAsPartOfClarifyRequirements:", "wrong": ["class TestGuardrailsInjection: (generic, missing context)", "class TestInjectGuardrails: (missing 'as Part of Clarify Requirements')", "class TestClarifyRequirements: (wrong focus)"]}, {"story": "Track Activity for Gather Context Action", "correct": "class TestTrackActivityForGatherContextAction:", "wrong": ["class TestTrackActivity: (missing context)", "class TestGatherContext: (wrong focus)", "class TestActivityTracking: (reworded)"]}, {"story": "Inject Validation Rules for Validate Rules Action", "correct": "class TestInjectValidationRulesForValidateRulesAction:", "wrong": ["class TestValidationRules: (generic)", "class TestInjectRules: (abbreviated)"]}]}, {"rule_id": "test_method_matches_scenario", "description": "Test method name must match scenario name from story document in snake_case: def test_<scenario_name_snake_case>", "examples": [{"scenario": "Generator creates bot tool for test_bot", "correct": "def test_generator_creates_bot_tool_for_test_bot(self, workspace_root):", "wrong": ["def test_creates_tool(self): (abbreviated)", "def test_bot_tool_generation(self): (generic)", "def test_scenario_1(self): (numbered, not descriptive)"]}, {"scenario": "Bot tool loads workflow state to determine routing", "correct": "def test_bot_tool_loads_workflow_state_to_determine_routing(self, workspace_root):", "wrong": ["def test_loads_state(self): (abbreviated)", "def test_routing(self): (too generic)"]}, {"scenario": "Router routes to current behavior from saved state", "correct": "def test_router_routes_to_current_behavior_from_saved_state(self, workspace_root):", "wrong": ["def test_routes_to_behavior(self): (abbreviated)", "def test_routing_behavior(self): (reworded)"]}]}, {"rule_id": "test_classes_ordered_by_story_map", "description": "Test classes must appear in same order as stories in story map. File should read like story map.", "examples": [{"story_map_order": ["1. Generate Bot Tools (Increment 3)", "2. Generate Behavior Tools (Increment 3)", "3. Generate MCP Bot Server (Increment 2)", "4. Generate Behavior Action Tools (Increment 2)"], "correct_test_order": ["class TestGenerateBotTools:", "class TestGenerateBehaviorTools:", "class TestGenerateMCPBotServer:", "class TestGenerateBehaviorActionTools:"], "wrong_test_order": ["class TestGenerateMCPBotServer: (out of order - increment 2 before increment 3)", "class TestGenerateBotTools: (should be first)", "class TestGenerateBehaviorTools:", "class TestGenerateBehaviorActionTools:"]}, {"story_map_order": ["1. Track Activity for Gather Context Action", "2. Proceed To Decide Planning"], "correct_test_order": ["class TestTrackActivityForGatherContextAction:", "class TestProceedToDecidePlanning:"], "wrong_test_order": ["class TestProceedToDecidePlanning: (should be second, not first)", "class TestTrackActivityForGatherContextAction: (should be first)"]}]}], "validation": {"check_file_naming": "Filename format is test_<sub_epic_snake_case>.py", "check_class_naming": "Class name format is Test<FullStoryNamePascalCase> (no abbreviations)", "check_method_naming": "Method name format is test_<scenario_name_snake_case>", "check_ordering": "Test classes appear in same sequence as stories in story map", "error_messages": {"file_naming": "Test file must be named test_<sub_epic_name>.py matching exact sub-epic name", "class_naming": "Test class must use EXACT story name: Test<ExactStoryName>, no abbreviations or generic names", "method_naming": "Test method must match scenario name from story document", "ordering": "Test classes must appear in same order as stories in story map"}}, "key_principles": ["Test file name = sub-epic name in snake_case", "Test class name = EXACT story name in PascalCase (no abbreviations!)", "Test method name = scenario name in snake_case", "Test class order = story map order (reads like story map)", "One test file per sub-epic (all stories in that sub-epic)", "One test class per story (exact 1-to-1 mapping)", "One test method per scenario (exact 1-to-1 mapping)"], "common_violations": ["Adding increment numbers to filenames (test_increment_3_<name>.py)", "Abbreviating story names in class names (TestGenTools vs TestGenerateBotTools)", "Using generic class names (TestGuardrailsInjection vs TestInjectGuardrailsAsPartOfClarifyRequirements)", "Using different words than story (test_bot_tool_invocation.py vs test_invoke_bot_tool.py)", "Test classes out of order (not matching story map sequence)", "Abbreviated method names (test_creates_tool vs test_generator_creates_bot_tool_for_test_bot)"]}}, {"rule_file": "test_driven_development.json", "rule_content": {"description": "Follow Test-Driven Development (TDD) with RED-GREEN-REFACTOR cycle. Write failing test FIRST that describes desired behavior. Write minimal production code to pass test. Refactor both test and production code while keeping tests green. Tests drive API design and production code structure.", "examples": [{"do": {"description": "RED-GREEN-REFACTOR cycle", "content": ["# PHASE 1: RED - Write failing test first", "def test_agent_loads_config_from_file(self, tmp_path):", "    \"\"\"Agent loads configuration from JSON file.\"\"\"", "    # Given: Config file exists", "    config_file = tmp_path / 'config.json'", "    config_file.write_text('{\"name\": \"story_bot\"}')", "    ", "    # When: Agent loads config", "    agent = Agent()", "    config = agent.load_config(config_file)  # Method doesn't exist yet!", "    ", "    # Then: Config is loaded", "    assert config['name'] == 'story_bot'", "    # RUN TEST - FAILS with AttributeError: 'Agent' has no 'load_config'", "", "# PHASE 2: GREEN - Write minimal code to pass", "class Agent:", "    def load_config(self, config_path: Path) -> dict:", "        \"\"\"Load configuration from file.\"\"\"", "        return json.loads(config_path.read_text())", "    # RUN TEST - PASSES!", "", "# PHASE 3: REFACTOR - Improve while keeping tests green", "class Agent:", "    def load_config(self, config_path: Path) -> dict:", "        \"\"\"Load configuration from JSON file.\"\"\"", "        self._validate_file_exists(config_path)", "        return self._parse_json(config_path)", "    ", "    def _validate_file_exists(self, path: Path):", "        if not path.exists():", "            raise FileNotFoundError(f'Config not found: {path}')", "    ", "    def _parse_json(self, path: Path) -> dict:", "        try:", "            return json.loads(path.read_text())", "        except json.JSONDecodeError as e:", "            raise ValueError(f'Invalid JSON: {e}')", "    # RUN TEST - STILL PASSES! Code is cleaner."]}, "dont": {"description": "Write production code before tests", "content": ["# DON'T: Write production code first", "class Agent:", "    def load_config(self, config_path: Path) -> dict:", "        \"\"\"Load configuration.\"\"\"", "        # WRONG - writing code without test!", "        if not config_path.exists():", "            raise FileNotFoundError()", "        content = config_path.read_text()", "        return json.loads(content)", "    # Then write test later... BAD!", "", "# DON'T: Skip refactoring step", "class Agent:", "    def load_config(self, config_path: Path) -> dict:", "        # WRONG - test passes but code is messy", "        if not config_path.exists(): raise FileNotFoundError()", "        c = config_path.read_text()", "        try: d = json.loads(c)", "        except: raise ValueError()", "        return d", "    # Test passes but code is bad! Need refactoring step!"]}}, {"do": {"description": "Tests drive API design", "content": ["# RED: Write test that describes desired API", "def test_agent_factory_creates_configured_agent(self, tmp_path):", "    \"\"\"Factory creates agent with configuration.\"\"\"", "    # Given: Configuration exists", "    config = {'name': 'story_bot', 'workspace': str(tmp_path)}", "    ", "    # When: Factory creates agent with config", "    # Design the API we WANT through the test", "    factory = AgentFactory(workspace_root=tmp_path)", "    agent = factory.create_agent_with_config(config)", "    ", "    # Then: Agent is configured", "    assert agent.name == 'story_bot'", "    assert agent.workspace_root == tmp_path", "    # This test DESIGNS the API - clean, explicit dependencies", "", "# GREEN: Implement the API designed by test", "class AgentFactory:", "    def __init__(self, workspace_root: Path):", "        self._workspace_root = workspace_root", "    ", "    def create_agent_with_config(self, config: dict) -> Agent:", "        return Agent(", "            name=config['name'],", "            workspace_root=Path(config['workspace'])", "        )", "    # Implementation follows the design from test"]}, "dont": {"description": "Tests that adapt to bad API design", "content": ["# DON'T: Write test that accepts bad design", "def test_agent_creation(self):", "    # WRONG - test accepts global singleton pattern", "    agent = Agent.get_instance('story_bot')", "    agent.set_workspace('/tmp')  # Mutable state!", "    agent.load_config()  # Where does config come from?", "    # Test doesn't drive good design - it enables bad design!", "", "# DON'T: Implement API without thinking about tests", "class Agent:", "    _instance = None", "    ", "    @classmethod", "    def get_instance(cls, name=None):", "        # WRONG - singleton, hidden state, hard to test", "        if cls._instance is None:", "            cls._instance = Agent()", "        if name:", "            cls._instance.name = name", "        return cls._instance", "    # If you write test first, you'd never design this API!"]}}, {"do": {"description": "Write multiple tests as you add features", "content": ["# RED #1: First test - basic loading", "def test_load_config_reads_json_from_file(self, tmp_path):", "    config_file = tmp_path / 'config.json'", "    config_file.write_text('{\"name\": \"bot\"}')", "    agent = Agent()", "    config = agent.load_config(config_file)", "    assert config == {'name': 'bot'}", "", "# GREEN #1: Implement basic loading", "class Agent:", "    def load_config(self, path: Path) -> dict:", "        return json.loads(path.read_text())", "", "# RED #2: Second test - error handling", "def test_load_config_raises_when_file_missing(self):", "    agent = Agent()", "    with pytest.raises(FileNotFoundError):", "        agent.load_config(Path('missing.json'))", "", "# GREEN #2: Add error handling", "class Agent:", "    def load_config(self, path: Path) -> dict:", "        if not path.exists():", "            raise FileNotFoundError(f'Config not found: {path}')", "        return json.loads(path.read_text())", "", "# RED #3: Third test - invalid JSON", "def test_load_config_raises_when_json_invalid(self, tmp_path):", "    config_file = tmp_path / 'bad.json'", "    config_file.write_text('not json')", "    agent = Agent()", "    with pytest.raises(ValueError, match='Invalid JSON'):", "        agent.load_config(config_file)", "", "# GREEN #3: Handle invalid JSON", "class Agent:", "    def load_config(self, path: Path) -> dict:", "        if not path.exists():", "            raise FileNotFoundError(f'Config not found: {path}')", "        try:", "            return json.loads(path.read_text())", "        except json.JSONDecodeError as e:", "            raise ValueError(f'Invalid JSON: {e}')", "", "# REFACTOR: Now refactor with all tests passing", "# Each test builds on previous, tests stay green throughout"]}, "dont": {"description": "Try to handle all cases in one test", "content": ["# DON'T: One giant test for everything", "def test_load_config_everything(self, tmp_path):", "    # WRONG - testing too many scenarios at once", "    # Test 1: File missing", "    with pytest.raises(FileNotFoundError):", "        Agent().load_config(Path('missing.json'))", "    ", "    # Test 2: Invalid JSON", "    bad_file = tmp_path / 'bad.json'", "    bad_file.write_text('not json')", "    with pytest.raises(ValueError):", "        Agent().load_config(bad_file)", "    ", "    # Test 3: Valid config", "    good_file = tmp_path / 'good.json'", "    good_file.write_text('{\"name\": \"bot\"}')", "    config = Agent().load_config(good_file)", "    assert config == {'name': 'bot'}", "    ", "    # WRONG - too many scenarios! Hard to understand failure!", "    # Split into separate tests, implement incrementally!"]}}]}}, {"rule_file": "test_file_and_class_naming.json", "rule_content": {"description": "Test files are named after sub-epics (test_sub_epic_name.py) and contain all story tests for that sub-epic. Test classes are named after stories (TestStoryName). This organization keeps related tests together while maintaining clear mapping between stories and test classes.", "examples": [{"do": {"description": "Name test file after sub-epic, test classes after stories", "content": ["# File: test_generate_bot_server_and_tools.py", "# Sub-epic: Generate Bot Server And Tools", "# Contains all stories for this sub-epic", "", "\"\"\"", "Generate Bot Server And Tools Tests", "", "Tests for all stories in the 'Generate Bot Server And Tools' sub-epic:", "- Generate MCP Bot Server", "- Generate Tool Definitions", "- Register Tools With Server", "\"\"\"", "import pytest", "from pathlib import Path", "import json", "", "# ============================================================================", "# HELPER FUNCTIONS", "# ============================================================================", "", "def create_bot_config(workspace: Path, bot_name: str) -> Path:", "    \"\"\"Helper: Create bot configuration file.\"\"\"", "    config_path = workspace / 'bots' / bot_name / 'config.json'", "    config_path.parent.mkdir(parents=True, exist_ok=True)", "    config_path.write_text(json.dumps({'name': bot_name}))", "    return config_path", "", "# ============================================================================", "# FIXTURES", "# ============================================================================", "", "@pytest.fixture", "def workspace_root(tmp_path):", "    \"\"\"Fixture: Temporary workspace directory.\"\"\"", "    workspace = tmp_path / 'workspace'", "    workspace.mkdir()", "    return workspace", "", "# ============================================================================", "# STORY: Generate MCP Bot Server", "# ============================================================================", "", "class TestGenerateMCPBotServer:", "    \"\"\"Story: Generate MCP Bot Server - Tests bot server generation.\"\"\"", "    ", "    def test_server_generates_with_bot_configuration(self, workspace_root):", "        \"\"\"", "        SCENARIO: Server generates with bot configuration", "        GIVEN: Bot configuration exists", "        WHEN: Server generator is invoked", "        THEN: MCP server file is generated", "        \"\"\"", "        # Given: Bot config exists", "        bot_config = create_bot_config(workspace_root, 'test_bot')", "        ", "        # When: Generate server", "        from agile_bot.bots.base_bot.src.server_generator import ServerGenerator", "        generator = ServerGenerator(", "            bot_name='test_bot',", "            config_path=bot_config,", "            workspace_root=workspace_root", "        )", "        server_file = generator.generate_server()", "        ", "        # Then: Server file created", "        assert server_file.exists()", "        assert 'mcp_server.py' in server_file.name", "", "# ============================================================================", "# STORY: Generate Tool Definitions", "# ============================================================================", "", "class TestGenerateToolDefinitions:", "    \"\"\"Story: Generate Tool Definitions - Tests tool definition generation.\"\"\"", "    ", "    def test_tools_generated_for_each_behavior_action(self, workspace_root):", "        \"\"\"", "        SCENARIO: Tools generated for each behavior action", "        GIVEN: Bot has behaviors with actions", "        WHEN: Tool generator is invoked", "        THEN: Tool definition created for each behavior-action pair", "        \"\"\"", "        # Given: Bot with behaviors", "        bot_config = create_bot_config(workspace_root, 'test_bot')", "        ", "        # When: Generate tools", "        from agile_bot.bots.base_bot.src.tool_generator import ToolGenerator", "        generator = ToolGenerator(", "            bot_name='test_bot',", "            config_path=bot_config,", "            workspace_root=workspace_root", "        )", "        tools = generator.generate_tool_definitions()", "        ", "        # Then: Tools created", "        assert len(tools) > 0", "        assert all('name' in tool for tool in tools)", "", "# ============================================================================", "# STORY: Register Tools With Server", "# ============================================================================", "", "class TestRegisterToolsWithServer:", "    \"\"\"Story: Register Tools With Server - Tests tool registration.\"\"\"", "    ", "    def test_tools_registered_with_mcp_server(self, workspace_root):", "        \"\"\"", "        SCENARIO: Tools registered with MCP server", "        GIVEN: Tools are generated", "        WHEN: Server registration is invoked", "        THEN: Tools are registered and callable", "        \"\"\"", "        # Given: Bot and tools exist", "        bot_config = create_bot_config(workspace_root, 'test_bot')", "        ", "        # When: Register tools", "        from agile_bot.bots.base_bot.src.server_tool_registry import ServerToolRegistry", "        registry = ServerToolRegistry(", "            bot_name='test_bot',", "            workspace_root=workspace_root", "        )", "        registered_tools = registry.register_all_tools()", "        ", "        # Then: Tools registered", "        assert len(registered_tools) > 0", "        assert all(tool.is_callable for tool in registered_tools)"]}, "dont": {"description": "One file per story or unclear naming", "content": ["# DON'T: One file per story (too many files)", "# File: test_generate_mcp_bot_server.py", "class TestGenerateMCPBotServer:", "    pass", "", "# File: test_generate_tool_definitions.py", "class TestGenerateToolDefinitions:", "    pass", "", "# File: test_register_tools_with_server.py", "class TestRegisterToolsWithServer:", "    pass", "", "# WRONG: Too many files! Should be one file per sub-epic", "", "# ============================================", "", "# DON'T: Generic class names not matching stories", "# File: test_server.py", "class TestServer:", "    \"\"\"Generic name - which story is this?\"\"\"", "    pass", "", "class TestTools:", "    \"\"\"Generic name - which story is this?\"\"\"", "    pass", "", "# WRONG: Class names don't map to story names", "", "# ============================================", "", "# DON'T: Mixing sub-epics in same file", "# File: test_all_bots.py", "class TestGenerateMCPBotServer:", "    \"\"\"From sub-epic: Generate Bot Server And Tools\"\"\"", "    pass", "", "class TestInvokeBehaviorActions:", "    \"\"\"From sub-epic: Invoke Behavior Actions\"\"\"", "    pass", "", "# WRONG: Multiple sub-epics mixed! Should be separate files"]}}, {"do": {"description": "Map story hierarchy to test structure", "content": ["# Story Hierarchy:", "# Epic: Build Agile Bots", "#   Sub-epic: Generate Bot Server And Tools", "#     Story: Generate MCP Bot Server", "#     Story: Generate Tool Definitions", "#     Story: Register Tools With Server", "#   Sub-epic: Invoke Behavior Actions", "#     Story: Route Tool Call To Behavior", "#     Story: Load Action Instructions", "#     Story: Execute Behavior Action", "", "# Test File Structure:", "# test_generate_bot_server_and_tools.py", "#   class TestGenerateMCPBotServer:", "#   class TestGenerateToolDefinitions:", "#   class TestRegisterToolsWithServer:", "", "# test_invoke_behavior_actions.py", "#   class TestRouteToolCallToBehavior:", "#   class TestLoadActionInstructions:", "#   class TestExecuteBehaviorAction:", "", "# GOOD: Clear 1-to-1 mapping:", "# - Sub-epic \u2192 test file", "# - Story \u2192 test class"]}, "dont": {"description": "Unclear mapping or inconsistent structure", "content": ["# BAD: Inconsistent naming", "# test_bot_server.py  (doesn't match sub-epic name)", "#   class TestMCPServer:  (doesn't match story name)", "#   class TestTools:  (doesn't match story name)", "", "# test_behaviors.py  (doesn't match sub-epic name)", "#   class TestRouting:  (doesn't match story name)", "#   class TestInstructions:  (doesn't match story name)", "", "# WRONG: Can't easily map back to story hierarchy!"]}}, {"do": {"description": "Convert sub-epic and story names to valid identifiers", "content": ["# Sub-epic: 'Generate Bot Server And Tools'", "# File: test_generate_bot_server_and_tools.py", "# - Convert to snake_case", "# - Remove special characters", "# - Keep words that identify the sub-epic", "", "# Story: 'Generate MCP Bot Server'", "# Class: TestGenerateMCPBotServer", "# - Convert to PascalCase", "# - Keep words that identify the story", "# - Prefix with 'Test'", "", "# Story: 'Bot Loads Configuration From File'", "# Class: TestBotLoadsConfigurationFromFile", "# - Full story name in PascalCase", "# - Clear and readable", "", "# Story: 'User Creates New Story Map'", "# Class: TestUserCreatesNewStoryMap", "# - Includes actor (User) for clarity"]}, "dont": {"description": "Abbreviated or unclear names", "content": ["# DON'T: Over-abbreviate", "# Story: 'Generate MCP Bot Server'", "# Class: TestGenMCPSrv  (too abbreviated!)", "", "# DON'T: Drop important words", "# Story: 'Bot Loads Configuration From File'", "# Class: TestBotLoadsConfig  (missing 'from file'!)", "", "# DON'T: Add words not in story", "# Story: 'User Creates Story Map'", "# Class: TestUserCreatesNewStoryMapDocument  (added 'Document'!)", "", "# WRONG: Names should match stories closely!"]}}], "rationale": ["Test files organized by sub-epic keep related stories together", "One file per sub-epic prevents excessive file proliferation", "Test class names matching story names create clear traceability", "Easy to find tests: know sub-epic \u2192 find file, know story \u2192 find class", "Test structure mirrors story map hierarchy for consistency", "Developers can navigate from story map to tests intuitively", "File-per-sub-epic balances organization with manageability"], "key_principles": ["Test file name = sub-epic name in snake_case: test_sub_epic_name.py", "Test class name = EXACT story name in PascalCase: TestStoryName", "CRITICAL: Test class MUST match story name EXACTLY (not abbreviated, not generic)", "All stories in a sub-epic go in the same test file", "One test class per story (clear 1-to-1 mapping)", "File docstring lists all stories in the sub-epic", "Section headers separate stories within file (# STORY: Story Name)", "Helper functions and fixtures at top of file", "Test classes grouped by story in order they appear in story map", "BAD: TestGuardrailsInjection (generic) vs GOOD: TestInjectGuardrailsAsPartOfClarifyRequirements (exact story name)", "BAD: TestValidationRules (generic) vs GOOD: TestInjectValidationRulesForValidateRulesAction (exact story name)"], "antipatterns": ["One test file per story (too many files)", "Mixing multiple sub-epics in one file (poor organization)", "Generic test class names that don't match stories (TestGuardrailsInjection vs TestInjectGuardrailsAsPartOfClarifyRequirements)", "Abbreviated names that lose clarity (TestGenSrv vs TestGenerateServer)", "Topic-based names instead of story names (TestValidationRules vs TestInjectValidationRulesForValidateRulesAction)", "Technical names instead of story names (TestContentLoading vs TestInjectLoadRenderedContentInstructions)", "Test files named differently from sub-epics (hard to find)", "Test classes named differently from stories (hard to trace)", "No clear structure or comments separating stories in file", "CRITICAL MISTAKE: Using generic class names like TestGuardrailsInjection when story is 'Inject Guardrails as Part of Clarify Requirements'"], "file_structure_example": {"description": "Example test file structure for a sub-epic", "content": ["# File: test_sub_epic_name.py", "", "\"\"\"", "Sub-Epic Name Tests", "", "Tests for all stories in the 'Sub-Epic Name' sub-epic:", "- Story Name 1", "- Story Name 2", "- Story Name 3", "\"\"\"", "import pytest", "from pathlib import Path", "", "# ============================================================================", "# HELPER FUNCTIONS - Reusable operations", "# ============================================================================", "", "def helper_function_name(param: type) -> type:", "    \"\"\"Helper: Description of what this does.\"\"\"", "    pass", "", "# ============================================================================", "# FIXTURES - Test setup", "# ============================================================================", "", "@pytest.fixture", "def fixture_name(tmp_path):", "    \"\"\"Fixture: Description of what this provides.\"\"\"", "    pass", "", "# ============================================================================", "# STORY: Story Name 1", "# ============================================================================", "", "class TestStoryName1:", "    \"\"\"Story: Story Name 1 - Description of story.\"\"\"", "    ", "    def test_scenario_name_1(self, fixture_name):", "        \"\"\"", "        SCENARIO: Scenario description", "        GIVEN: Preconditions", "        WHEN: Action", "        THEN: Expected outcome", "        \"\"\"", "        # Test implementation", "        pass", "", "# ============================================================================", "# STORY: Story Name 2", "# ============================================================================", "", "class TestStoryName2:", "    \"\"\"Story: Story Name 2 - Description of story.\"\"\"", "    ", "    def test_scenario_name_2(self, fixture_name):", "        \"\"\"", "        SCENARIO: Scenario description", "        GIVEN: Preconditions", "        WHEN: Action", "        THEN: Expected outcome", "        \"\"\"", "        # Test implementation", "        pass"]}}}, {"rule_file": "test_observable_behavior.json", "rule_content": {"description": "Test observable behavior, not implementation details. Verify public API behavior and visible state changes. Don't assert on private methods, internal flags, or how the code works internally. Test WHAT happens, not HOW it happens. This makes tests resilient to refactoring.", "examples": [{"do": {"description": "Test observable behavior through public API", "content": ["def test_agent_creates_config_path_when_initialized(self, tmp_path):", "    \"\"\"Agent creates configuration path when initialized.\"\"\"", "    # Given", "    config = {'name': 'story_bot'}", "    ", "    # When", "    agent = Agent(agent_name='story_bot', workspace_root=tmp_path)", "    agent.initialize(config)", "    ", "    # Then - Test observable outcomes through public API", "    expected_path = tmp_path / 'agents' / 'base' / 'agent.json'", "    assert agent.config_path == expected_path  # Public property", "    assert agent.config_path.exists()  # Observable file system state", "    assert agent.is_initialized  # Public property"]}, "dont": {"description": "Test implementation details or private state", "content": ["def test_agent_initialization(self, tmp_path):", "    agent = Agent('story_bot', tmp_path)", "    agent.initialize({'name': 'bot'})", "    ", "    # DON'T: Test internal implementation details", "    assert agent._setup_called == True  # WRONG - private flag", "    assert agent._validate_config.called  # WRONG - method called", "    assert agent._internal_state == 'initialized'  # WRONG - private state", "    assert len(agent._initialization_steps) == 3  # WRONG - internal list", "    # These assertions break when you refactor!", "    # Test BEHAVIOR not IMPLEMENTATION!"]}}, {"do": {"description": "Test behavior from user perspective", "content": ["def test_agent_loads_domain_graph_when_config_provided(self, tmp_path):", "    \"\"\"Agent loads domain graph when configuration is provided.\"\"\"", "    # Given: Configuration with domain path", "    domain_file = tmp_path / 'domain_graph.json'", "    domain_file.write_text('{\"nodes\": [\"node1\"]}')", "    config = {'domain_graph_path': str(domain_file)}", "    ", "    # When: Agent initializes with config", "    agent = Agent(agent_name='story_bot', workspace_root=tmp_path)", "    agent.load_domain_graph(config)", "    ", "    # Then: Agent has loaded graph (test from user perspective)", "    assert agent.has_domain_graph  # Can user check if loaded?", "    assert agent.get_domain_nodes() == ['node1']  # Can user get nodes?", "    # Test through PUBLIC API that users would call"]}, "dont": {"description": "Test internal data structures", "content": ["def test_agent_loads_graph(self, tmp_path):", "    domain_file = tmp_path / 'graph.json'", "    domain_file.write_text('{\"nodes\": [\"n1\"]}')", "    agent = Agent('bot', tmp_path)", "    agent.load_domain_graph({'domain_graph_path': str(domain_file)})", "    ", "    # DON'T: Test internal data structures", "    assert agent._graph_data == {'nodes': ['n1']}  # WRONG - private data", "    assert agent._graph_loader.was_called  # WRONG - internal component", "    assert len(agent._node_cache) == 1  # WRONG - internal cache", "    assert agent._parser.parse_count == 1  # WRONG - internal counter", "    # If you refactor graph storage, all these tests break!", "    # Test BEHAVIOR through PUBLIC API instead!"]}}, {"do": {"description": "Test makes refactoring safe", "content": ["# Test focuses on WHAT, not HOW", "def test_config_validator_rejects_missing_name(self):", "    \"\"\"Validator rejects config missing required 'name' field.\"\"\"", "    validator = ConfigValidator()", "    result = validator.validate({'workspace': '/tmp'})", "    ", "    assert not result.is_valid", "    assert 'name' in result.error_message", "    # This test stays valid even if you completely refactor", "    # the internal validation logic!"]}, "dont": {"description": "Test couples to implementation, breaks on refactor", "content": ["# DON'T: Test implementation, breaks on refactor", "def test_validator(self):", "    validator = ConfigValidator()", "    result = validator.validate({'workspace': '/tmp'})", "    ", "    # WRONG - coupled to implementation", "    assert validator._check_name.call_count == 1  # Internal method", "    assert validator._errors == ['Missing name']  # Internal list", "    assert validator._validation_steps_completed == 5  # Internal counter", "    # Refactor validation logic \u2192 ALL THESE TESTS BREAK!", "    # Tests should NOT know HOW validation works internally!"]}}]}}, {"rule_file": "ubiquitous_language.json", "rule_content": {"description": "Use Ubiquitous Language (DDD): The SAME language EVERYWHERE - domain model, stories, acceptance criteria, scenarios, AND code. Class names = domain entities/nouns (GatherContextAction, BotConfig, Guardrails). Method names = domain responsibilities/verbs (inject_questions_and_evidence, load_and_merge_instructions). Do NOT reinvent with generic technical terms (execute, process, handle, manager, service). You may refine for finer detail, but ALWAYS preserve domain terminology.", "examples": [{"do": {"description": "Class names from domain model entities/nouns", "content": ["# Domain Model Entity: 'Gather Context Action'", "class GatherContextAction:", "    pass", "", "# Domain Model Entity: 'Build Knowledge Action'", "class BuildKnowledgeAction:", "    pass", "", "# Domain Model Entity: 'Validate Rules Action'", "class ValidateRulesAction:", "    pass", "", "# Story/AC Noun: 'MCP Server Generator'", "class MCPServerGenerator:", "    pass", "", "# Story/AC Noun: 'Tool Generator'", "class ToolGenerator:", "    pass", "", "# Story/AC Noun: 'Bot Config'", "class BotConfig:", "    pass", "", "# Story/AC Noun: 'Guardrails'", "class Guardrails:", "    pass", "", "# GOOD: Classes use exact nouns from domain model and stories"]}, "dont": {"description": "Generic technical class names", "content": ["# DON'T: Generic technical names", "class Action:  # Which action? Use specific domain name!", "    pass", "", "class Loader:  # What does it load? Use domain noun!", "    pass", "", "class Handler:  # What does it handle? Use domain entity!", "    pass", "", "class Manager:  # What does it manage? Use domain term!", "    pass", "", "class Service:  # What service? Use domain language!", "    pass", "", "class Processor:  # What does it process? Use domain entity!", "    pass", "", "# WRONG: Generic technical terms instead of domain language"]}}, {"do": {"description": "Method names from domain responsibilities and story steps", "content": ["# Domain Model Responsibility: 'Inject gather context instructions: Behavior, Guardrails, Required Clarifications'", "", "class GatherContextAction:", "    def inject_guardrails_into_instructions(self) -> Instructions:", "        \"\"\"Inject guardrails into gather context instructions.\"\"\"", "        pass", "", "# Story AC: 'WHEN Action loads guardrails THEN guardrails are injected into instructions'", "# Uses 'inject' from AC, 'guardrails' from domain, 'instructions' from AC", "", "# Domain Model Responsibility: 'Load and merge base and behavior instructions'", "", "class GatherContextAction:", "    def load_and_merge_instructions(self) -> Instructions:", "        \"\"\"Load and merge base and behavior-specific instructions.\"\"\"", "        pass", "", "# Scenario Step: 'Generator loads trigger words from behavior folder'", "", "class ToolGenerator:", "    def load_trigger_words_from_behavior_folder(self, behavior: str) -> List[str]:", "        \"\"\"Load trigger words from behavior folder.\"\"\"", "        pass", "", "# Scenario Step: 'Tool routes to correct behavior action'", "", "class Tool:", "    def route_to_behavior_action(self, bot) -> Result:", "        \"\"\"Route invocation to correct behavior action.\"\"\"", "        pass", "", "# GOOD: Methods use exact domain/story language:", "# - 'inject', 'load', 'merge', 'route' are domain verbs", "# - 'guardrails', 'instructions', 'trigger words', 'behavior' are domain nouns"]}, "dont": {"description": "Generic technical method names", "content": ["# DON'T: Generic execute/process/handle methods", "", "class GatherContextAction:", "    def execute_with_guardrails(self):  # 'execute_with' not in domain!", "        pass", "    ", "    def execute_with_rendered_content(self):  # Generic technical pattern!", "        pass", "    ", "    def get_instructions_with_templates(self):  # 'get_with' not in domain!", "        pass", "    ", "    def process(self):  # What does it process? Use domain verb!", "        pass", "    ", "    def handle_request(self):  # 'handle' not in domain!", "        pass", "", "# DON'T: Made-up verbs not in domain", "", "class ToolGenerator:", "    def fetch_patterns(self):  # Domain says 'load trigger words'!", "        pass", "    ", "    def retrieve_config(self):  # Domain says 'load' not 'retrieve'!", "        pass", "", "# WRONG: Using generic technical terms instead of domain language"]}}, {"do": {"description": "Refine while preserving ubiquitous language", "content": ["# Domain Responsibility: 'Inject guardrails'", "# Refined into specific methods using domain terms:", "", "class GatherContextAction:", "    def inject_key_questions_into_instructions(self) -> Instructions:", "        \"\"\"Inject key questions guardrails into instructions.\"\"\"", "        # 'inject', 'key questions', 'guardrails', 'instructions' all from domain", "        pass", "    ", "    def inject_evidence_into_instructions(self) -> Instructions:", "        \"\"\"Inject evidence guardrails into instructions.\"\"\"", "        # 'inject', 'evidence', 'guardrails', 'instructions' all from domain", "        pass", "", "# Domain Responsibility: 'Merge validation rules'", "# Refined into specific steps:", "", "class ValidateRulesAction:", "    def load_common_validation_rules(self) -> List[Rule]:", "        # 'load', 'common', 'validation rules' from domain", "        pass", "    ", "    def load_behavior_validation_rules(self) -> List[Rule]:", "        # 'load', 'behavior', 'validation rules' from domain", "        pass", "    ", "    def merge_validation_rules(self, common, behavior) -> List[Rule]:", "        # 'merge', 'validation rules' from domain", "        pass", "", "# GOOD: Refinement preserves all domain terminology"]}, "dont": {"description": "Losing ubiquitous language during refinement", "content": ["# Domain: 'Inject guardrails'", "# DON'T: Lose domain terms", "", "class GatherContextAction:", "    def add_metadata(self):  # Lost 'inject' and 'guardrails'!", "        pass", "    ", "    def populate_config(self):  # Lost all domain language!", "        pass", "    ", "    def enhance_instructions(self):  # 'enhance' not in domain!", "        pass", "", "# Domain: 'Merge validation rules'", "# DON'T: Use generic verbs", "", "class ValidateRulesAction:", "    def combine_rules(self):  # Domain says 'merge' not 'combine'!", "        pass", "    ", "    def fetch_all_rules(self):  # Domain says 'load' not 'fetch'!", "        pass", "", "# WRONG: Lost ubiquitous language during refinement"]}}], "rationale": ["Ubiquitous Language is core DDD principle - same vocabulary in domain, stories, and code", "Business stakeholders can read and understand code using familiar terms", "Eliminates translation between business language and technical language", "Makes traceability between stories, domain model, and code obvious", "Reduces cognitive load - one vocabulary for entire team", "Domain language is more precise than generic technical terms", "Code becomes living documentation using business language", "Consistency across domain model, stories, tests, and production code"], "key_principles": ["USE UBIQUITOUS LANGUAGE: Same terms in domain model, stories, AC, scenarios, AND code", "Class names = domain entities/nouns (GatherContextAction, BotConfig, Guardrails)", "Method names = domain responsibilities/verbs (inject, load, merge, route)", "Consult domain model FIRST when naming classes and methods", "Consult stories/AC/scenarios SECOND for behavioral language", "Preserve domain terms when refining to finer detail", "Do NOT use generic technical terms (execute, process, handle, manager, service)", "Do NOT replace domain terms with synonyms", "Code should read like the domain model and stories", "When in doubt, use exact phrase from domain model or story"], "antipatterns": ["Generic class names: Action, Loader, Handler, Manager, Service, Processor", "Generic method names: execute, process, handle, perform, run", "execute_with_X pattern instead of domain verbs", "get/set when domain uses specific verbs (load, inject, merge, route)", "Made-up terms not in domain model or stories", "Synonyms of domain terms ('fetch' instead of 'load', 'combine' instead of 'merge')", "Technical jargon over business language", "Losing domain language during code refinement"], "sources_for_naming": {"classes": ["Domain Model entities (exact nouns)", "Domain Model aggregates and value objects", "Story nouns and entities (MCP Server Generator, Tool Generator, Bot Config)", "Acceptance criteria entities"], "methods": ["Domain Model responsibilities (exact verbs and phrases)", "Story acceptance criteria (WHEN/THEN language)", "Scenario steps (Given/When/Then phrases)", "Domain operations and behaviors"], "allowed_refinement": ["Break responsibilities into smaller methods using domain terms", "Add specificity using domain language (e.g., 'inject_key_questions' from 'inject_guardrails')", "Make relationships explicit using domain nouns (e.g., 'from_behavior_folder')"], "not_allowed": ["Generic technical terms: execute, process, handle, perform, manage, service", "Synonyms of domain terms unless they appear in domain model", "New abstractions not in domain model", "Framework/library terminology over domain terms", "Marketing/buzzword names instead of domain names"]}}}, {"rule_file": "use_arrange_act_assert.json", "rule_content": {"description": "Use Given-When-Then (Arrange-Act-Assert) structure in tests. Each test should have clear Given (setup), When (action), Then (verify) sections with comments. Keep each section focused and under 5 lines. Extract complex setup into helper functions.", "examples": [{"do": {"description": "Clear Given-When-Then structure", "content": ["def test_agent_initializes_with_base_config(self, workspace_root):", "    \"\"\"Agent initializes with base configuration when config exists.\"\"\"", "    # Given: Base configuration exists", "    config_path = create_base_config(workspace_root, name='story_bot')", "    ", "    # When: Agent is initialized", "    agent = Agent(agent_name='story_bot', workspace_root=workspace_root)", "    ", "    # Then: Agent has correct configuration path", "    assert agent.config_path == config_path", "    assert agent.config_path.exists()"]}, "dont": {"description": "Missing structure or mixed concerns", "content": ["# DON'T: No clear sections", "def test_agent(self):", "    config_path = Path('config.json')", "    config_path.write_text('{}')", "    agent = Agent('bot')", "    assert agent.config_path == config_path", "    agent.initialize()", "    assert agent.initialized", "    # WRONG - no clear Given/When/Then, mixed actions", "", "# DON'T: Sections too long (over 5 lines)", "def test_agent_setup(self):", "    # Given - TOO LONG", "    workspace = Path('workspace')", "    workspace.mkdir()", "    config = workspace / 'config.json'", "    config.write_text('{\"name\": \"bot\"}')", "    data = workspace / 'data'", "    data.mkdir()", "    # Extract to helper function!"]}}, {"do": {"description": "Extract complex setup to helpers", "content": ["# Helper function", "def create_workspace_with_config(tmp_path, agent_name):", "    workspace = tmp_path / 'workspace'", "    workspace.mkdir()", "    config_path = workspace / 'config.json'", "    config_path.write_text(f'{{\"name\": \"{agent_name}\"}}')", "    return workspace, config_path", "", "# Clean test using helper", "def test_agent_loads_config(self, tmp_path):", "    # Given", "    workspace, config_path = create_workspace_with_config(tmp_path, 'story_bot')", "    ", "    # When", "    agent = Agent.from_config(config_path)", "    ", "    # Then", "    assert agent.name == 'story_bot'"]}, "dont": {"description": "Inline complex setup in test", "content": ["def test_agent(self, tmp_path):", "    # DON'T: Complex setup inline (should be helper)", "    workspace = tmp_path / 'workspace'", "    workspace.mkdir()", "    agents_dir = workspace / 'agents'", "    agents_dir.mkdir()", "    base_dir = agents_dir / 'base'", "    base_dir.mkdir()", "    config = base_dir / 'config.json'", "    config.write_text('{\"name\": \"bot\"}')", "    # Use helper function instead!"]}}]}}, {"rule_file": "use_ascii_only.json", "rule_content": {"description": "All test code must use ASCII-only characters. No Unicode symbols, emojis, or special characters in test code, assertions, print statements, or output messages. Use plain ASCII alternatives like [PASS], [ERROR], [FAIL].", "examples": [{"do": {"description": "ASCII-only characters", "content": ["print(\"[PASS] Agent initialized successfully\")", "print(\"[ERROR] Configuration file not found\")", "assert result.status == \"success\"", "assert result.message == \"Agent initialized\""]}, "dont": {"description": "Unicode characters", "content": ["print(\"\u2713 Agent initialized\")  # WRONG - Unicode checkmark", "print(\"\u2705 Configuration loaded\")  # WRONG - Emoji", "print(\"\u2192 Next step\")  # WRONG - Unicode arrow", "assert result.status == \"\u2713\"  # WRONG - Unicode in assertions"]}}]}}, {"rule_file": "use_class_based_organization.json", "rule_content": {"description": "Use class-based organization with pytest orchestrator pattern. Test classes match story names exactly (Test<ExactStoryName>), test methods match scenario names exactly (test_<scenario_name_snake_case>). Helper functions/fixtures provide reusable operations. Keep tests under 20 lines, helpers under 20 lines, classes under 300 lines.", "rationale": ["Class-based organization groups related scenarios by story, making it easy to find all tests for a specific story", "Test classes named after stories provide 1-to-1 traceability with story map", "Test methods named after scenarios provide 1-to-1 traceability with story scenarios", "Orchestrator pattern keeps test methods readable and focused on flow, not implementation details", "Helper functions extract complex setup, keeping tests under 20 lines and readable", "File structure mirrors story map hierarchy: sub-epic \u2192 file, story \u2192 class, scenario \u2192 method"], "examples": [{"do": {"description": "Class matches story name exactly, methods match scenario names exactly", "content": ["# File: test_generate_bot_server_and_tools.py", "# Sub-epic: Generate Bot Server And Tools", "", "# ============================================================================", "# HELPER FUNCTIONS - Reusable operations (under 20 lines each)", "# ============================================================================", "", "def create_bot_config(workspace: Path, bot_name: str) -> Path:", "    \"\"\"Helper: Create bot configuration file.\"\"\"", "    config_path = workspace / 'bots' / bot_name / 'config.json'", "    config_path.parent.mkdir(parents=True, exist_ok=True)", "    config_path.write_text(json.dumps({'name': bot_name}))", "    return config_path", "", "# ============================================================================", "# STORY: Generate Bot Tools", "# ============================================================================", "", "class TestGenerateBotTools:", "    \"\"\"Story: Generate Bot Tools - Tests bot tool generation.\"\"\"", "    ", "    def test_generator_creates_bot_tool_for_test_bot(self, workspace_root):", "        \"\"\"", "        SCENARIO: Generator creates bot tool for test_bot", "        GIVEN: Bot configuration exists", "        WHEN: Generator processes Bot Config", "        THEN: Generator creates bot tool instance", "        \"\"\"", "        # Given: Bot config exists", "        bot_config = create_bot_config(workspace_root, 'test_bot')", "        ", "        # When: Call REAL Generator API", "        from agile_bot.bots.base_bot.src.tool_generator import ToolGenerator", "        generator = ToolGenerator(bot_name='test_bot', config_path=bot_config, workspace_root=workspace_root)", "        tool = generator.generate_bot_tool()", "        ", "        # Then: Tool created", "        assert tool.name == 'test_bot_bot'", "", "    def test_generator_creates_tool_with_correct_parameters(self, workspace_root):", "        \"\"\"", "        SCENARIO: Generator creates tool with correct parameters", "        GIVEN: Bot configuration exists", "        WHEN: Generator processes Bot Config", "        THEN: Tool has correct behavior and action parameters", "        \"\"\"", "        # Given: Bot config exists", "        bot_config = create_bot_config(workspace_root, 'test_bot')", "        ", "        # When: Generate tool", "        from agile_bot.bots.base_bot.src.tool_generator import ToolGenerator", "        generator = ToolGenerator(bot_name='test_bot', config_path=bot_config, workspace_root=workspace_root)", "        tool = generator.generate_bot_tool()", "        ", "        # Then: Tool has correct parameters", "        assert 'bot_name' in tool.parameters", "        assert tool.parameters['bot_name'] == 'test_bot'", "", "# ============================================================================", "# STORY: Generate Behavior Tools", "# ============================================================================", "", "class TestGenerateBehaviorTools:", "    \"\"\"Story: Generate Behavior Tools - Tests behavior tool generation.\"\"\"", "    ", "    def test_generator_creates_behavior_tool_for_each_behavior(self, workspace_root):", "        \"\"\"", "        SCENARIO: Generator creates behavior tool for each behavior", "        GIVEN: Bot has multiple behaviors", "        WHEN: Generator processes Bot Config", "        THEN: Generator creates one tool per behavior", "        \"\"\"", "        # Given: Bot with behaviors", "        bot_config = create_bot_config(workspace_root, 'test_bot', behaviors=['shape', 'discovery'])", "        ", "        # When: Generate tools", "        from agile_bot.bots.base_bot.src.tool_generator import ToolGenerator", "        generator = ToolGenerator(bot_name='test_bot', config_path=bot_config, workspace_root=workspace_root)", "        tools = generator.generate_behavior_tools()", "        ", "        # Then: Tools created", "        assert len(tools) == 2", "        assert any(tool.name == 'test_bot_shape' for tool in tools)", "        assert any(tool.name == 'test_bot_discovery' for tool in tools)"]}, "dont": {"description": "Generic class names or abbreviated method names", "content": ["# DON'T: Generic class names not matching story", "class TestToolGeneration:  # WRONG - story is 'Generate Bot Tools'", "    \"\"\"Generic name - which story is this?\"\"\"", "    pass", "", "# DON'T: Abbreviated class names", "class TestGenBotTools:  # WRONG - story is 'Generate Bot Tools'", "    pass", "", "# DON'T: Abbreviated method names", "def test_creates_tool(self):  # WRONG - scenario is 'Generator creates bot tool for test_bot'", "    pass", "", "# DON'T: Generic method names", "def test_tool_generation(self):  # WRONG - doesn't match scenario name", "    pass", "", "# DON'T: Numbered scenarios", "def test_scenario_1(self):  # WRONG - not descriptive, doesn't match scenario", "    pass", "", "# DON'T: Tests over 20 lines (extract to helpers)", "def test_generator_creates_bot_tool(self, workspace_root):", "    # Given: 10 lines of complex setup...", "    # When: 5 lines of action...", "    # Then: 10 lines of verification...", "    # WRONG: Extract setup to helper function!"]}}, {"do": {"description": "File structure mirrors story map hierarchy", "content": ["# Story Map Structure:", "# Epic: Build Agile Bots", "#   Sub-epic: Generate Bot Server And Tools", "#     Story: Generate Bot Tools", "#       Scenario: Generator creates bot tool for test_bot", "#       Scenario: Generator creates tool with correct parameters", "#     Story: Generate Behavior Tools", "#       Scenario: Generator creates behavior tool for each behavior", "", "# Test File Structure:", "# File: test_generate_bot_server_and_tools.py  (matches sub-epic)", "#   class TestGenerateBotTools:  (matches story exactly)", "#     def test_generator_creates_bot_tool_for_test_bot(...):  (matches scenario exactly)", "#     def test_generator_creates_tool_with_correct_parameters(...):  (matches scenario exactly)", "#   class TestGenerateBehaviorTools:  (matches story exactly)", "#     def test_generator_creates_behavior_tool_for_each_behavior(...):  (matches scenario exactly)", "", "# GOOD: Clear 1-to-1 mapping:", "# - Sub-epic \u2192 test file", "# - Story \u2192 test class (EXACT name match)", "# - Scenario \u2192 test method (EXACT name match)"]}, "dont": {"description": "Unclear mapping or inconsistent structure", "content": ["# BAD: Inconsistent naming", "# File: test_bot_tools.py  (doesn't match sub-epic 'Generate Bot Server And Tools')", "#   class TestToolGen:  (doesn't match story 'Generate Bot Tools')", "#     def test_creates_tool(self):  (doesn't match scenario 'Generator creates bot tool for test_bot')", "", "# BAD: Multiple stories in wrong order", "#   class TestGenerateBehaviorTools:  (should be second)", "#   class TestGenerateBotTools:  (should be first)", "", "# WRONG: Can't easily map back to story map!"]}}, {"do": {"description": "Helper functions keep tests under 20 lines", "content": ["# Helper function (under 20 lines)", "def create_bot_with_behaviors(workspace_root: Path, bot_name: str, behaviors: list) -> tuple[Path, Bot]:", "    \"\"\"Helper: Create bot configuration with behaviors and return bot instance.\"\"\"", "    config_path = workspace_root / 'bots' / bot_name / 'config.json'", "    config_path.parent.mkdir(parents=True, exist_ok=True)", "    config = {'name': bot_name, 'behaviors': behaviors}", "    config_path.write_text(json.dumps(config))", "    ", "    from agile_bot.bots.base_bot.src.bot.bot import Bot", "    bot = Bot(bot_name=bot_name, workspace_root=workspace_root, config_path=config_path)", "    return config_path, bot", "", "# Test method (under 20 lines)", "def test_generator_creates_bot_tool_for_test_bot(self, workspace_root):", "    \"\"\"", "    SCENARIO: Generator creates bot tool for test_bot", "    GIVEN: Bot configuration exists", "    WHEN: Generator processes Bot Config", "    THEN: Generator creates bot tool instance", "    \"\"\"", "    # Given: Bot config exists (using helper)", "    config_path, bot = create_bot_with_behaviors(workspace_root, 'test_bot', ['shape'])", "    ", "    # When: Generate tool", "    from agile_bot.bots.base_bot.src.tool_generator import ToolGenerator", "    generator = ToolGenerator(bot_name='test_bot', config_path=config_path, workspace_root=workspace_root)", "    tool = generator.generate_bot_tool()", "    ", "    # Then: Tool created", "    assert tool.name == 'test_bot_bot'"]}, "dont": {"description": "Long test methods with inline complex setup", "content": ["# DON'T: Test method over 20 lines", "def test_generator_creates_bot_tool(self, workspace_root):", "    # Given: Complex setup inline (10+ lines)", "    workspace = workspace_root / 'workspace'", "    workspace.mkdir()", "    bots_dir = workspace / 'bots'", "    bots_dir.mkdir()", "    bot_dir = bots_dir / 'test_bot'", "    bot_dir.mkdir()", "    config_dir = bot_dir / 'config'", "    config_dir.mkdir()", "    config_file = config_dir / 'bot_config.json'", "    config = {'name': 'test_bot', 'behaviors': ['shape']}", "    config_file.write_text(json.dumps(config))", "    # ... more setup ...", "    ", "    # When: Action (5 lines)", "    # ...", "    ", "    # Then: Verification (10+ lines)", "    # ...", "    ", "    # WRONG: Extract setup to helper function!"]}}, {"do": {"description": "Test classes ordered by story map sequence", "content": ["# Story Map Order:", "# 1. Generate Bot Tools", "# 2. Generate Behavior Tools", "# 3. Generate MCP Bot Server", "", "# Test File Order (matches story map):", "class TestGenerateBotTools:  # First story", "    \"\"\"Story: Generate Bot Tools\"\"\"", "    pass", "", "class TestGenerateBehaviorTools:  # Second story", "    \"\"\"Story: Generate Behavior Tools\"\"\"", "    pass", "", "class TestGenerateMCPBotServer:  # Third story", "    \"\"\"Story: Generate MCP Bot Server\"\"\"", "    pass", "", "# GOOD: File reads like story map!"]}, "dont": {"description": "Test classes out of order", "content": ["# DON'T: Classes out of story map order", "class TestGenerateMCPBotServer:  # Should be third, not first!", "    pass", "", "class TestGenerateBotTools:  # Should be first!", "    pass", "", "class TestGenerateBehaviorTools:  # Should be second!", "    pass", "", "# WRONG: Can't follow story map order!"]}}], "key_principles": ["Test class name = EXACT story name in PascalCase: Test<ExactStoryName>", "Test method name = EXACT scenario name in snake_case: test_<scenario_name_snake_case>", "Test classes appear in same order as stories in story map", "One test class per story (exact 1-to-1 mapping)", "One test method per scenario (exact 1-to-1 mapping)", "Test methods under 20 lines (extract complex setup to helpers)", "Helper functions under 20 lines each", "Test classes under 300 lines (split if too large)", "Use orchestrator pattern: test methods show flow, helpers handle details", "File structure mirrors story map: sub-epic \u2192 file, story \u2192 class, scenario \u2192 method"], "antipatterns": ["Generic class names not matching story names (TestToolGeneration vs TestGenerateBotTools)", "Abbreviated class names (TestGenBotTools vs TestGenerateBotTools)", "Abbreviated method names (test_creates_tool vs test_generator_creates_bot_tool_for_test_bot)", "Generic method names (test_tool_generation vs test_generator_creates_bot_tool_for_test_bot)", "Numbered scenarios (test_scenario_1 vs test_generator_creates_bot_tool_for_test_bot)", "Test methods over 20 lines (extract setup to helpers)", "Helper functions over 20 lines (split into smaller helpers)", "Test classes over 300 lines (split into multiple classes or files)", "Test classes out of story map order", "Unclear mapping between story map and test structure"]}}, {"rule_file": "use_descriptive_function_names.json", "rule_content": {"description": "Use intention-revealing names that describe behavior, not implementation. Test names should describe WHAT happens WHEN. Helper names should describe their single responsibility. Follow clean code naming: searchable, pronounceable, one word per concept.", "examples": [{"do": {"description": "Descriptive behavior-focused names", "content": ["# Test names: test_<behavior>_when_<condition>", "def test_agent_initializes_with_base_config_when_config_exists(self):", "    pass", "", "def test_agent_loads_behavior_graph_when_domain_structure_available(self):", "    pass", "", "# Helper names: <verb>_<noun> that reveals purpose", "def create_agent_with_config(name: str, config: dict) -> Agent:", "    pass", "", "def verify_config_path_exists(agent: Agent, expected_path: Path):", "    pass"]}, "dont": {"description": "Abbreviated, vague, or implementation-focused names", "content": ["# DON'T: Abbreviated or cryptic", "def test_agt_init(self):  # WRONG - abbreviated", "def test1(self):  # WRONG - meaningless", "def test_xyz(self):  # WRONG - non-descriptive", "", "# DON'T: Implementation-focused instead of behavior", "def test_constructor_sets_variables(self):  # WRONG - how, not what", "def test_calls_setup_method(self):  # WRONG - implementation", "", "# DON'T: Vague helper names", "def setup(data):  # WRONG - setup what?", "def do_thing(obj):  # WRONG - what thing?", "def handler(ctx):  # WRONG - handles what?"]}}, {"do": {"description": "Consistent vocabulary across codebase", "content": ["# Pick ONE word per concept and use consistently:", "def create_agent(...)  # Use 'create' everywhere", "def create_config(...)", "def create_workspace(...)", "", "def verify_path_exists(...)  # Use 'verify' for assertions", "def verify_config_valid(...)", "def verify_agent_initialized(...)"]}, "dont": {"description": "Mixing synonyms for same concept", "content": ["# DON'T: Mix create/build/make/construct", "def create_agent(...)", "def build_config(...)  # WRONG - inconsistent with 'create'", "def make_workspace(...)  # WRONG - use 'create'", "", "# DON'T: Mix verify/check/assert/validate randomly", "def verify_path(...)", "def check_config(...)  # WRONG - use 'verify'", "def assert_agent(...)  # WRONG - use 'verify'"]}}]}}, {"rule_file": "use_exact_variable_names.json", "rule_content": {"description": "Use exact variable names from specification scenarios. When specification mentions specific variables (agent_name, workspace_root, config_path), use those exact names in tests and production code. Consistency in naming makes tests match specification exactly.", "examples": [{"do": {"description": "Exact variable names matching specification", "content": ["# Specification mentions: agent_name='story_bot', workspace_root, config_path", "", "# Test uses exact names from specification", "def test_agent_initializes_with_config(self, workspace_root):", "    # Given", "    agent_name = 'story_bot'  # Exact name from spec", "    config_path = workspace_root / 'config.json'  # Exact name from spec", "    ", "    # When", "    agent = Agent(agent_name=agent_name, workspace_root=workspace_root)", "    agent.initialize(config_path)", "    ", "    # Then", "    assert agent.config_path == config_path  # Exact property name from spec", "", "# Production code uses same names", "class Agent:", "    def __init__(self, agent_name: str, workspace_root: Path):", "        self.agent_name = agent_name  # Exact name from spec", "        self.workspace_root = workspace_root  # Exact name from spec", "        self.config_path = None  # Exact name from spec"]}, "dont": {"description": "Different variable names than specification", "content": ["# DON'T: Use different names than specification", "# Specification says: agent_name, workspace_root, config_path", "", "def test_agent_init(self, tmp_path):", "    # WRONG: Different names than specification", "    name = 'story_bot'  # Should be: agent_name", "    root = tmp_path  # Should be: workspace_root", "    cfg_path = root / 'config.json'  # Should be: config_path", "    ", "    agent = Agent(name=name, root=root)  # WRONG", "    agent.initialize(cfg_path)  # WRONG", "", "# DON'T: Production code with different names", "class Agent:", "    def __init__(self, name: str, root: Path):  # WRONG", "        self.name = name  # Should be: agent_name", "        self.root = root  # Should be: workspace_root", "        self.cfg = None  # Should be: config_path"]}}, {"do": {"description": "Consistent naming across test and production", "content": ["# Specification: Agent loads domain_graph from domain_graph_path", "", "# Test uses exact specification terminology", "def test_agent_loads_domain_graph(self, workspace_root):", "    domain_graph_path = workspace_root / 'domain_graph.json'", "    agent = Agent('bot', workspace_root)", "    agent.load_domain_graph(domain_graph_path)", "    assert agent.domain_graph is not None", "", "# Production code matches specification exactly", "class Agent:", "    def load_domain_graph(self, domain_graph_path: Path):", "        self.domain_graph = json.loads(domain_graph_path.read_text())"]}, "dont": {"description": "Inconsistent naming causes confusion", "content": ["# DON'T: Mix different terms for same concept", "# Specification says: domain_graph_path, domain_graph", "", "def test_agent_loads_graph(self, workspace_root):", "    graph_file = workspace_root / 'graph.json'  # WRONG: not 'domain_graph_path'", "    agent = Agent('bot', workspace_root)", "    agent.load_domain_graph(graph_file)", "    assert agent.graph is not None  # WRONG: should be 'domain_graph'", "", "class Agent:", "    def load_domain_graph(self, path: Path):  # WRONG: vague 'path'", "        self.graph = json.loads(path.read_text())  # WRONG: not 'domain_graph'"]}}]}}, {"rule_file": "use_real_implementations.json", "rule_content": {"description": "Use real implementations by default. Only mock when explicitly asked or for uncontrollable external dependencies (network APIs, external services). Create real files in temporary test workspace using pytest tmp_path fixture. Don't mock file operations - use real temp files instead.", "examples": [{"do": {"description": "Real implementation with temporary test files", "content": ["def test_agent_loads_config_from_file(self, tmp_path):", "    \"\"\"Agent loads configuration from real file.\"\"\"", "    # Given: Create REAL file in temp workspace", "    config_path = tmp_path / 'agents' / 'base' / 'agent.json'", "    config_path.parent.mkdir(parents=True, exist_ok=True)", "    config_path.write_text('{\"name\": \"story_bot\"}')", "    ", "    # When: Agent loads from REAL file", "    agent = Agent('story_bot', tmp_path)", "    agent.load_config(config_path)", "    ", "    # Then: Config loaded from REAL file I/O", "    assert agent.name == 'story_bot'", "    # No mocking! Real file operations!"]}, "dont": {"description": "Mocking file operations when real files work", "content": ["def test_agent_loads_config(self):", "    # DON'T: Mock file operations when temp files work", "    with patch('pathlib.Path.exists', return_value=True):", "        with patch('pathlib.Path.read_text', return_value='{\"name\": \"bot\"}'):", "            agent = Agent('bot', Path('/fake'))", "            agent.load_config(Path('fake.json'))", "    # WRONG: Use real temp files instead!"]}}, {"do": {"description": "Mock only truly external dependencies", "content": ["def test_agent_fetches_remote_config(self):", "    \"\"\"Agent fetches configuration from remote API.\"\"\"", "    # Given: Mock EXTERNAL network call (can't control)", "    with patch('requests.get') as mock_get:", "        mock_get.return_value.json.return_value = {'name': 'bot'}", "        ", "        # When: Agent fetches from API", "        agent = Agent.from_remote_config('http://api.example.com/config')", "        ", "        # Then: Config loaded", "        assert agent.name == 'bot'", "    # OK to mock: External service we don't control", "", "def test_agent_sends_metrics(self):", "    \"\"\"Agent sends metrics to monitoring service.\"\"\"", "    # Given: Mock EXTERNAL metrics service", "    with patch('monitoring.send_metric') as mock_send:", "        agent = Agent('bot', Path('/tmp'))", "        ", "        # When: Agent performs action that sends metrics", "        agent.initialize()", "        ", "        # Then: Metrics sent", "        mock_send.assert_called_once()", "    # OK to mock: External monitoring service"]}, "dont": {"description": "Mock internal business logic or testable I/O", "content": ["def test_agent_initialization(self):", "    # DON'T: Mock the class under test", "    agent = Mock(spec=Agent)  # WRONG - defeats purpose!", "    agent.initialize()", "    ", "    # DON'T: Mock internal business logic", "    with patch.object(Agent, 'validate_config') as mock_validate:", "        agent = Agent('bot', Path('/tmp'))", "        agent.initialize()", "        # WRONG - test the validation logic, don't mock it!", "    ", "    # DON'T: Mock file operations when you can use real files", "    with patch('json.loads') as mock_json:", "        # WRONG - use real temp files and real json.loads!"]}}, {"do": {"description": "Use pytest fixtures for real test data", "content": ["@pytest.fixture", "def config_file(tmp_path):", "    \"\"\"Fixture: Real configuration file.\"\"\"", "    config_path = tmp_path / 'config.json'", "    config_path.write_text('{\"name\": \"story_bot\"}')", "    return config_path", "", "@pytest.fixture", "def workspace_with_config(tmp_path):", "    \"\"\"Fixture: Real workspace with config.\"\"\"", "    workspace = tmp_path / 'workspace'", "    workspace.mkdir()", "    config_dir = workspace / 'agents' / 'base'", "    config_dir.mkdir(parents=True)", "    (config_dir / 'agent.json').write_text('{\"name\": \"bot\"}')", "    return workspace", "", "class TestAgent:", "    def test_loads_from_workspace(self, workspace_with_config):", "        # Use REAL workspace fixture", "        agent = Agent('bot', workspace_with_config)", "        agent.initialize()", "        assert agent.is_initialized"]}, "dont": {"description": "Mock fixtures instead of creating real data", "content": ["@pytest.fixture", "def config_file():", "    \"\"\"DON'T: Mock fixture instead of real file.\"\"\"", "    mock_file = Mock(spec=Path)", "    mock_file.exists.return_value = True", "    mock_file.read_text.return_value = '{\"name\": \"bot\"}'", "    return mock_file  # WRONG - create real temp file!"]}}]}}], "content_to_validate": {"project_location": "C:\\dev\\augmented-teams\\demo\\mob_minion", "rendered_outputs": ["C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-description.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\mob-minion-domain-model-diagram.md", "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\story-graph.json"], "clarification_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\clarification.json", "planning_file": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\planning.json", "report_path": "C:\\dev\\augmented-teams\\demo\\mob_minion\\docs\\stories\\validation-report.md"}}}}, "109": {"action_state": "story_bot.8_code.gather_context", "status": "started", "timestamp": "2025-12-10T01:30:43.617581"}, "110": {"action_state": "story_bot.8_code.gather_context", "status": "completed", "timestamp": "2025-12-10T01:30:43.642583", "outputs": {"instructions": {"action": "gather_context", "behavior": "8_code", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["What programming language specialization should be used? (python, javascript, or both)", "What is the target file or module name and location?", "What are the main functions, features, or capabilities that need to be implemented?", "What are the major domain objects, entities, or data structures involved?", "What programming paradigm should be used: functional programming, object-oriented programming, or a hybrid approach?", "How should the code be organized into layers or modules? (e.g., domain layer, service layer, presentation layer, data access layer)", "What are the key responsibilities and behaviors of each major component?", "What dependencies exist between components, modules, or external systems?", "Are there any existing code patterns, architectural styles, or design patterns to follow?", "What inputs are available from previous phases? (Check for: story documents, domain maps, BDD test files, existing code structure)", "What are the integration points with existing code or external systems?", "What error handling and validation requirements exist?", "What are the performance, scalability, or resource constraints?", "Are there any language-specific idioms, patterns, or conventions that must be respected?"], "evidence": ["User stories or story documents (from story writing phase)", "Domain maps or domain model documents (from DDD documentation)", "BDD test files or test specifications (from BDD or TDD tests)", "Existing source code files", "API specifications or interface definitions", "Architecture diagrams, design documents / diagrams, or Architecture templates", "Code style guides or conventions", "Project documentation", "Previous code reviews or feedback", "Team coding standards", "Language-specific style guides (PEP 8, Airbnb JS, etc.)"]}}}}, "111": {"action_state": "story_bot.8_code.gather_context", "status": "started", "timestamp": "2025-12-10T01:30:43.979412"}, "112": {"action_state": "story_bot.8_code.gather_context", "status": "completed", "timestamp": "2025-12-10T01:30:44.000640", "outputs": {"instructions": {"action": "gather_context", "behavior": "8_code", "base_instructions": ["Instruction for gather_context"], "guardrails": {"key_questions": ["What programming language specialization should be used? (python, javascript, or both)", "What is the target file or module name and location?", "What are the main functions, features, or capabilities that need to be implemented?", "What are the major domain objects, entities, or data structures involved?", "What programming paradigm should be used: functional programming, object-oriented programming, or a hybrid approach?", "How should the code be organized into layers or modules? (e.g., domain layer, service layer, presentation layer, data access layer)", "What are the key responsibilities and behaviors of each major component?", "What dependencies exist between components, modules, or external systems?", "Are there any existing code patterns, architectural styles, or design patterns to follow?", "What inputs are available from previous phases? (Check for: story documents, domain maps, BDD test files, existing code structure)", "What are the integration points with existing code or external systems?", "What error handling and validation requirements exist?", "What are the performance, scalability, or resource constraints?", "Are there any language-specific idioms, patterns, or conventions that must be respected?"], "evidence": ["User stories or story documents (from story writing phase)", "Domain maps or domain model documents (from DDD documentation)", "BDD test files or test specifications (from BDD or TDD tests)", "Existing source code files", "API specifications or interface definitions", "Architecture diagrams, design documents / diagrams, or Architecture templates", "Code style guides or conventions", "Project documentation", "Previous code reviews or feedback", "Team coding standards", "Language-specific style guides (PEP 8, Airbnb JS, etc.)"]}}}}, "113": {"action_state": "story_bot.8_code.decide_planning_criteria", "status": "started", "timestamp": "2025-12-10T01:31:31.307478"}, "114": {"action_state": "story_bot.8_code.decide_planning_criteria", "status": "completed", "timestamp": "2025-12-10T01:31:31.334394", "outputs": {"instructions": {"assumptions": ["Focus on maintainability and readability over performance optimizations", "Single Responsibility Principle - Each function/class does one thing well", "Dependency Injection - Dependencies passed through constructors, not created internally", "Immutability preferred - Minimize mutable state where possible", "Explicit over implicit - Make dependencies and behavior explicit", "Testability - Code should be easy to test in isolation", "Respect language-specific idioms and patterns", "Consider code context when generating or validating", "Provide actionable suggestions for violations or improvements", "Balance between strict adherence and practical constraints", "When generating code, incorporate requirements from stories, domain maps, and BDD tests", "When validating code, infer structure and intent from existing code", "Properties vs methods decision determines how object state and behavior are exposed", "Programming paradigm decision (functional/OOP/hybrid) guides overall code structure and patterns"], "decision_criteria": {"decision_criteria": {"description": "Decision making criteria for code behavior", "criteria": [{"description": "Architecture and layering", "question": "How should the code be organized into layers or architectural components?", "outcome": "Determines code structure, separation of concerns, and module organization", "options": ["Layered architecture - Domain, Service, Presentation, Data layers", "Hexagonal/Ports and Adapters - Core domain with adapters for external concerns", "Clean Architecture - Entities, Use Cases, Interface Adapters, Frameworks", "Domain-Driven Design - Services, Aggregates, Context Boundaries, Entities, Value objects, Repositories, Factories, Events, Rules, UI", "Simple module structure - Functions and classes organized by feature", "MVC/MVP/MVVM - Model-View separation patterns", "Microservices structure - Independent services with clear boundaries", "Monolithic structure - Single module with clear internal organization", "Business Logic Only- pure business logic classes focused on modeling both properties and behavior"]}, {"description": "Dependency management", "question": "How should dependencies be managed and injected?", "outcome": "Determines how components depend on each other and external systems", "options": ["Constructor injection - All dependencies passed through constructors", "Dependency injection container - Use DI framework for dependency management", "Factory pattern - Use factories to create dependencies", "Service locator - Central registry for dependencies", "Minimal dependencies - Keep dependencies explicit and minimal", "Interface-based - Depend on interfaces/abstractions, not concrete types"]}, {"description": "Error handling strategy", "question": "What error handling and exception strategy should be used?", "outcome": "Determines how errors are handled and propagated", "options": ["Exception-based - Use exceptions for error conditions", "Result/Either types - Return success/failure results explicitly", "Error codes - Return error codes with results", "Fail-fast - Throw exceptions immediately on errors", "Graceful degradation - Handle errors gracefully with fallbacks", "Language-specific patterns - Use language idioms (Python exceptions, JS promises, etc.)"]}, {"description": "Programming paradigm", "question": "What programming paradigm should be used?", "outcome": "Determines whether code follows functional, object-oriented, or hybrid patterns", "options": ["Functional programming - Pure functions, immutability, higher-order functions, no side effects", "Object-oriented programming - Classes, objects, inheritance, polymorphism, encapsulation", "Hybrid approach - Combine functional and OOP patterns as appropriate", "Procedural - Functions organized by feature, minimal object orientation", "Data-oriented - Focus on data structures and transformations", "Language-idiomatic - Follow the primary paradigm of the chosen language"]}, {"description": "Properties vs methods", "question": "When should properties be used versus methods?", "outcome": "Determines how to expose object state and behavior", "options": ["Properties for all cases - Use properties for both data access and computed values", "Properties only for data - Use properties for simple data access, methods for behavior/computation", "Methods preferred - Use methods for most access, properties only for simple field access", "Computed properties - Use properties for computed values that are cheap and have no side effects", "Language conventions - Follow language-specific conventions (Python @property, C# properties, etc.)", "No properties - Use methods exclusively, no property accessors"]}]}}}}}, "115": {"action_state": "story_bot.8_code.build_knowledge", "status": "started", "timestamp": "2025-12-10T01:31:48.986259"}, "116": {"action_state": "story_bot.8_code.render_output", "status": "started", "timestamp": "2025-12-10T01:32:38.991806"}, "117": {"action_state": "story_bot.8_code.render_output", "status": "completed", "timestamp": "2025-12-10T01:32:39.107585", "outputs": {"instructions": {"action": "render_output", "behavior": "8_code", "base_instructions": ["\n**PROJECT PATH: C:\\dev\\augmented-teams\\demo\\mob_minion**\nAll render outputs must be written to paths relative to this project path, NOT to the bot's own directories.", "Instruction for render_output"], "project_path": "C:\\dev\\augmented-teams\\demo\\mob_minion"}}}}}